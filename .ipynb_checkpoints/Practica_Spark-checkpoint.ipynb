{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICA SPARK - Julia Hernández Elena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import types\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "\n",
    "    SparkConf()\n",
    "    .setAppName(u\"[ICAI] Ejercicios Spark\")\n",
    "    .set(\"spark.executor.memory\", \"7g\")\n",
    "    .set(\"spark.executor.cores\", \"5\")\n",
    "    .set(\"spark.default.parallelism\", 600)\n",
    "    .set(\"spark.sql.shuffle.partitions\", 600) \n",
    "    .set(\"spark.dynamicAllocation.maxExecutors\", 4) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer ambos ficheros a Spark DataFrame y hacer las transformaciones necesarias para conseguir los esquemas establecidos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el esquema que queremos para leer el CSV de info_contenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "esquema_contenidos = T.StructType([\n",
    "\n",
    "    T.StructField(\"id_contenido\",T.IntegerType()),\n",
    "    T.StructField(\"genero\",T.StringType()),\n",
    "    T.StructField(\"subgenero\",T.StringType()),\n",
    "    T.StructField(\"tipo_contenido\",T.StringType())\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contenidos = (\n",
    "\n",
    "    spark.read\n",
    "    .options(header=False) #comprobamos que no tiene header\n",
    "    .schema(esquema_contenidos)\n",
    "    .csv('/datos/practica_spark/info_contenidos.csv') \n",
    "\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#Esquema del dataframe de contenidos:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_contenido: integer (nullable = true)\n",
      " |-- genero: string (nullable = true)\n",
      " |-- subgenero: string (nullable = true)\n",
      " |-- tipo_contenido: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contenidos.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ficheros parquet tienen su propio esquema contenido en el fichero por lo que no lo podemos alterar hasta que lo cargemos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiencias = spark.read.load('/datos/practica_spark/muestra_audiencias.parquet').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audiencias.printSchema() #no imprimimos este por pantalla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos los tipos de las columnas y con un select cambiamos el orden de las columnas en el dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiencias = (\n",
    "    audiencias\n",
    "    .withColumn(\"id_contenido\", audiencias[\"id_contenido\"].cast(\"integer\"))\n",
    "    .withColumn(\"co_cadena\", audiencias[\"co_cadena\"].cast(\"integer\"))\n",
    "    .withColumn(\"it_inicio_titulo\", audiencias[\"it_inicio_titulo\"].cast(\"string\"))\n",
    "    .withColumn(\"it_fin_titulo\", audiencias[\"it_fin_titulo\"].cast(\"string\"))\n",
    "    .withColumn(\"it_inicio_visionado\", audiencias[\"it_inicio_visionado\"].cast(\"string\"))\n",
    "    .withColumn(\"it_fin_visionado\", audiencias[\"it_fin_visionado\"].cast(\"string\"))\n",
    "    \n",
    "    .select('id_contenido', 'co_cadena', 'it_inicio_titulo', 'it_fin_titulo', 'it_inicio_visionado','it_fin_visionado')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#Esquema del dataframe de audiencias tras manipularlo para conseguir el deseado:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_contenido: integer (nullable = true)\n",
      " |-- co_cadena: integer (nullable = true)\n",
      " |-- it_inicio_titulo: string (nullable = true)\n",
      " |-- it_fin_titulo: string (nullable = true)\n",
      " |-- it_inicio_visionado: string (nullable = true)\n",
      " |-- it_fin_visionado: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audiencias.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuántos registros tiene cada DF? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_aud = audiencias.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cont = contenidos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Registros de muestras_audiencias: 17461469\n",
      "#Registros de info_contenidos: 178359\n"
     ]
    }
   ],
   "source": [
    "print(\"#Registros de muestras_audiencias: {}\" .format(count_aud))\n",
    "print(\"#Registros de info_contenidos: {}\" .format(count_cont))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuántos contenidos (id_contenido) únicos tiene cada uno? ¿Cuántas cadenas (co_cadena) hay en el primer DF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|Contenidos unicos en muestras_audiencias|\n",
      "+----------------------------------------+\n",
      "|                                  159083|\n",
      "+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contenido_unico_aud = (\n",
    "    audiencias\n",
    "    .select(F.countDistinct('id_contenido').alias('Contenidos unicos en muestras_audiencias'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|Contenidos unicos en info_contenidos|\n",
      "+------------------------------------+\n",
      "|                              178359|\n",
      "+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contenido_unico_cont = (\n",
    "    contenidos\n",
    "    .select(F.countDistinct('id_contenido').alias('Contenidos unicos en info_contenidos'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|Cadenas en muestras_audiencia|\n",
      "+-----------------------------+\n",
      "|                          154|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cadenas_aud = (\n",
    "    audiencias\n",
    "    .select(F.countDistinct('co_cadena').alias('Cadenas en muestras_audiencia'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En el primer dataset las columnas que marcan momentos (las variables que empiezan por it) están definidas como string, convertirlas a formato timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiencias = (\n",
    "    audiencias\n",
    "    .withColumn(\"it_inicio_titulo\", audiencias[\"it_inicio_titulo\"].cast(\"timestamp\"))\n",
    "    .withColumn(\"it_fin_titulo\", audiencias[\"it_fin_titulo\"].cast(\"timestamp\"))\n",
    "    .withColumn(\"it_inicio_visionado\", audiencias[\"it_inicio_visionado\"].cast(\"timestamp\"))\n",
    "    .withColumn(\"it_fin_visionado\", audiencias[\"it_fin_visionado\"].cast(\"timestamp\"))\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#Esquema del dataframe de audiencias con variables timestamp:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_contenido: integer (nullable = true)\n",
      " |-- co_cadena: integer (nullable = true)\n",
      " |-- it_inicio_titulo: timestamp (nullable = true)\n",
      " |-- it_fin_titulo: timestamp (nullable = true)\n",
      " |-- it_inicio_visionado: timestamp (nullable = true)\n",
      " |-- it_fin_visionado: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audiencias.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular ahora la duración en minutos de cada programa usando it_inicio_titulo y it_fin_titulo, una vez calculado descartar del dataset todos los registros donde la duración sea menor que un minuto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos el formato timestamp a unix timestamp (en segundos), calculamos la diferencia y lo dividimos entre 60. Ademas redondeamos hasta 4 decimales porque no necesitamos tanta informacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiencias = (\n",
    "    \n",
    "    audiencias\n",
    "    \n",
    "    .withColumn(\n",
    "    \"duracion_contenido\", \n",
    "    F.round((F.col(\"it_fin_titulo\").cast(\"long\") - F.col(\"it_inicio_titulo\").cast(\"long\"))/60, 4))\n",
    "\n",
    "    .filter('duracion_contenido>=1')\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es la duración media de los contenidos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|Duracion media de los contenidos en min|\n",
      "+---------------------------------------+\n",
      "|                      78.69994184237703|\n",
      "+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Duracion_media = (\n",
    "    audiencias\n",
    "    .select(F.mean('duracion_contenido').alias(\"Duracion media de los contenidos en min\"))\n",
    "    .show()\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar ahora todos los registros donde el inicio de visionado sea después del fin de visionado ya que se entienden que estos registros son erróneos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audiencias = (\n",
    "    audiencias\n",
    "    .filter('it_fin_visionado>=it_inicio_visionado')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular la duración de cada visualización en minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiencias = (\n",
    "    audiencias\n",
    "    .withColumn(\n",
    "    \"duracion_visualizacion\", \n",
    "    F.round((F.col(\"it_fin_visionado\").cast(\"long\") - F.col(\"it_inicio_visionado\").cast(\"long\"))/60, 4))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para cada contenido, cadena e inicio del título agregar (sumar) todos los minutos vistos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado = (\n",
    "    audiencias\n",
    "    .groupBy('id_contenido', 'co_cadena', 'it_inicio_titulo')\n",
    "    .agg(F.sum('duracion_visualizacion').alias('minutos_visualizados'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el nuevo DF con la información agregada en el esquema personal de hive con el nombre practica_audiencias_agregado (activar el modo overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_user = os.environ.get('USER') #cogemos nuetro nombre de usuario\n",
    "table_name = mi_user + \".practica_audiencias_agregado\" #nombramos la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado.write.mode('overwrite').saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando el DF con información extra de los contenidos, conseguir/pegar en cada registro del DF agregado los campos: genero, subgenero y tipo_contenido usando para ello el campo en común id_contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    agregado\n",
    "    #Hago un Join con la duracion del contenido\n",
    "    .join(contenidos, 'id_contenido')\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir ahora las siguientes columnas sobre el nuevo DF:\n",
    "\n",
    "- ### id_weekday: Día de la semana (en literal) del inicio del programa.\n",
    "- ### id_month: Mes (en literal) del inicio del programa.\n",
    "- ### id_inicio: Hora del inicio del programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    \n",
    "    #Creamos las nuevas columnas\n",
    "    .withColumn(\"id_weekday\", F.date_format(F.col(\"it_inicio_titulo\"), \"EEEE\"))\n",
    "    .withColumn(\"id_month\", F.date_format(F.col(\"it_inicio_titulo\"), \"MMMM\"))\n",
    "    .withColumn(\"id_inicio\", F.hour(F.col(\"it_inicio_titulo\")))\n",
    "    .drop(F.col(\"it_inicio_titulo\"))\n",
    "    \n",
    "    \n",
    "    #Cambiamos el nombre de la columna minutos_visualizados para conseguir el esquema dado\n",
    "    .withColumn(\"minutos\", df[\"minutos_visualizados\"])\n",
    "    \n",
    "    #Seleccionamos el orden de las columnas en el orden dado en el esquema\n",
    "    .select('id_contenido', 'minutos', 'co_cadena', 'genero', 'subgenero', 'tipo_contenido','id_weekday', 'id_month', 'id_inicio')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#Esquema del dataframe de contenidos y audiencias agragegado con las nuevas columnas id_weekday, id_month e id_inicio:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_contenido: integer (nullable = true)\n",
      " |-- minutos: double (nullable = true)\n",
      " |-- co_cadena: integer (nullable = true)\n",
      " |-- genero: string (nullable = true)\n",
      " |-- subgenero: string (nullable = true)\n",
      " |-- tipo_contenido: string (nullable = true)\n",
      " |-- id_weekday: string (nullable = true)\n",
      " |-- id_month: string (nullable = true)\n",
      " |-- id_inicio: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_contenido</th>\n",
       "      <th>minutos</th>\n",
       "      <th>co_cadena</th>\n",
       "      <th>genero</th>\n",
       "      <th>subgenero</th>\n",
       "      <th>tipo_contenido</th>\n",
       "      <th>id_weekday</th>\n",
       "      <th>id_month</th>\n",
       "      <th>id_inicio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4351</td>\n",
       "      <td>265.6334</td>\n",
       "      <td>39</td>\n",
       "      <td>CN</td>\n",
       "      <td>AC</td>\n",
       "      <td>TITULO</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>October</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2770</td>\n",
       "      <td>93.8833</td>\n",
       "      <td>60</td>\n",
       "      <td>DP</td>\n",
       "      <td>PR</td>\n",
       "      <td>SERIE</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>November</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28941</td>\n",
       "      <td>37.7333</td>\n",
       "      <td>142</td>\n",
       "      <td>SR</td>\n",
       "      <td>PO</td>\n",
       "      <td>EPISOD</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>November</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2191</td>\n",
       "      <td>74.9332</td>\n",
       "      <td>150</td>\n",
       "      <td>IN</td>\n",
       "      <td>DA</td>\n",
       "      <td>EPISOD</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>November</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1513</td>\n",
       "      <td>77.6662</td>\n",
       "      <td>49</td>\n",
       "      <td>IN</td>\n",
       "      <td>ED</td>\n",
       "      <td>EPISOD</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>November</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47798</td>\n",
       "      <td>178.2833</td>\n",
       "      <td>84</td>\n",
       "      <td>DP</td>\n",
       "      <td>TN</td>\n",
       "      <td>EVENTO</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44768</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>36</td>\n",
       "      <td>CN</td>\n",
       "      <td>PR</td>\n",
       "      <td>EPISOD</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63979</td>\n",
       "      <td>1.3500</td>\n",
       "      <td>114</td>\n",
       "      <td>SR</td>\n",
       "      <td>AN</td>\n",
       "      <td>EPISOD</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7176</td>\n",
       "      <td>33.5499</td>\n",
       "      <td>53</td>\n",
       "      <td>DP</td>\n",
       "      <td>FE</td>\n",
       "      <td>TITULO</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46874</td>\n",
       "      <td>33.6001</td>\n",
       "      <td>51</td>\n",
       "      <td>DP</td>\n",
       "      <td>IN</td>\n",
       "      <td>EVENTO</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_contenido   minutos  co_cadena genero subgenero tipo_contenido  \\\n",
       "0          4351  265.6334         39     CN        AC         TITULO   \n",
       "1          2770   93.8833         60     DP        PR          SERIE   \n",
       "2         28941   37.7333        142     SR        PO         EPISOD   \n",
       "3          2191   74.9332        150     IN        DA         EPISOD   \n",
       "4          1513   77.6662         49     IN        ED         EPISOD   \n",
       "5         47798  178.2833         84     DP        TN         EVENTO   \n",
       "6         44768    6.7500         36     CN        PR         EPISOD   \n",
       "7         63979    1.3500        114     SR        AN         EPISOD   \n",
       "8          7176   33.5499         53     DP        FE         TITULO   \n",
       "9         46874   33.6001         51     DP        IN         EVENTO   \n",
       "\n",
       "  id_weekday  id_month  id_inicio  \n",
       "0   Saturday   October         18  \n",
       "1   Saturday  November         18  \n",
       "2   Saturday  November          5  \n",
       "3   Saturday  November         21  \n",
       "4   Saturday  November          9  \n",
       "5     Sunday   January         21  \n",
       "6     Sunday   January         10  \n",
       "7     Sunday   January          8  \n",
       "8     Sunday   January         16  \n",
       "9     Sunday   January          9  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con el DF generado hasta ahora, vamos a entrenar un modelo de Machine Learning, queremos explicar los minutos visualizados en función del resto de variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (NOTA: No se usará la variable id_contenido ya que es un identificador)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id_contenido')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Usando StringIndexer codificar cada una de las columnas en numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_quiero = ['co_cadena','genero', 'subgenero', 'tipo_contenido', 'id_weekday', 'id_month','id_inicio']\n",
    "\n",
    "indexers = [ \n",
    "\n",
    "    StringIndexer(inputCol=i, outputCol=i + \"_Index\").setHandleInvalid(\"skip\")  \n",
    "    for i in columnas_quiero\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Usar OneHotEncoder en cada columna para generar las variables binarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [ \n",
    "\n",
    "    OneHotEncoder(dropLast=False, inputCol=indexer.getOutputCol(), outputCol=indexer.getOutputCol() + \"_encoded\") \n",
    "    for indexer in indexers\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Usar VectorAssembler para conseguir un vector de features con todas las variables binarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders], outputCol=\"features\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Encapsular todas las transformaciones de ML anteriores en una pipeline de Spark ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=indexers+encoders+[vectorAssembler]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### ¿Qué tamaño tiene este vector de features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "featues_length = len(transformed.first()[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Tamaño del vector features: 282\n"
     ]
    }
   ],
   "source": [
    "print(\"#Tamanio del vector features: {}\" .format(featues_length))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Dividir xtrain en 80% Train y 20% Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[minutos: double, co_cadena: int, genero: string, subgenero: string, tipo_contenido: string, id_weekday: string, id_month: string, id_inicio: int, co_cadena_Index: double, genero_Index: double, subgenero_Index: double, tipo_contenido_Index: double, id_weekday_Index: double, id_month_Index: double, id_inicio_Index: double, co_cadena_Index_encoded: vector, genero_Index_encoded: vector, subgenero_Index_encoded: vector, tipo_contenido_Index_encoded: vector, id_weekday_Index_encoded: vector, id_month_Index_encoded: vector, id_inicio_Index_encoded: vector, features: vector]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1234\n",
    "trainDF, testDF = transformed.randomSplit([0.8, 0.2], seed=seed)\n",
    "trainDF.cache()\n",
    "testDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Entrenar un árbol de regresión para predecir la variable minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(labelCol='minutos') #toma como inputCo \"features\" de manera predeterminada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=dt.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Evaluar el modelo resultante usando RMSE tanto en la muestra de entrenamiento como en la muestra de test: Comentar el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDF = model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = evaluator.evaluate(model.transform(trainDF))\n",
    "rmse_valid = evaluator.evaluate(predictionDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#RMSE de trainDF: 672.879179\n",
      "#RMSE de testDF: 718.448681\n"
     ]
    }
   ],
   "source": [
    "print(\"#RMSE de trainDF: {:3f}\".format(rmse_train))\n",
    "print(\"#RMSE de testDF: {:3f}\".format(rmse_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En primer lugar podemos comentar que el error de test no es mucho mayor que el error de entrenamiento por lo que podriamos decir que nuestro modelo no sobre-entrena. \n",
      "\n",
      "Sin embargo, tambien podemos comentar que un error de 600-700 minutos es un errror bastante grande y que nuestro modelo no aproxima muy bien los minutos de visualizacion. Quiza necestirariamos un modelo mas complejo como un Forest que consiguiera predecir mejor esta variable\n"
     ]
    }
   ],
   "source": [
    "print(\"En primer lugar podemos comentar que el error de test no es mucho mayor que el error de entrenamiento por lo que podriamos decir\" \n",
    "print(\"que nuestro modelo no sobre-entrena lo que es positivo.\") \n",
    "print(\"Sin embargo, tambien podemos comentar que un error de 718 minutos que es un errror bastante grande. Nuestro modelo no aproximamuy bien los\") \n",
    "print(\"minutos de visualizacion. Quiza necestirariamos un modelo mas complejo como un Random Forest que consiguiera predecir mejor esta variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *OPCIONAL:*\n",
    "- ##### Entrenar también un modelo de Gradient_boosting (implementado en Spark en el objeto GBTRegressor).\n",
    "- ##### Usar validación cruzada sobre la muestra de entrenamiento para tunear los hiperparámetros convenientes hasta conseguir el mejor resultado que seamos capaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Gradient Boosting que aplicaremos a la columna de features calculada anteriormente mendiante StringIndexer, OneHotEnconder y VectorAssembler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(labelCol=\"minutos\", seed=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos a tunear varios parametros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (\n",
    "\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(gbt.maxDepth, [2, 4, 6, 8])\n",
    "    .addGrid(gbt.maxIter, [10, 50, 100, 150])\n",
    "    .build()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando Cross Validation ajustamos el modelo a la columna de features y los hiper-parametros del mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(\n",
    "\n",
    "    estimator = gbt, #aqui ya emos metido que queremos el gbt sin parametros\n",
    "    estimatorParamMaps = paramGrid, #aqui metemos los parametros\n",
    "    evaluator = evaluator,\n",
    "    numFolds = 2\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvGTBModel = crossval.fit(trainDF) #coge el data-set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.avgMetrics #media en cada uno de esos puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor = np.argsort(cvModel.avgMetrics)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cuales son los parametros para el mejor resultado de RMSE. Si fueran extremos del ParamGrid ajustariamos la maya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.avgMetrics[mejor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.getEstimatorParamMaps()[mejor] #nos quedamos con la configuracion de la maya para la mejor configuracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = evaluator.evaluate(cvModel.transform(trainDF))\n",
    "rmse_valid = evaluator.evaluate(cvModel.transform(testDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"## RMSE (Train) de Cross Validation del modelo Gradient Boosting: {:.3f}\".format(rmse_train))\n",
    "print(\"## RMSE (Valid) de Cross Validation del modelo Gradient Boosting: {:.3f}\".format(rmse_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Como podemos comprobar obtenemos bastante mejor resultado que en el arbol de decision.\") \n",
    "print(\"La tecnica de validacion cruzada y este modelo mas complejo han dado resultado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**NOTA:**\n",
    "Para guardar el .ipyng a un.py usamos:\n",
    ">export PATH=/opt/share/anaconda3/bin:$PATH\n",
    "\n",
    ">jupyter nbconvert --to python jupyter_code/Practica_Spark.ipynb\n",
    "\n",
    "Para lanzarlo desde consola y guardar el output en un .txt:\n",
    ">spark2-submit jupyter_code/Practica_Spark.py 2 > jupyter_code/Prints_PracticaSpark.txt\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
