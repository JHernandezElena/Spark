{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> Dataframe API </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spark](img/esquema2.png)\n",
    "\n",
    "&nbsp;  \n",
    "&nbsp;  \n",
    "&nbsp;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark es un framework muy global y nos puede servir para tratar textos, tablas e incluso imágenes y vídeo. Pero la realidad es que mucha de la información a procesar suele ser información estructuradas (tablas, ya sean en csv, parquet, hive o MySQL) y también información semi-estructurada (JSON y XML).\n",
    "\n",
    "Para trabajar con esta información en spark existe la librería `DataFrame`, inspirada en SQL y por su puesto en los `DataFrame` de pandas. Esta librería es muy intuitiva, muy utilizada y con ella conseguimos una *performance* mucho más alta que con spark core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/dataframe.png)\n",
    "<center>\n",
    "    https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros pasos con `DataFrame` de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F  ##F SON FUNCIONES DENTRO DE SPARK PARA TRABAJAR CON DATAFRAMES\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "\n",
    "    SparkConf()\n",
    "    .setAppName(u\"[ICAI] Intro Pyspark\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El punto de entrada para trabajar con la librería de `DataFrame` es directamente `spark`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a2dc82d5ab07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreadme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/datos/README.md'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m#cuando pongo sparkcontext estoy usando la parte spark core con RDDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Si no pongo sc usara la API de dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "readme = spark.read.text('/datos/README.md') \n",
    "    #cuando pongo sparkcontext estoy usando la parte spark core con RDDS\n",
    "    #Si no pongo sc usara la API de dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readme' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0753dda72921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreadme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'readme' is not defined"
     ]
    }
   ],
   "source": [
    "readme#CREA UNA UNICA COLUMNA QUE SE LLAMA VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(readme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** No hay que confundir estos `DataFrame` que viven en spark con los `Dataframe` de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.DataFrame(list(range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='# Apache Spark')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque el uso es parecido y serán muy fáciles de usar si conocemos *pandas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "|     |   47|\n",
      "|  the|   24|\n",
      "|   to|   17|\n",
      "|Spark|   16|\n",
      "|  for|   12|\n",
      "|  and|    9|\n",
      "|   ##|    9|\n",
      "|    a|    8|\n",
      "|  can|    7|\n",
      "|   on|    7|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    # Leemos el fichero como `Dataframe`\n",
    "    spark.read.text('/datos/README.md')\n",
    "    \n",
    "    # Dividimos cada línea por espacios y llamamos a la columna word\n",
    "    #SELECT ES PARA SELECCIONAR COLUMNAS Y AQUI SOLO TENEMOS UNA COLUMNA (VALUE)\n",
    "    .select(\n",
    "        F.split(F.col('value'), \"\\s+\").alias(\"word\")\n",
    "    )\n",
    "    \n",
    "    # Desplegamos cada línea generando más filas (similar al flatMap) UNA FILA POR PALABRA\n",
    "    .withColumn('word',F.explode('word'))\n",
    "    \n",
    "    # Agrupamos y contamos\n",
    "    .groupBy(\"word\")\n",
    "    .count()\n",
    "    \n",
    "    # Ordenamos de mayor a menor\n",
    "    .orderBy(F.desc('count'))\n",
    "    \n",
    "# Mostramos los 10 primeros resultados\n",
    ").limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos generar nuevos DataFrame basados en transformaciones de otros DataFrame igual que haciamos con RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount = (\n",
    "\n",
    "    # Leemos el fichero como `Dataframe`\n",
    "    spark.read.text('/datos/README.md')\n",
    "    \n",
    "    # Dividimos cada línea por espacios y llamamos a la columna word\n",
    "    .select(\n",
    "        F.split(F.col('value'), \"\\s+\").alias(\"word\")\n",
    "    )\n",
    "    \n",
    "    # Desplegamos cada línea generando más filas (similar al flatMap)\n",
    "    .withColumn('word',F.explode('word'))\n",
    "    \n",
    "    # Agrupamos y contamos\n",
    "    .groupBy(\"word\")\n",
    "    .count()  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluso podemos explora el `DAG`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) HashAggregate(keys=[word#40], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(word#40, 200)\n",
      "   +- *(2) HashAggregate(keys=[word#40], functions=[partial_count(1)])\n",
      "      +- Generate explode(word#37), false, [word#40]\n",
      "         +- *(1) Project [split(value#35, \\s+) AS word#37]\n",
      "            +- *(1) FileScan text [value#35] Batched: false, Format: Text, Location: InMemoryFileIndex[hdfs://nameservice1/datos/README.md], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n"
     ]
    }
   ],
   "source": [
    "wordcount.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[word: string, count: bigint]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras que aparecen 4 veces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     word|count|\n",
      "+---------+-----+\n",
      "|      you|    4|\n",
      "|     with|    4|\n",
      "|      You|    4|\n",
      "|   Please|    4|\n",
      "|    build|    4|\n",
      "|       an|    4|\n",
      "|including|    4|\n",
      "|       if|    4|\n",
      "|     also|    4|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordcount.filter(F.col('count') == 4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas y Spark\n",
    "\n",
    "![](img/pandas_logo.png)\n",
    "\n",
    "Al ser estructuras muy parecidas podemos cambiar de una a otra, teniendo en cuenta que si los datos son grandes no podemos trabajar en *pandas* (solo una máquina)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4),columns=list('ABCD'))\n",
    "df['date'] = pd.date_range('20130101',periods=6).astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df) #pasa de ser un pd a un datafraame que vive en el cluster en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: double (nullable = true)\n",
      " |-- B: double (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: double (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+--------------------+----------+\n",
      "|                   A|                   B|                  C|                   D|      date|\n",
      "+--------------------+--------------------+-------------------+--------------------+----------+\n",
      "|  1.1980535635286897|-0.24437765146820498|-0.9495248500522142| -0.3855850717703094|2013-01-01|\n",
      "|   0.548011303239816| -1.1876165112511843|-0.7185140095517636|  1.2556876883555412|2013-01-02|\n",
      "|-0.16064988157166102|  1.2356066991045929|  1.481917218911236| -1.0037837950240482|2013-01-03|\n",
      "|  0.7404059554224549|  1.7408646367938128| -0.571144834151883|-0.04033065546495...|2013-01-04|\n",
      "|    0.91473455953381| -1.4485160371047239| 1.4637898904303752|  1.1174684931238552|2013-01-05|\n",
      "|  0.1735179626327817|-0.18960524296196218|0.43384817979954554| -1.1317267639525321|2013-01-06|\n",
      "+--------------------+--------------------+-------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_df = (\n",
    "\n",
    "    df_spark\n",
    "    .withColumn('nuevo', F.abs(F.col('A') -  F.col('B')) / F.abs(F.col('D'))) #crea una columna nueva o si ya existe la cambia\n",
    "    .select('date','nuevo')\n",
    "\n",
    ").toPandas()  ##COMO HACER UN COLLECT PERO YA EN FORMATO PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nuevo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>nuevo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3.740890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.382213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1.390993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>24.806408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>2.114825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>0.320858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      nuevo\n",
       "0  2013-01-01   3.740890\n",
       "1  2013-01-02   1.382213\n",
       "2  2013-01-03   1.390993\n",
       "3  2013-01-04  24.806408\n",
       "4  2013-01-05   2.114825\n",
       "5  2013-01-06   0.320858"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de CSV\n",
    "\n",
    "![](img/csv.png)\n",
    "&nbsp;   \n",
    "\n",
    "Hemos visto como crear DataFrames leyendo texto con `spark.read` o como crearlos desde *pandas*. Pero la potencía de spark `DataFrames` es trabajar con datos estructurados. Es decir registros con columnas y cada columna de tipos diferentes. Veamos ahora como leer csv desde el hdfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = spark.read.text('/datos/diamonds.csv') #lo lee todo sin formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|\"carat\",\"cut\",\"co...|\n",
      "|0.23,\"Ideal\",\"E\",...|\n",
      "|0.21,\"Premium\",\"E...|\n",
      "|0.23,\"Good\",\"E\",\"...|\n",
      "+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='\"carat\",\"cut\",\"color\",\"clarity\",\"depth\",\"table\",\"price\",\"x\",\"y\",\"z\"'),\n",
       " Row(value='0.23,\"Ideal\",\"E\",\"SI2\",61.5,55,326,3.95,3.98,2.43'),\n",
       " Row(value='0.21,\"Premium\",\"E\",\"SI1\",59.8,61,326,3.89,3.84,2.31'),\n",
       " Row(value='0.23,\"Good\",\"E\",\"VS1\",56.9,65,327,4.05,4.07,2.31')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos `spark.read.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = spark.read.csv('/datos/diamonds.csv') #por defecto el separador es la coma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|  _c0|    _c1|  _c2|    _c3|  _c4|  _c5|  _c6| _c7| _c8| _c9|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5|   55|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8|   61|  326|3.89|3.84|2.31|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.show(3) #no ha sabido interpretar que la primera fila es los nombres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que no ha utilizado la cabecera, pero es una opción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `spark.read.csv` not found.\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv?\n",
    "#saber header, separador e inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = spark.read.options(header=True).csv('/datos/diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- carat: string (nullable = true)\n",
      " |-- cut: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- clarity: string (nullable = true)\n",
      " |-- depth: string (nullable = true)\n",
      " |-- table: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- x: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      " |-- z: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.printSchema() #HACER SIEMPRE ESTO PARA VER QUE LOS TIPOS SON CORRECTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5|   55|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8|   61|  326|3.89|3.84|2.31|\n",
      "| 0.23|   Good|    E|    VS1| 56.9|   65|  327|4.05|4.07|2.31|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos arreglado las cabeceras, pero todos los campos son de tipo `string`. Por defecto será así, podemos pedir que infiera los tipos (aunque esto hará que tarde más la lectura):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = (\n",
    "    \n",
    "    spark.read\n",
    "    .options(header=True, inferSchema=True) ##INFERIR ESQEUMA!! MUY IMP PARA QUE COJA LOS TIPOS\n",
    "    .csv('/datos/diamonds.csv')\n",
    ")\n",
    "#si ya sabemos cual es el esquema se lopodemos poener aqui y seria lo mas ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- carat: double (nullable = true)\n",
      " |-- cut: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- clarity: string (nullable = true)\n",
      " |-- depth: double (nullable = true)\n",
      " |-- table: double (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DOS MANERAS DE HACER FLITRADO\n",
    "filtrado = ( \n",
    "\n",
    "    diamonds\n",
    "    .filter(\"cut = 'Fair' \")\n",
    "    .filter( F.col('clarity') == 'SI2' ) #ALGO MAS CORRECTO\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtrado.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat| cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+----+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.86|Fair|    E|    SI2| 55.1| 69.0| 2757|6.45|6.33|3.52|\n",
      "| 0.96|Fair|    F|    SI2| 66.3| 62.0| 2759|6.27|5.95|4.07|\n",
      "| 0.91|Fair|    H|    SI2| 64.4| 57.0| 2763|6.11|6.09|3.93|\n",
      "| 0.91|Fair|    H|    SI2| 65.7| 60.0| 2763|6.03|5.99|3.95|\n",
      "| 0.98|Fair|    H|    SI2| 67.9| 60.0| 2777|6.05|5.97|4.08|\n",
      "+-----+----+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtrado.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Fair</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>55.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.45</td>\n",
       "      <td>6.33</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.96</td>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>66.3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2759</td>\n",
       "      <td>6.27</td>\n",
       "      <td>5.95</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.91</td>\n",
       "      <td>Fair</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2763</td>\n",
       "      <td>6.11</td>\n",
       "      <td>6.09</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.91</td>\n",
       "      <td>Fair</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>65.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2763</td>\n",
       "      <td>6.03</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.98</td>\n",
       "      <td>Fair</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>67.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2777</td>\n",
       "      <td>6.05</td>\n",
       "      <td>5.97</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat   cut color clarity  depth  table  price     x     y     z\n",
       "0   0.86  Fair     E     SI2   55.1   69.0   2757  6.45  6.33  3.52\n",
       "1   0.96  Fair     F     SI2   66.3   62.0   2759  6.27  5.95  4.07\n",
       "2   0.91  Fair     H     SI2   64.4   57.0   2763  6.11  6.09  3.93\n",
       "3   0.91  Fair     H     SI2   65.7   60.0   2763  6.03  5.99  3.95\n",
       "4   0.98  Fair     H     SI2   67.9   60.0   2777  6.05  5.97  4.08"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##lo hace mucho y es muy util\n",
    "filtrado.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura desde Hive (LO VAMOS A USAR COMO METASTORE)\n",
    "\n",
    "![](img/hive.png)\n",
    "&nbsp;  \n",
    "\n",
    "Spark es comtaible con Hive, esto quiere decir que podemos leer cualquier tabla almacenada allí. Muchas empresas usan Hive como su *Data Warehouse* de big data. Y poder acceder desde spark a estos datos nos aisla de dónde están los datos, en qué formato están almacenados y cómo están comprimidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `spark.catalog` podemos acceder a la información del metastore y listar las bases de datos, tablas, ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase() #nos dice cuales son las bases de datos por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas = spark.catalog.listTables('palcalde') #tablas en la base de datos palcalde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='airport', database='palcalde', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='airport_data', database='palcalde', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='airport_spark', database='palcalde', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='contents', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='dns', database='palcalde', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='flume', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='googletrends', database='palcalde', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='mastercard', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='products_solr', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='ratings', database='palcalde', description='Imported by sqoop on 2017/11/11 10:06:52', tableType='MANAGED', isTemporary=False),\n",
       " Table(name='ratings_parquet', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='ratings_parquet2', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='ratings_parquet_snappy', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='ratings_parquet_snappy2', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='restaurants', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='restaurants2', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='restaurants_avro', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='restaurants_avro_2018', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='tags', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='tags_2018', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='telefonica', database='palcalde', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='test_tbl', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='topdns', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='tvevents', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='tvevents_avro', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='tvevents_parquet', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='tweets', database='palcalde', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='wh_avro', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='wh_parquet', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='wh_parquet2', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='world_happiness', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='world_happiness_part', database='palcalde', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='world_happiness_part2', database='palcalde', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>database</th>\n",
       "      <th>description</th>\n",
       "      <th>tableType</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airport</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airport_data</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airport_spark</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contents</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dns</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flume</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>googletrends</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mastercard</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>products_solr</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ratings</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>Imported by sqoop on 2017/11/11 10:06:52</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ratings_parquet</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ratings_parquet2</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ratings_parquet_snappy</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ratings_parquet_snappy2</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>restaurants</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restaurants2</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>restaurants_avro</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>restaurants_avro_2018</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tags</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tags_2018</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>telefonica</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_tbl</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>topdns</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tvevents</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tvevents_avro</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tvevents_parquet</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tweets</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>wh_avro</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>wh_parquet</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>wh_parquet2</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>world_happiness</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>world_happiness_part</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>world_happiness_part2</td>\n",
       "      <td>palcalde</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  database  \\\n",
       "0                   airport  palcalde   \n",
       "1              airport_data  palcalde   \n",
       "2             airport_spark  palcalde   \n",
       "3                  contents  palcalde   \n",
       "4                       dns  palcalde   \n",
       "5                     flume  palcalde   \n",
       "6              googletrends  palcalde   \n",
       "7                mastercard  palcalde   \n",
       "8             products_solr  palcalde   \n",
       "9                   ratings  palcalde   \n",
       "10          ratings_parquet  palcalde   \n",
       "11         ratings_parquet2  palcalde   \n",
       "12   ratings_parquet_snappy  palcalde   \n",
       "13  ratings_parquet_snappy2  palcalde   \n",
       "14              restaurants  palcalde   \n",
       "15             restaurants2  palcalde   \n",
       "16         restaurants_avro  palcalde   \n",
       "17    restaurants_avro_2018  palcalde   \n",
       "18                     tags  palcalde   \n",
       "19                tags_2018  palcalde   \n",
       "20               telefonica  palcalde   \n",
       "21                 test_tbl  palcalde   \n",
       "22                   topdns  palcalde   \n",
       "23                 tvevents  palcalde   \n",
       "24            tvevents_avro  palcalde   \n",
       "25         tvevents_parquet  palcalde   \n",
       "26                   tweets  palcalde   \n",
       "27                  wh_avro  palcalde   \n",
       "28               wh_parquet  palcalde   \n",
       "29              wh_parquet2  palcalde   \n",
       "30          world_happiness  palcalde   \n",
       "31     world_happiness_part  palcalde   \n",
       "32    world_happiness_part2  palcalde   \n",
       "\n",
       "                                 description tableType  isTemporary  \n",
       "0                                       None  EXTERNAL        False  \n",
       "1                                       None  EXTERNAL        False  \n",
       "2                                       None  EXTERNAL        False  \n",
       "3                                       None   MANAGED        False  \n",
       "4                                       None  EXTERNAL        False  \n",
       "5                                       None   MANAGED        False  \n",
       "6                                       None  EXTERNAL        False  \n",
       "7                                       None   MANAGED        False  \n",
       "8                                       None   MANAGED        False  \n",
       "9   Imported by sqoop on 2017/11/11 10:06:52   MANAGED        False  \n",
       "10                                      None   MANAGED        False  \n",
       "11                                      None   MANAGED        False  \n",
       "12                                      None   MANAGED        False  \n",
       "13                                      None   MANAGED        False  \n",
       "14                                      None   MANAGED        False  \n",
       "15                                      None   MANAGED        False  \n",
       "16                                      None   MANAGED        False  \n",
       "17                                      None   MANAGED        False  \n",
       "18                                      None   MANAGED        False  \n",
       "19                                      None   MANAGED        False  \n",
       "20                                      None  EXTERNAL        False  \n",
       "21                                      None   MANAGED        False  \n",
       "22                                      None   MANAGED        False  \n",
       "23                                      None   MANAGED        False  \n",
       "24                                      None   MANAGED        False  \n",
       "25                                      None   MANAGED        False  \n",
       "26                                      None  EXTERNAL        False  \n",
       "27                                      None   MANAGED        False  \n",
       "28                                      None   MANAGED        False  \n",
       "29                                      None   MANAGED        False  \n",
       "30                                      None   MANAGED        False  \n",
       "31                                      None   MANAGED        False  \n",
       "32                                      None   MANAGED        False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tablas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos `spark.table` para accerder a estas tablas, podemos hacerlo con `base_de_datos.nombre_de_la_tabla` o mejor, cambinado primero de base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[url: string, _id: map<string,string>, address: string, address_line: string, name: string, outcode: string, postcode: string, rating: float, type_of_food: string]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##LEEER TABLAS\n",
    "spark.table('palcalde.restaurants_avro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase('palcalde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes = spark.table('restaurants_avro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- _id: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- address_line: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- outcode: string (nullable = true)\n",
      " |-- postcode: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- type_of_food: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restaurantes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+--------------+--------------------+-------+--------+------+------------+\n",
      "|                 url|                 _id|            address|  address_line|                name|outcode|postcode|rating|type_of_food|\n",
      "+--------------------+--------------------+-------------------+--------------+--------------------+-------+--------+------+------------+\n",
      "|http://www.just-e...|[$oid -> 55f14312...|    Stella Building|    Washington|        Albany Spice|   NE37|     1BH|   4.5|       Curry|\n",
      "|http://www.just-e...|[$oid -> 55f14312...|279 Manchester Road|West Yorkshire|           Albarakah|    HD4|     5AA|   4.5|       Curry|\n",
      "|http://www.just-e...|[$oid -> 55f14312...|  18 Sir Isaac Walk|    Colchester|             Albatta|    CO1|     1JJ|   5.0|    Lebanese|\n",
      "|http://www.just-e...|[$oid -> 55f14312...|    112 Gannow Lane|       Burnley|Alberto's Pizza &...|   BB12|     6QD|   5.5|       Kebab|\n",
      "+--------------------+--------------------+-------------------+--------------+--------------------+-------+--------+------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restaurantes.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>_id</th>\n",
       "      <th>address</th>\n",
       "      <th>address_line</th>\n",
       "      <th>name</th>\n",
       "      <th>outcode</th>\n",
       "      <th>postcode</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_of_food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albany-s...</td>\n",
       "      <td>{'$oid': '55f14312c7447c3da7051d42'}</td>\n",
       "      <td>Stella Building</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Albany Spice</td>\n",
       "      <td>NE37</td>\n",
       "      <td>1BH</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albaraka...</td>\n",
       "      <td>{'$oid': '55f14312c7447c3da7051d43'}</td>\n",
       "      <td>279 Manchester Road</td>\n",
       "      <td>West Yorkshire</td>\n",
       "      <td>Albarakah</td>\n",
       "      <td>HD4</td>\n",
       "      <td>5AA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albatta-...</td>\n",
       "      <td>{'$oid': '55f14312c7447c3da7051d44'}</td>\n",
       "      <td>18 Sir Isaac Walk</td>\n",
       "      <td>Colchester</td>\n",
       "      <td>Albatta</td>\n",
       "      <td>CO1</td>\n",
       "      <td>1JJ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lebanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albertos...</td>\n",
       "      <td>{'$oid': '55f14312c7447c3da7051d45'}</td>\n",
       "      <td>112 Gannow Lane</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Alberto's Pizza &amp; Kebab House</td>\n",
       "      <td>BB12</td>\n",
       "      <td>6QD</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.just-eat.co.uk/restaurants-albany-s...   \n",
       "1  http://www.just-eat.co.uk/restaurants-albaraka...   \n",
       "2  http://www.just-eat.co.uk/restaurants-albatta-...   \n",
       "3  http://www.just-eat.co.uk/restaurants-albertos...   \n",
       "\n",
       "                                    _id              address    address_line  \\\n",
       "0  {'$oid': '55f14312c7447c3da7051d42'}      Stella Building      Washington   \n",
       "1  {'$oid': '55f14312c7447c3da7051d43'}  279 Manchester Road  West Yorkshire   \n",
       "2  {'$oid': '55f14312c7447c3da7051d44'}    18 Sir Isaac Walk      Colchester   \n",
       "3  {'$oid': '55f14312c7447c3da7051d45'}      112 Gannow Lane         Burnley   \n",
       "\n",
       "                            name outcode postcode  rating type_of_food  \n",
       "0                   Albany Spice    NE37      1BH     4.5        Curry  \n",
       "1                      Albarakah     HD4      5AA     4.5        Curry  \n",
       "2                        Albatta     CO1      1JJ     5.0     Lebanese  \n",
       "3  Alberto's Pizza & Kebab House    BB12      6QD     5.5        Kebab  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurantes.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definido el `DataFrame` podemos trabajar como hasta ahora. Por ejemplo contar el número de restaurantes por tipo de cómida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos_comida = restaurantes.groupBy('type_of_food').count().orderBy(F.desc('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|  type_of_food|count|\n",
      "+--------------+-----+\n",
      "|         Curry|  712|\n",
      "|         Pizza|  387|\n",
      "|       Chinese|  138|\n",
      "|         Kebab|  127|\n",
      "|  Fish & Chips|   99|\n",
      "|      American|   83|\n",
      "|       Turkish|   61|\n",
      "|      Lebanese|   45|\n",
      "|     Caribbean|   42|\n",
      "|          Thai|   37|\n",
      "|       Chicken|   37|\n",
      "|       English|   24|\n",
      "|       Burgers|   21|\n",
      "|   Bangladeshi|   15|\n",
      "|Middle Eastern|   13|\n",
      "|     Peri Peri|   13|\n",
      "|      Japanese|   12|\n",
      "|         Grill|   11|\n",
      "| Mediterranean|   11|\n",
      "|       Persian|   10|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tipos_comida.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual que leemos también podemos escribir en hive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos_comida.write.mode('overwrite').saveAsTable('jayuso.tipos_comida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otros ejemplos, buscar la hamburguesa con mayor puntuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_burguer = (\n",
    "\n",
    "    restaurantes\n",
    "    .filter(\"type_of_food = 'Burgers' \")\n",
    "    .orderBy(F.desc('rating'))\n",
    "    \n",
    ").limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>_id</th>\n",
       "      <th>address</th>\n",
       "      <th>address_line</th>\n",
       "      <th>name</th>\n",
       "      <th>outcode</th>\n",
       "      <th>postcode</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_of_food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-beastgou...</td>\n",
       "      <td>{'$oid': '55f14313c7447c3da7052293'}</td>\n",
       "      <td>64 Torwood Street</td>\n",
       "      <td>Torquay</td>\n",
       "      <td>Beast Gourmet Burgers</td>\n",
       "      <td>TQ1</td>\n",
       "      <td>1DT</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Burgers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.just-eat.co.uk/restaurants-beastgou...   \n",
       "\n",
       "                                    _id            address address_line  \\\n",
       "0  {'$oid': '55f14313c7447c3da7052293'}  64 Torwood Street      Torquay   \n",
       "\n",
       "                    name outcode postcode  rating type_of_food  \n",
       "0  Beast Gourmet Burgers     TQ1      1DT     6.0      Burgers  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejor_burguer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a buscar el mejor restaurante del tipo de comida con más restaurantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hay_mas = restaurantes.groupBy('type_of_food').count().orderBy(F.desc('count')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Curry'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hay_mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>_id</th>\n",
       "      <th>address</th>\n",
       "      <th>address_line</th>\n",
       "      <th>name</th>\n",
       "      <th>outcode</th>\n",
       "      <th>postcode</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_of_food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-baltihut...</td>\n",
       "      <td>{'$oid': '55f14313c7447c3da7052149'}</td>\n",
       "      <td>12 Pilkington Buildings</td>\n",
       "      <td>Middlesborough</td>\n",
       "      <td>Balti Hut</td>\n",
       "      <td>TS5</td>\n",
       "      <td>6DY</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Curry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.just-eat.co.uk/restaurants-baltihut...   \n",
       "\n",
       "                                    _id                  address  \\\n",
       "0  {'$oid': '55f14313c7447c3da7052149'}  12 Pilkington Buildings   \n",
       "\n",
       "     address_line       name outcode postcode  rating type_of_food  \n",
       "0  Middlesborough  Balti Hut     TS5      6DY     6.0        Curry  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    restaurantes\n",
    "    .filter(F.col(\"type_of_food\") == hay_mas)\n",
    "    .orderBy(F.desc('rating'))\n",
    "    \n",
    ").limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O podemos hacerlo usando `join` con una sola acción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_of_food</th>\n",
       "      <th>url</th>\n",
       "      <th>_id</th>\n",
       "      <th>address</th>\n",
       "      <th>address_line</th>\n",
       "      <th>name</th>\n",
       "      <th>outcode</th>\n",
       "      <th>postcode</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curry</td>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-amina-st...</td>\n",
       "      <td>{'$oid': '55f14312c7447c3da7051e94'}</td>\n",
       "      <td>5 Sutton Oak Corner</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Amina</td>\n",
       "      <td>B74</td>\n",
       "      <td>2DH</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_of_food                                                url  \\\n",
       "0        Curry  http://www.just-eat.co.uk/restaurants-amina-st...   \n",
       "\n",
       "                                    _id              address address_line  \\\n",
       "0  {'$oid': '55f14312c7447c3da7051e94'}  5 Sutton Oak Corner   Birmingham   \n",
       "\n",
       "    name outcode postcode  rating  \n",
       "0  Amina     B74      2DH     6.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    restaurantes\n",
    "    .join(\n",
    "\n",
    "        restaurantes\n",
    "        .groupBy('type_of_food')\n",
    "        .count()\n",
    "        .orderBy(F.desc('count'))\n",
    "        .limit(1),\n",
    "        'type_of_food',\n",
    "        'leftsemi'\n",
    "\n",
    "    )\n",
    "    .orderBy(F.desc('rating'))\n",
    "    \n",
    ").limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería `DataFrame` también es comptabile con el lenguaje SQL, aunque por debajo también será un `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>_id</th>\n",
       "      <th>address</th>\n",
       "      <th>address_line</th>\n",
       "      <th>name</th>\n",
       "      <th>outcode</th>\n",
       "      <th>postcode</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_of_food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-baltihut...</td>\n",
       "      <td>{'$oid': '55f14313c7447c3da7052149'}</td>\n",
       "      <td>12 Pilkington Buildings</td>\n",
       "      <td>Middlesborough</td>\n",
       "      <td>Balti Hut</td>\n",
       "      <td>TS5</td>\n",
       "      <td>6DY</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Curry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.just-eat.co.uk/restaurants-baltihut...   \n",
       "\n",
       "                                    _id                  address  \\\n",
       "0  {'$oid': '55f14313c7447c3da7052149'}  12 Pilkington Buildings   \n",
       "\n",
       "     address_line       name outcode postcode  rating type_of_food  \n",
       "0  Middlesborough  Balti Hut     TS5      6DY     6.0        Curry  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "select x.* from restaurants_avro x\n",
    "inner join (\n",
    "    \n",
    "    select type_of_food, count(*) as N from restaurants_avro\n",
    "    group by type_of_food\n",
    "    order by N DESC\n",
    "    limit 1\n",
    "\n",
    ") y \n",
    "on x.type_of_food = y.type_of_food\n",
    "order by rating DESC\n",
    "limit 1\n",
    "\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[url: string, _id: map<string,string>, address: string, address_line: string, name: string, outcode: string, postcode: string, rating: float, type_of_food: string]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurantes.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Al finalizar, siempre hay que cerrar la conexión de spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Introduction to Apache Spark on Databricks (2)",
  "notebookId": 687660855473850
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
