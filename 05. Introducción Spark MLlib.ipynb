{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> MLlib: Machine Learning con Spark </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;   \n",
    "\n",
    "![](img/AdvancedAnalytics.jpg)\n",
    "\n",
    "&nbsp;   \n",
    "\n",
    "Otro de los módulos importantes del proyecto Spark es la librería de Machine Learning que se conoce con el nombre de [MLlib](https://spark.apache.org/docs/latest/ml-guide.html). Además de la documentación oficial una buena referencia sobre Machine Learning con Spark es el libro: [Advanced Analytics with Spark\n",
    "](http://shop.oreilly.com/product/0636920035091.do).\n",
    "\n",
    "\n",
    "Se conoce como MLlib al módule de ML de Spark, aunque realmente son dós librerías:\n",
    "\n",
    "* `spark.mllib`: Es la primera de las dos, está basada en RDD y ahora mismo no se desarrolla más sobre esta.\n",
    "* `spark.ml`: Está basada en los DataFrames es más potente y es la que se sigue desarrollando y mejorando.\n",
    "\n",
    "\n",
    "De mano de sus creadores MLlib tiene los siguientes propósitos:\n",
    "\n",
    "**MLlib’s Mission**\n",
    ">MLlib’s mission is to make practical\n",
    "machine learning easy and scalable.    \n",
    "* Capable of learning from large-scale datasets    \n",
    "* Easy to build machine learning applications \n",
    "\n",
    "&nbsp;   \n",
    "\n",
    "Ya conocemos el flujo habitual de una aplicación de ML, podemos verlo resumido en el siguiente gráfico:\n",
    "\n",
    "\n",
    "&nbsp;   \n",
    "\n",
    "![](img/data_flow.jpeg)\n",
    "\n",
    "\n",
    "&nbsp;   \n",
    "\n",
    "Vamos a ver cómo usamos Spark y MLlib para cada uno de estos pasos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "\n",
    "    SparkConf()\n",
    "    .setAppName(u\"[ICAI] Introducción ML\")\n",
    "    .set(\"spark.executor.memory\",\"4g\")\n",
    "    .set(\"spark.executor.cores\",\"2\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Data\n",
    "\n",
    "Para la parte de adquisición y procesamiento de los datos usaremos los DF de spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el primer ejemplo, vamos a usar un dataset de *reviews* de Amazon, está basado en los datos que Amazon publica [aquí](https://snap.stanford.edu/data/web-Amazon.html). Veamos qué formato tienen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsDF = spark.read.parquet('/datos/reviews_amazon.parquet').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This had some assembling but overall it is a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>We love these markers. They state right on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It is the perfect size for storage under a bed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>The hardware works very well, and the fact tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have not had a good camera since my early 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I had to modify it to fit my machine. I though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Well &amp;#34;Joe&amp;#34; made it home for the holida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The lamp this bulb was installed in died a lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I've had these for a few weeks. I absolutely  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Very nice rich color - slightly reddish, sturd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>My son really loved the movie and at first did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I decided to buy this meter after reading revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ONE GREAT COMPANY TO DEAL WITH AT FANTASTIC PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Love this raincoat. Very thin and light. Great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The Secret that we all need to know...Order on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I tried the dermelect smooth upper lip anti-ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>So far it has been great. MY daughter can get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Very good for stopping hair loss and improving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have used a Paul Mitchell straight iron in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>My dog LOVED this toy while it lasted. Unfortu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating                                             review\n",
       "0      5.0  This had some assembling but overall it is a g...\n",
       "1      5.0  We love these markers. They state right on the...\n",
       "2      5.0  It is the perfect size for storage under a bed...\n",
       "3      3.0  The hardware works very well, and the fact tha...\n",
       "4      5.0  I have not had a good camera since my early 20...\n",
       "5      4.0  I had to modify it to fit my machine. I though...\n",
       "6      5.0  Well &#34;Joe&#34; made it home for the holida...\n",
       "7      5.0  The lamp this bulb was installed in died a lon...\n",
       "8      5.0  I've had these for a few weeks. I absolutely  ...\n",
       "9      5.0  Very nice rich color - slightly reddish, sturd...\n",
       "10     5.0  My son really loved the movie and at first did...\n",
       "11     1.0  I decided to buy this meter after reading revi...\n",
       "12     5.0  ONE GREAT COMPANY TO DEAL WITH AT FANTASTIC PR...\n",
       "13     5.0  Love this raincoat. Very thin and light. Great...\n",
       "14     5.0  The Secret that we all need to know...Order on...\n",
       "15     1.0  I tried the dermelect smooth upper lip anti-ag...\n",
       "16     5.0  So far it has been great. MY daughter can get ...\n",
       "17     5.0  Very good for stopping hair loss and improving...\n",
       "18     5.0  I have used a Paul Mitchell straight iron in t...\n",
       "19     3.0  My dog LOVED this toy while it lasted. Unfortu..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsDF.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rating: double (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviewsDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver tenemos una columna `rating` con la puntuación que el usuario a dado en su reseña, además la columna `review` es el texto que ha escrito. Veamos cómo se distribuye el campo `rating`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado = reviewsDF.groupBy('rating').count().orderBy('rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  count\n",
       "0     1.0   1881\n",
       "1     2.0   1138\n",
       "2     3.0   1696\n",
       "3     4.0   3460\n",
       "4     5.0  11784"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agregado.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mejor con porcentajes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "      <th>pcte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1881</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1138</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1696</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3460</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11784</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  count  pcte\n",
       "0     1.0   1881  0.09\n",
       "1     2.0   1138  0.06\n",
       "2     3.0   1696  0.08\n",
       "3     4.0   3460  0.17\n",
       "4     5.0  11784  0.59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    agregado\n",
    "    .crossJoin(agregado.select(F.sum(\"count\").alias(\"total\")))\n",
    "    .withColumn('pcte', F.round(F.col('count') / F.col('total'),2) )\n",
    "    .drop('total')\n",
    "    .orderBy('rating')\n",
    "\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casi el 60% de las reseñas tienen un 5, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Somos capaces de predecir qué valor va a tener la reseña según el texto que se escribe?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es claro que si el texto tienen algunas palabras hay más posibilidades de tener una buena o mala valoración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado2 = reviewsDF.filter(\"\"\" lower(review) LIKE '%great%' \"\"\").groupBy('rating').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "      <th>pcte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>142</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>242</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>840</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3580</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  count  pcte\n",
       "0     1.0    142  0.03\n",
       "1     2.0    139  0.03\n",
       "2     3.0    242  0.05\n",
       "3     4.0    840  0.17\n",
       "4     5.0   3580  0.72"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    agregado2\n",
    "    .crossJoin(agregado2.select(F.sum(\"count\").alias(\"total\")))\n",
    "    .withColumn('pcte', F.round(F.col('count') / F.col('total'),2) )\n",
    "    .drop('total')\n",
    "    .orderBy('rating')\n",
    "\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrando por las que contengan la palabra 'great', vemos como el porcentaje de 5 sube hasta el 72%, ¿Qué pasara si la review contienen la cadena 'poor'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregado3 = reviewsDF.filter(\"\"\" lower(review) LIKE '%poor%' \"\"\").groupBy('rating').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "      <th>pcte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  count  pcte\n",
       "0     1.0     81  0.34\n",
       "1     2.0     55  0.23\n",
       "2     3.0     28  0.12\n",
       "3     4.0     24  0.10\n",
       "4     5.0     47  0.20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    agregado3\n",
    "    .crossJoin(agregado3.select(F.sum(\"count\").alias(\"total\")))\n",
    "    .withColumn('pcte', F.round(F.col('count') / F.col('total'),2) )\n",
    "    .drop('total')\n",
    "    .orderBy('rating')\n",
    "\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperar la distribución cambia y hay más peso en los valores bajos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Clean, Prepare & Manipulate Data\n",
    "\n",
    "Esta parte es una de la más laboriosas (y menos divertidas/gratificantes) de un proceso de ML. Además de poder usar los DF para hacer la parte más básica (seleccionar, filtrar, agrupar, unir...) con MLlib existen funciones que nos serán de gran ayuda en este apartado.\n",
    "\n",
    "Se conocen bajo el nombre de [ml-features](https://spark.apache.org/docs/latest/ml-features.html) y tenemos a nuestra disposición todas estas funciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul id=\"markdown-toc\">\n",
    "  <li><a href=\"#feature-extractors\" id=\"markdown-toc-feature-extractors\">Feature Extractors</a>    <ul>\n",
    "      <li><a href=\"#tf-idf\" id=\"markdown-toc-tf-idf\">TF-IDF</a></li>\n",
    "      <li><a href=\"#word2vec\" id=\"markdown-toc-word2vec\">Word2Vec</a></li>\n",
    "      <li><a href=\"#countvectorizer\" id=\"markdown-toc-countvectorizer\">CountVectorizer</a></li>\n",
    "      <li><a href=\"#featurehasher\" id=\"markdown-toc-featurehasher\">FeatureHasher</a></li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><a href=\"#feature-transformers\" id=\"markdown-toc-feature-transformers\">Feature Transformers</a>    <ul>\n",
    "      <li><a href=\"#tokenizer\" id=\"markdown-toc-tokenizer\">Tokenizer</a></li>\n",
    "      <li><a href=\"#stopwordsremover\" id=\"markdown-toc-stopwordsremover\">StopWordsRemover</a></li>\n",
    "      <li><a href=\"#binarizer\" id=\"markdown-toc-binarizer\">Binarizer</a></li>\n",
    "      <li><a href=\"#pca\" id=\"markdown-toc-pca\">PCA</a></li>\n",
    "      <li><a href=\"#polynomialexpansion\" id=\"markdown-toc-polynomialexpansion\">PolynomialExpansion</a></li>\n",
    "      <li><a href=\"#discrete-cosine-transform-dct\" id=\"markdown-toc-discrete-cosine-transform-dct\">Discrete Cosine Transform (DCT)</a></li>\n",
    "      <li><a href=\"#stringindexer\" id=\"markdown-toc-stringindexer\">StringIndexer</a></li>\n",
    "      <li><a href=\"#indextostring\" id=\"markdown-toc-indextostring\">IndexToString</a></li>\n",
    "      <li><a href=\"#onehotencoder-deprecated-since-230\" id=\"markdown-toc-onehotencoder-deprecated-since-230\">OneHotEncoder (Deprecated since 2.3.0)</a></li>\n",
    "      <li><a href=\"#onehotencoderestimator\" id=\"markdown-toc-onehotencoderestimator\">OneHotEncoderEstimator</a></li>\n",
    "      <li><a href=\"#vectorindexer\" id=\"markdown-toc-vectorindexer\">VectorIndexer</a></li>\n",
    "      <li><a href=\"#interaction\" id=\"markdown-toc-interaction\">Interaction</a></li>\n",
    "      <li><a href=\"#normalizer\" id=\"markdown-toc-normalizer\">Normalizer</a></li>\n",
    "      <li><a href=\"#standardscaler\" id=\"markdown-toc-standardscaler\">StandardScaler</a></li>\n",
    "      <li><a href=\"#minmaxscaler\" id=\"markdown-toc-minmaxscaler\">MinMaxScaler</a></li>\n",
    "      <li><a href=\"#maxabsscaler\" id=\"markdown-toc-maxabsscaler\">MaxAbsScaler</a></li>\n",
    "      <li><a href=\"#bucketizer\" id=\"markdown-toc-bucketizer\">Bucketizer</a></li>\n",
    "      <li><a href=\"#elementwiseproduct\" id=\"markdown-toc-elementwiseproduct\">ElementwiseProduct</a></li>\n",
    "      <li><a href=\"#sqltransformer\" id=\"markdown-toc-sqltransformer\">SQLTransformer</a></li>\n",
    "      <li><a href=\"#vectorassembler\" id=\"markdown-toc-vectorassembler\">VectorAssembler</a></li>\n",
    "      <li><a href=\"#vectorsizehint\" id=\"markdown-toc-vectorsizehint\">VectorSizeHint</a></li>\n",
    "      <li><a href=\"#quantilediscretizer\" id=\"markdown-toc-quantilediscretizer\">QuantileDiscretizer</a></li>\n",
    "      <li><a href=\"#imputer\" id=\"markdown-toc-imputer\">Imputer</a></li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><a href=\"#feature-selectors\" id=\"markdown-toc-feature-selectors\">Feature Selectors</a>    <ul>\n",
    "      <li><a href=\"#vectorslicer\" id=\"markdown-toc-vectorslicer\">VectorSlicer</a></li>\n",
    "      <li><a href=\"#rformula\" id=\"markdown-toc-rformula\">RFormula</a></li>\n",
    "      <li><a href=\"#chisqselector\" id=\"markdown-toc-chisqselector\">ChiSqSelector</a></li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><a href=\"#locality-sensitive-hashing\" id=\"markdown-toc-locality-sensitive-hashing\">Locality Sensitive Hashing</a>    <ul>\n",
    "      <li><a href=\"#lsh-operations\" id=\"markdown-toc-lsh-operations\">LSH Operations</a>        <ul>\n",
    "          <li><a href=\"#feature-transformation\" id=\"markdown-toc-feature-transformation\">Feature Transformation</a></li>\n",
    "          <li><a href=\"#approximate-similarity-join\" id=\"markdown-toc-approximate-similarity-join\">Approximate Similarity Join</a></li>\n",
    "          <li><a href=\"#approximate-nearest-neighbor-search\" id=\"markdown-toc-approximate-nearest-neighbor-search\">Approximate Nearest Neighbor Search</a></li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li><a href=\"#lsh-algorithms\" id=\"markdown-toc-lsh-algorithms\">LSH Algorithms</a>        <ul>\n",
    "          <li><a href=\"#bucketed-random-projection-for-euclidean-distance\" id=\"markdown-toc-bucketed-random-projection-for-euclidean-distance\">Bucketed Random Projection for Euclidean Distance</a></li>\n",
    "          <li><a href=\"#minhash-for-jaccard-distance\" id=\"markdown-toc-minhash-for-jaccard-distance\">MinHash for Jaccard Distance</a></li>\n",
    "        </ul>\n",
    "      </li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver algunas de ellas usando nuestro ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegexTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `RegexTokenizer` podemos dividir un texto por una expresión regular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "#definimos el tokenizador que es un TRANSFORMADOR\n",
    "tokenizer = (\n",
    "\n",
    "    RegexTokenizer()\n",
    "    .setInputCol(\"review\") #columna de la que voy a leer\n",
    "    .setOutputCol(\"tokens\") #como voy a exportar la columna\n",
    "    .setPattern(\"\\\\W+\") #patron: separara por cualquier caracter no alfanumerico y contiguo (se los cargara y creara una list)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería `pyspark.ml` está inspirada en el proyecto [scikit-learn](http://scikit-learn.org/) de python, al igual que esta, para cada proceso/transformación que queramos realizar creamos primero un obejeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.RegexTokenizer"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el objeto es de tipo `RegexTokenizer`, una vez definido tendremos que usar `fit` si es necesario (en este caso no) y después `transform` para transformar nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedDF = tokenizer.transform(reviewsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rating: double (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This had some assembling but overall it is a g...</td>\n",
       "      <td>[this, had, some, assembling, but, overall, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>We love these markers. They state right on the...</td>\n",
       "      <td>[we, love, these, markers, they, state, right,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It is the perfect size for storage under a bed...</td>\n",
       "      <td>[it, is, the, perfect, size, for, storage, und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>The hardware works very well, and the fact tha...</td>\n",
       "      <td>[the, hardware, works, very, well, and, the, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have not had a good camera since my early 20...</td>\n",
       "      <td>[i, have, not, had, a, good, camera, since, my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  \\\n",
       "0     5.0  This had some assembling but overall it is a g...   \n",
       "1     5.0  We love these markers. They state right on the...   \n",
       "2     5.0  It is the perfect size for storage under a bed...   \n",
       "3     3.0  The hardware works very well, and the fact tha...   \n",
       "4     5.0  I have not had a good camera since my early 20...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [this, had, some, assembling, but, overall, it...  \n",
       "1  [we, love, these, markers, they, state, right,...  \n",
       "2  [it, is, the, perfect, size, for, storage, und...  \n",
       "3  [the, hardware, works, very, well, and, the, f...  \n",
       "4  [i, have, not, had, a, good, camera, since, my...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedDF.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'had',\n",
       " 'some',\n",
       " 'assembling',\n",
       " 'but',\n",
       " 'overall',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'product',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'youtuber',\n",
       " 'and',\n",
       " 'when',\n",
       " 'i',\n",
       " 'make',\n",
       " 'car']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedDF.first()['tokens'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words\n",
    "\n",
    "Cuando trabajamos con texto y hacemos [*Text mining*](https://en.wikipedia.org/wiki/Text_mining), hay muchas palabras que se repiten mucho y no aportan significado, son por ejemplo los artículos, conjunciones...\n",
    "\n",
    "Con `StopWordsRemover` podemos borrar estas palabras, la función de Spark está diseñada para el idioa en inglés (como el ejemplo), pero podemos encontrar diccionarios con las palabras comunes para el español y otros idiomas.\n",
    "\n",
    "Por ejemplo: https://github.com/postgres/postgres/blob/master/src/backend/snowball/stopwords/spanish.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "remover = (\n",
    "\n",
    "    StopWordsRemover()\n",
    "    .setInputCol(\"tokens\")\n",
    "    .setOutputCol(\"stopWordFree\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.StopWordsRemover"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "removedStopWordsDF = remover.transform(tokenizedDF) #nos anadira una columna con las palabras menos las que ha eliminado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rating: double (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- stopWordFree: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "removedStopWordsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stopWordFree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This had some assembling but overall it is a g...</td>\n",
       "      <td>[this, had, some, assembling, but, overall, it...</td>\n",
       "      <td>[assembling, overall, great, product, youtuber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>We love these markers. They state right on the...</td>\n",
       "      <td>[we, love, these, markers, they, state, right,...</td>\n",
       "      <td>[love, markers, state, right, package, washabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It is the perfect size for storage under a bed...</td>\n",
       "      <td>[it, is, the, perfect, size, for, storage, und...</td>\n",
       "      <td>[perfect, size, storage, bed, sturdy, holds, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>The hardware works very well, and the fact tha...</td>\n",
       "      <td>[the, hardware, works, very, well, and, the, f...</td>\n",
       "      <td>[hardware, works, well, fact, solid, state, hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have not had a good camera since my early 20...</td>\n",
       "      <td>[i, have, not, had, a, good, camera, since, my...</td>\n",
       "      <td>[good, camera, since, early, 20, managed, lose...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  \\\n",
       "0     5.0  This had some assembling but overall it is a g...   \n",
       "1     5.0  We love these markers. They state right on the...   \n",
       "2     5.0  It is the perfect size for storage under a bed...   \n",
       "3     3.0  The hardware works very well, and the fact tha...   \n",
       "4     5.0  I have not had a good camera since my early 20...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [this, had, some, assembling, but, overall, it...   \n",
       "1  [we, love, these, markers, they, state, right,...   \n",
       "2  [it, is, the, perfect, size, for, storage, und...   \n",
       "3  [the, hardware, works, very, well, and, the, f...   \n",
       "4  [i, have, not, had, a, good, camera, since, my...   \n",
       "\n",
       "                                        stopWordFree  \n",
       "0  [assembling, overall, great, product, youtuber...  \n",
       "1  [love, markers, state, right, package, washabl...  \n",
       "2  [perfect, size, storage, bed, sturdy, holds, w...  \n",
       "3  [hardware, works, well, fact, solid, state, hu...  \n",
       "4  [good, camera, since, early, 20, managed, lose...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removedStopWordsDF.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|size(tokens)|size(stopWordFree)|\n",
      "+------------+------------------+\n",
      "|          69|                29|\n",
      "|          93|                42|\n",
      "|          45|                20|\n",
      "|         140|                65|\n",
      "|         335|               170|\n",
      "|          39|                15|\n",
      "|          25|                14|\n",
      "|          72|                34|\n",
      "|          22|                 9|\n",
      "|          20|                14|\n",
      "|          49|                26|\n",
      "|          66|                36|\n",
      "|          71|                36|\n",
      "|          27|                15|\n",
      "|          26|                12|\n",
      "|         101|                50|\n",
      "|          23|                 7|\n",
      "|          25|                14|\n",
      "|          77|                39|\n",
      "|          72|                41|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "removedStopWordsDF.select(F.size('tokens'),F.size('stopWordFree')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este modo hemos podido simplificar los datos, podemos ver el set de palabras usado del siguiente modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n",
       "       'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his',\n",
       "       'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n",
       "       'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
       "       'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
       "       'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
       "       'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
       "       'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
       "       'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
       "       'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
       "       'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
       "       'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
       "       'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
       "       'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
       "       'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will',\n",
       "       'just', 'don', 'should', 'now', \"i'll\", \"you'll\", \"he'll\",\n",
       "       \"she'll\", \"we'll\", \"they'll\", \"i'd\", \"you'd\", \"he'd\", \"she'd\",\n",
       "       \"we'd\", \"they'd\", \"i'm\", \"you're\", \"he's\", \"she's\", \"it's\",\n",
       "       \"we're\", \"they're\", \"i've\", \"we've\", \"you've\", \"they've\", \"isn't\",\n",
       "       \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\",\n",
       "       \"don't\", \"doesn't\", \"didn't\", \"won't\", \"wouldn't\", \"shan't\",\n",
       "       \"shouldn't\", \"mustn't\", \"can't\", \"couldn't\", 'cannot', 'could',\n",
       "       \"here's\", \"how's\", \"let's\", 'ought', \"that's\", \"there's\", \"what's\",\n",
       "       \"when's\", \"where's\", \"who's\", \"why's\", 'would'], dtype='<U10')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(remover.getStopWords())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer\n",
    "\n",
    "Let's build a vocabulary of 1000 words from our reviews by building a [CountVectorizer](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizer) model. We retain only the most frequent 1000 tokens that occur in the reviews.\n",
    "\n",
    "Cuenta para las 1000 palabras mas frecuentes en los reviews el numero de veces que aparecen en cada review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "counts = (\n",
    "    \n",
    "    CountVectorizer()\n",
    "    .setInputCol(\"stopWordFree\")\n",
    "    .setOutputCol(\"features\")\n",
    "    .setVocabSize(1000) #voy a contar las 1000 palabras que mas aparezcan\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.CountVectorizer"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CountVectorizer' object has no attribute 'transform'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    counts.transform(removedStopWordsDF)\n",
    "\n",
    "except Exception as inst:\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso antes de usasr `transform`, tenemos que hacer `fit`. Esto es porque la función que queremos emplear necesita primero analizar los datos y \"aprender\" para luego poder transformarlo. \n",
    "\n",
    "**Nota:** Hacer `fit` se considera una acción para spark ya que tiene que evaluar así que suele ser un buen momento para cachear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19959"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removedStopWordsDF.cache()\n",
    "removedStopWordsDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "countModel = counts.fit(removedStopWordsDF) #aprende del data frame para ver cuales son las 1000 palabras mas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.CountVectorizerModel"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(countModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['one', 'great', 'like', 'good', 'use', 'product', 'well', 'get',\n",
       "       'time', 'really', 'love', 'little', 'much', 'bought', 'also',\n",
       "       'easy', 'price', 'works', 'used', 'work', 'even', '2', 'm', 've',\n",
       "       'quality', 'buy', 'first', 'better', 'using', 'back', 'got',\n",
       "       'made', 'recommend', '34', 'still', 'nice', 'two', 'make', 'case',\n",
       "       '3', 'new', 'need', 'put', 'old', 'way', 'best', 'go', 'small',\n",
       "       '5', 'phone', 'fit', 'day', 'long', 'set', 'perfect', '1', 'didn',\n",
       "       'years', 'think', 'see', 'doesn', 'enough', 'want', 'right',\n",
       "       'thing', 'find', 'another', 'around', 'light', 'since', 'amazon',\n",
       "       '4', 'never', 'water', 'many', 'bit', 'without', 'every', 'take',\n",
       "       'sure', 'lot', 'looking', 'know', 'year', 'hair', 'say', 'look',\n",
       "       'size', 'purchased', 'keep', 'far', 'found', 'box', 'makes',\n",
       "       'pretty', 'last', 're', 'came', 'money', 'hard'], dtype='<U13')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(countModel.vocabulary)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = countModel.transform(removedStopWordsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rating: double (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- stopWordFree: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stopWordFree</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This had some assembling but overall it is a g...</td>\n",
       "      <td>[this, had, some, assembling, but, overall, it...</td>\n",
       "      <td>[assembling, overall, great, product, youtuber...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>We love these markers. They state right on the...</td>\n",
       "      <td>[we, love, these, markers, they, state, right,...</td>\n",
       "      <td>[love, markers, state, right, package, washabl...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It is the perfect size for storage under a bed...</td>\n",
       "      <td>[it, is, the, perfect, size, for, storage, und...</td>\n",
       "      <td>[perfect, size, storage, bed, sturdy, holds, w...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>The hardware works very well, and the fact tha...</td>\n",
       "      <td>[the, hardware, works, very, well, and, the, f...</td>\n",
       "      <td>[hardware, works, well, fact, solid, state, hu...</td>\n",
       "      <td>(0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have not had a good camera since my early 20...</td>\n",
       "      <td>[i, have, not, had, a, good, camera, since, my...</td>\n",
       "      <td>[good, camera, since, early, 20, managed, lose...</td>\n",
       "      <td>(0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I had to modify it to fit my machine. I though...</td>\n",
       "      <td>[i, had, to, modify, it, to, fit, my, machine,...</td>\n",
       "      <td>[modify, fit, machine, thought, model, right, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Well &amp;#34;Joe&amp;#34; made it home for the holida...</td>\n",
       "      <td>[well, 34, joe, 34, made, it, home, for, the, ...</td>\n",
       "      <td>[well, 34, joe, 34, made, home, holidays, exac...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The lamp this bulb was installed in died a lon...</td>\n",
       "      <td>[the, lamp, this, bulb, was, installed, in, di...</td>\n",
       "      <td>[lamp, bulb, installed, died, long, time, ago,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I've had these for a few weeks. I absolutely  ...</td>\n",
       "      <td>[i, ve, had, these, for, a, few, weeks, i, abs...</td>\n",
       "      <td>[ve, weeks, absolutely, love, ve, great, resul...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Very nice rich color - slightly reddish, sturd...</td>\n",
       "      <td>[very, nice, rich, color, slightly, reddish, s...</td>\n",
       "      <td>[nice, rich, color, slightly, reddish, sturdy,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  \\\n",
       "0     5.0  This had some assembling but overall it is a g...   \n",
       "1     5.0  We love these markers. They state right on the...   \n",
       "2     5.0  It is the perfect size for storage under a bed...   \n",
       "3     3.0  The hardware works very well, and the fact tha...   \n",
       "4     5.0  I have not had a good camera since my early 20...   \n",
       "5     4.0  I had to modify it to fit my machine. I though...   \n",
       "6     5.0  Well &#34;Joe&#34; made it home for the holida...   \n",
       "7     5.0  The lamp this bulb was installed in died a lon...   \n",
       "8     5.0  I've had these for a few weeks. I absolutely  ...   \n",
       "9     5.0  Very nice rich color - slightly reddish, sturd...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [this, had, some, assembling, but, overall, it...   \n",
       "1  [we, love, these, markers, they, state, right,...   \n",
       "2  [it, is, the, perfect, size, for, storage, und...   \n",
       "3  [the, hardware, works, very, well, and, the, f...   \n",
       "4  [i, have, not, had, a, good, camera, since, my...   \n",
       "5  [i, had, to, modify, it, to, fit, my, machine,...   \n",
       "6  [well, 34, joe, 34, made, it, home, for, the, ...   \n",
       "7  [the, lamp, this, bulb, was, installed, in, di...   \n",
       "8  [i, ve, had, these, for, a, few, weeks, i, abs...   \n",
       "9  [very, nice, rich, color, slightly, reddish, s...   \n",
       "\n",
       "                                        stopWordFree  \\\n",
       "0  [assembling, overall, great, product, youtuber...   \n",
       "1  [love, markers, state, right, package, washabl...   \n",
       "2  [perfect, size, storage, bed, sturdy, holds, w...   \n",
       "3  [hardware, works, well, fact, solid, state, hu...   \n",
       "4  [good, camera, since, early, 20, managed, lose...   \n",
       "5  [modify, fit, machine, thought, model, right, ...   \n",
       "6  [well, 34, joe, 34, made, home, holidays, exac...   \n",
       "7  [lamp, bulb, installed, died, long, time, ago,...   \n",
       "8  [ve, weeks, absolutely, love, ve, great, resul...   \n",
       "9  [nice, rich, color, slightly, reddish, sturdy,...   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "3  (0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, ...  \n",
       "4  (0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...  \n",
       "8  (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|rating|              review|              tokens|        stopWordFree|            features|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   5.0|This had some ass...|[this, had, some,...|[assembling, over...|(1000,[1,3,5,14,3...|\n",
      "|   5.0|We love these mar...|[we, love, these,...|[love, markers, s...|(1000,[4,10,11,43...|\n",
      "|   5.0|It is the perfect...|[it, is, the, per...|[perfect, size, s...|(1000,[6,9,54,61,...|\n",
      "|   3.0|The hardware work...|[the, hardware, w...|[hardware, works,...|(1000,[1,4,5,6,7,...|\n",
      "|   5.0|I have not had a ...|[i, have, not, ha...|[good, camera, si...|(1000,[1,2,3,14,2...|\n",
      "|   4.0|I had to modify i...|[i, had, to, modi...|[modify, fit, mac...|(1000,[5,32,50,63...|\n",
      "|   5.0|Well &#34;Joe&#34...|[well, 34, joe, 3...|[well, 34, joe, 3...|(1000,[6,31,33,10...|\n",
      "|   5.0|The lamp this bul...|[the, lamp, this,...|[lamp, bulb, inst...|(1000,[6,8,9,15,3...|\n",
      "|   5.0|I've had these fo...|[i, ve, had, thes...|[ve, weeks, absol...|(1000,[1,4,8,10,2...|\n",
      "|   5.0|Very nice rich co...|[very, nice, rich...|[nice, rich, colo...|(1000,[5,15,35,42...|\n",
      "|   5.0|My son really lov...|[my, son, really,...|[son, really, lov...|(1000,[2,3,9,24,2...|\n",
      "|   1.0|I decided to buy ...|[i, decided, to, ...|[decided, buy, me...|(1000,[0,25,74,12...|\n",
      "|   5.0|ONE GREAT COMPANY...|[one, great, comp...|[one, great, comp...|(1000,[0,1,24,26,...|\n",
      "|   5.0|Love this raincoa...|[love, this, rain...|[love, raincoat, ...|(1000,[1,10,13,21...|\n",
      "|   5.0|The Secret that w...|[the, secret, tha...|[secret, need, kn...|(1000,[0,41,62,77...|\n",
      "|   1.0|I tried the derme...|[i, tried, the, d...|[tried, dermelect...|(1000,[5,7,8,28,2...|\n",
      "|   5.0|So far it has bee...|[so, far, it, has...|[far, great, daug...|(1000,[1,7,15,90,...|\n",
      "|   5.0|Very good for sto...|[very, good, for,...|[good, stopping, ...|(1000,[3,28,57,84...|\n",
      "|   5.0|I have used a Pau...|[i, have, used, a...|[used, paul, mitc...|(1000,[2,10,16,18...|\n",
      "|   3.0|My dog LOVED this...|[my, dog, loved, ...|[dog, loved, toy,...|(1000,[0,52,66,95...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta.show() #fijate que guarda en features solo los que no son 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = meta.first()['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(1000, {1: 1.0, 3: 2.0, 5: 1.0, 14: 1.0, 37: 1.0, 42: 1.0, 46: 1.0, 65: 1.0, 99: 1.0, 163: 1.0, 181: 1.0, 184: 1.0, 197: 2.0, 216: 1.0, 297: 1.0, 518: 2.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector #lo guarda un poco raro: NO GUATDA LOS 0s\n",
    "#las primeras palabras que eran las mas utilizadas en los reviews son logicamente las que mas se repiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.linalg.SparseVector"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un vector de Spark de tipo *sparse*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 2., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.toArray()[:50] #podiamos pasarlo a array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 2.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.values #podriamos coger solo los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   3,   5,  14,  37,  42,  46,  65,  99, 163, 181, 184, 197,\n",
       "       216, 297, 518], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.indices #o solo los indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMO SERIA ESTO EN PYTHON?\n",
    "\n",
    "matrix_sparse = sp.csr_matrix(\n",
    "\n",
    "    (vector.values,(np.zeros_like(vector.values),vector.indices)),\n",
    "    shape=(1,vector.size)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t2.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 14)\t1.0\n",
      "  (0, 37)\t1.0\n",
      "  (0, 42)\t1.0\n",
      "  (0, 46)\t1.0\n",
      "  (0, 65)\t1.0\n",
      "  (0, 99)\t1.0\n",
      "  (0, 163)\t1.0\n",
      "  (0, 181)\t1.0\n",
      "  (0, 184)\t1.0\n",
      "  (0, 197)\t2.0\n",
      "  (0, 216)\t1.0\n",
      "  (0, 297)\t1.0\n",
      "  (0, 518)\t2.0\n"
     ]
    }
   ],
   "source": [
    "print(matrix_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizer\n",
    "\n",
    "En este ejemplo queremos seperar las reseñan en \"positivas\" o \"negativas\". Así que en este caso queremos convertir la variable `rating` en dos grupos.\n",
    "\n",
    "En Spark tenemos dos funciones que nos pueden ayudar a esto:\n",
    "\n",
    "* `Bucketizer` que es más general y sirve para dividir una variable numérica en un número de grupos,es similar a la función `findInterval` de R o a `bisect` de python.\n",
    "\n",
    "* `Binarizer` que como su propio nombre indica sirve para convertir en dos clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "binarizer = (\n",
    "\n",
    "    Binarizer()\n",
    "    .setInputCol(\"rating\") #elegimos la columna rating\n",
    "    .setOutputCol(\"label\") #la vamos a llamar label a la nueva colummna de 1s y 0s\n",
    "    .setThreshold(3.5) #cortamos en 3.5\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = binarizer.transform(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stopWordFree</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This had some assembling but overall it is a g...</td>\n",
       "      <td>[this, had, some, assembling, but, overall, it...</td>\n",
       "      <td>[assembling, overall, great, product, youtuber...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>We love these markers. They state right on the...</td>\n",
       "      <td>[we, love, these, markers, they, state, right,...</td>\n",
       "      <td>[love, markers, state, right, package, washabl...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It is the perfect size for storage under a bed...</td>\n",
       "      <td>[it, is, the, perfect, size, for, storage, und...</td>\n",
       "      <td>[perfect, size, storage, bed, sturdy, holds, w...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>The hardware works very well, and the fact tha...</td>\n",
       "      <td>[the, hardware, works, very, well, and, the, f...</td>\n",
       "      <td>[hardware, works, well, fact, solid, state, hu...</td>\n",
       "      <td>(0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have not had a good camera since my early 20...</td>\n",
       "      <td>[i, have, not, had, a, good, camera, since, my...</td>\n",
       "      <td>[good, camera, since, early, 20, managed, lose...</td>\n",
       "      <td>(0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I had to modify it to fit my machine. I though...</td>\n",
       "      <td>[i, had, to, modify, it, to, fit, my, machine,...</td>\n",
       "      <td>[modify, fit, machine, thought, model, right, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Well &amp;#34;Joe&amp;#34; made it home for the holida...</td>\n",
       "      <td>[well, 34, joe, 34, made, it, home, for, the, ...</td>\n",
       "      <td>[well, 34, joe, 34, made, home, holidays, exac...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The lamp this bulb was installed in died a lon...</td>\n",
       "      <td>[the, lamp, this, bulb, was, installed, in, di...</td>\n",
       "      <td>[lamp, bulb, installed, died, long, time, ago,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I've had these for a few weeks. I absolutely  ...</td>\n",
       "      <td>[i, ve, had, these, for, a, few, weeks, i, abs...</td>\n",
       "      <td>[ve, weeks, absolutely, love, ve, great, resul...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Very nice rich color - slightly reddish, sturd...</td>\n",
       "      <td>[very, nice, rich, color, slightly, reddish, s...</td>\n",
       "      <td>[nice, rich, color, slightly, reddish, sturdy,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  \\\n",
       "0     5.0  This had some assembling but overall it is a g...   \n",
       "1     5.0  We love these markers. They state right on the...   \n",
       "2     5.0  It is the perfect size for storage under a bed...   \n",
       "3     3.0  The hardware works very well, and the fact tha...   \n",
       "4     5.0  I have not had a good camera since my early 20...   \n",
       "5     4.0  I had to modify it to fit my machine. I though...   \n",
       "6     5.0  Well &#34;Joe&#34; made it home for the holida...   \n",
       "7     5.0  The lamp this bulb was installed in died a lon...   \n",
       "8     5.0  I've had these for a few weeks. I absolutely  ...   \n",
       "9     5.0  Very nice rich color - slightly reddish, sturd...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [this, had, some, assembling, but, overall, it...   \n",
       "1  [we, love, these, markers, they, state, right,...   \n",
       "2  [it, is, the, perfect, size, for, storage, und...   \n",
       "3  [the, hardware, works, very, well, and, the, f...   \n",
       "4  [i, have, not, had, a, good, camera, since, my...   \n",
       "5  [i, had, to, modify, it, to, fit, my, machine,...   \n",
       "6  [well, 34, joe, 34, made, it, home, for, the, ...   \n",
       "7  [the, lamp, this, bulb, was, installed, in, di...   \n",
       "8  [i, ve, had, these, for, a, few, weeks, i, abs...   \n",
       "9  [very, nice, rich, color, slightly, reddish, s...   \n",
       "\n",
       "                                        stopWordFree  \\\n",
       "0  [assembling, overall, great, product, youtuber...   \n",
       "1  [love, markers, state, right, package, washabl...   \n",
       "2  [perfect, size, storage, bed, sturdy, holds, w...   \n",
       "3  [hardware, works, well, fact, solid, state, hu...   \n",
       "4  [good, camera, since, early, 20, managed, lose...   \n",
       "5  [modify, fit, machine, thought, model, right, ...   \n",
       "6  [well, 34, joe, 34, made, home, holidays, exac...   \n",
       "7  [lamp, bulb, installed, died, long, time, ago,...   \n",
       "8  [ve, weeks, absolutely, love, ve, great, resul...   \n",
       "9  [nice, rich, color, slightly, reddish, sturdy,...   \n",
       "\n",
       "                                            features  label  \n",
       "0  (0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...    1.0  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...    1.0  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...    1.0  \n",
       "3  (0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, ...    0.0  \n",
       "4  (0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    1.0  \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...    1.0  \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...    1.0  \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...    1.0  \n",
       "8  (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...    1.0  \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...    1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos pasos, ya hemos conseguido tener una columna `features` que será nuestra matriz $X$ de aprendizaje y una columna `label` que es de la que queremos aprender con un modelo de clasificación binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model\n",
    "\n",
    "Esta es la parte donde usaremos modelos de Machine Learning propiamente dicho, con Spark podemos hacer bastantes cosas, desde [modelos supervisados](https://spark.apache.org/docs/latest/ml-classification-regression.html), [clustering](https://spark.apache.org/docs/latest/ml-clustering.html), [sistemas de recomendaciones](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html) y [reglas se asociación](https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html).\n",
    "\n",
    "\n",
    "&nbsp;  \n",
    "&nbsp;  \n",
    "\n",
    "Volviento a nuesto ejemplo, es claro que es un problema supervisado de clasificación (sentimiento positivo o negativo) veamos qué tipo de modelos de clasifación tenemos en Spark:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul id=\"markdown-toc\">\n",
    "  <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#classification\" id=\"markdown-toc-classification\">Classification</a>    <ul>\n",
    "      <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\" id=\"markdown-toc-logistic-regression\">Logistic regression</a>        <ul>\n",
    "          <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression\" id=\"markdown-toc-binomial-logistic-regression\">Binomial logistic regression</a></li>\n",
    "          <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#multinomial-logistic-regression\" id=\"markdown-toc-multinomial-logistic-regression\">Multinomial logistic regression</a></li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier\" id=\"markdown-toc-decision-tree-classifier\">Decision tree classifier</a></li>\n",
    "      <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\" id=\"markdown-toc-random-forest-classifier\">Random forest classifier</a></li>\n",
    "      <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier\" id=\"markdown-toc-gradient-boosted-tree-classifier\">Gradient-boosted tree classifier</a></li>\n",
    "      <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier\" id=\"markdown-toc-multilayer-perceptron-classifier\">Multilayer perceptron classifier</a></li>\n",
    "      <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-support-vector-machine\" id=\"markdown-toc-linear-support-vector-machine\">Linear Support Vector Machine</a></li>\n",
    "      <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#one-vs-rest-classifier-aka-one-vs-all\" id=\"markdown-toc-one-vs-rest-classifier-aka-one-vs-all\">One-vs-Rest classifier (a.k.a. One-vs-All)</a></li>\n",
    "      <li><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#naive-bayes\" id=\"markdown-toc-naive-bayes\">Naive Bayes</a></li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "family: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\n",
      "featuresCol: features column name. (default: features)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "lowerBoundsOnCoefficients: The lower bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\n",
      "lowerBoundsOnIntercepts: The lower bounds on intercepts if fitting under bound constrained optimization. The bounds vector size must beequal with 1 for binomial regression, or the number oflasses for multinomial regression. (undefined)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "threshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "upperBoundsOnCoefficients: The upper bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\n",
      "upperBoundsOnIntercepts: The upper bounds on intercepts if fitting under bound constrained optimization. The bound vector size must be equal with 1 for binomial regression, or the number of classes for multinomial regression. (undefined)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "print(LogisticRegression().explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = LogisticRegression(featuresCol='features', #variable de emtrada\n",
    "                        labelCol = 'label', #variable de salida\n",
    "                        predictionCol='labelCol' #esta colunma sera la de la prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = rl.fit(meta) #si que tiene que hacer fit porque tiene que aprender de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05539396,  1.0620651 ,  0.05371914,  0.21893744,  0.06806565,\n",
       "       -0.25884074,  0.55660344, -0.19275559, -0.02909625, -0.09761498,\n",
       "        1.40608576,  0.25216638, -0.00571913, -0.04102093,  0.0499756 ,\n",
       "        0.83604661,  0.31962407,  0.48671637,  0.18476393, -0.50561418,\n",
       "       -0.2869175 , -0.0235039 ,  0.0129517 ,  0.29153212,  0.08648835,\n",
       "       -0.1861831 ,  0.08382417, -0.10093676,  0.23850552, -0.41111558,\n",
       "       -0.03836653, -0.26403495,  0.06089811, -0.02265092,  0.159968  ,\n",
       "        0.48816559, -0.30278214,  0.04610715,  0.07930039, -0.25221191])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.coefficients[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = modelo.transform(meta.select('label','features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- labelCol: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicciones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------+\n",
      "|label|            features|       rawPrediction|         probability|labelCol|\n",
      "+-----+--------------------+--------------------+--------------------+--------+\n",
      "|  1.0|(1000,[1,3,5,14,3...|[-4.4977676628692...|[0.01101122621757...|     1.0|\n",
      "|  1.0|(1000,[4,10,11,43...|[-6.2386230214074...|[0.00194873728958...|     1.0|\n",
      "|  1.0|(1000,[6,9,54,61,...|[-5.4360796186942...|[0.00433763207075...|     1.0|\n",
      "|  0.0|(1000,[1,4,5,6,7,...|[-3.1958712221916...|[0.03932139197717...|     1.0|\n",
      "|  1.0|(1000,[1,2,3,14,2...|[-12.537692114717...|[3.58878912475756...|     1.0|\n",
      "|  1.0|(1000,[5,32,50,63...|[-0.1369912419279...|[0.46580564877646...|     1.0|\n",
      "|  1.0|(1000,[6,31,33,10...|[-2.5310866697984...|[0.07370742023978...|     1.0|\n",
      "|  1.0|(1000,[6,8,9,15,3...|[-4.0661836642483...|[0.01685376723437...|     1.0|\n",
      "|  1.0|(1000,[1,4,8,10,2...|[-3.4552046131211...|[0.03061402515385...|     1.0|\n",
      "|  1.0|(1000,[5,15,35,42...|[-4.5883826722428...|[0.01006691872124...|     1.0|\n",
      "|  1.0|(1000,[2,3,9,24,2...|[-4.6063907975717...|[0.00988903164715...|     1.0|\n",
      "|  0.0|(1000,[0,25,74,12...|[1.15297881624922...|[0.76005458922257...|     0.0|\n",
      "|  1.0|(1000,[0,1,24,26,...|[-3.4910622222984...|[0.02956761021019...|     1.0|\n",
      "|  1.0|(1000,[1,10,13,21...|[-4.6629075123557...|[0.00935071729980...|     1.0|\n",
      "|  1.0|(1000,[0,41,62,77...|[-1.3635712740227...|[0.20366048972055...|     1.0|\n",
      "|  0.0|(1000,[5,7,8,28,2...|[2.67692217077780...|[0.93565106147163...|     0.0|\n",
      "|  1.0|(1000,[1,7,15,90,...|[-4.2022746604412...|[0.01474095880015...|     1.0|\n",
      "|  1.0|(1000,[3,28,57,84...|[-3.5924097654428...|[0.02679420936098...|     1.0|\n",
      "|  1.0|(1000,[2,10,16,18...|[-0.4293147144808...|[0.39428998328964...|     1.0|\n",
      "|  0.0|(1000,[0,52,66,95...|[0.40794400109612...|[0.60059478657130...|     0.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicciones.show() #el raw no se usa casi nunca, la prob si (debe haber un e^) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fila = predicciones.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-4.4978, 4.4978])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fila['rawPrediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.011, 0.989])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fila['probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fila['labelCol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En muchas ocasiones no está claro qué modelo es el más adecuado, existen algunos \"chuletas\" como la de abajo, pero lo mejor es conocer bien la teoría de los modelos a emplear para no cometer errores de concepto y usar metodologías apropiadas para asegurarse que el modelo está funcionando correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Test data\n",
    "\n",
    "Uno de los procedimientos más importantes a la hora de hacer un ML es comprobar si nuestro modelo funciona correctamente para otros datos con los que no hemos entrenado el modelo, así evitaremos el problema de [sobreajuste o *overfitting*]https://en.wikipedia.org/wiki/Overfitting.\n",
    "\n",
    "Vamos a usar la función [RandomSplit](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit) para dividir nuestro DF en dos partes así usaremos una para entrenar y otroa para evaluar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![trainTest](img/TrainTestSplit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir el DF original en dos partes, volvemos a trabajar con el DF original ya que las transformaciones y extraer las *features* también son partes del modelo y si lo hacemos con todo el DF podemos estar siendo imparciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[rating: double, review: string]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainDF, testDF) = reviewsDF.randomSplit([0.8, 0.2], seed=42)\n",
    "trainDF.cache()\n",
    "testDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros en el DF original: 19959\n",
      "Porcentaje en  train respecto al original: 0.8023448068540509\n",
      "Porcentaje en  test respecto al original: 0.1976551931459492\n"
     ]
    }
   ],
   "source": [
    "n = reviewsDF.count()\n",
    "print(\"Total de registros en el DF original: {}\".format(n))\n",
    "print(\"Porcentaje en  train respecto al original: {}\".format(1.0 * trainDF.count() / n))\n",
    "print(\"Porcentaje en  test respecto al original: {}\".format(1.0 * testDF.count() / n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos de hacer el procesamiento que hemos visto para el dataset de entrenamiento y guradarlo para después realizarlo en el de test o validación y en un futuro en un nuevo dataset que queramos predecir. \n",
    "\n",
    "#### 4.1 Pipelines\n",
    "\n",
    "Como esta tarea puede ser un un poco tediosa Spark ha introducido el concepto de [**Pipeline**](https://spark.apache.org/docs/latest/ml-pipeline.html) (también basado en el de [scikit-learn](http://scikit-learn.org/stable/modules/pipeline.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = (\n",
    "\n",
    "    RegexTokenizer()\n",
    "    .setInputCol(\"review\")\n",
    "    .setOutputCol(\"tokens\")\n",
    "    .setPattern(\"\\\\W+\")\n",
    "\n",
    ")\n",
    "\n",
    "remover = (\n",
    "\n",
    "    StopWordsRemover()\n",
    "    .setInputCol(\"tokens\")\n",
    "    .setOutputCol(\"stopWordFree\")\n",
    "\n",
    ")\n",
    "\n",
    "counts = (\n",
    "    \n",
    "    CountVectorizer()\n",
    "    .setInputCol(\"stopWordFree\")\n",
    "    .setOutputCol(\"features\")\n",
    "    .setVocabSize(1000)\n",
    "\n",
    ")\n",
    "\n",
    "binarizer = (\n",
    "\n",
    "    Binarizer()\n",
    "    .setInputCol(\"rating\")\n",
    "    .setOutputCol(\"label\")\n",
    "    .setThreshold(3.5)\n",
    "\n",
    ")\n",
    "\n",
    "rl = LogisticRegression(featuresCol='features',predictionCol='labelCol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline(stages=[tokenizer, remover, counts, binarizer, rl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_46a0853a885f703674ca"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.pipeline.Pipeline"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora defino/entreno todas las transformaciones a la vez (¡más eficiente!) para los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model = p.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_4cb2a561ec6480c1cd36"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stopWordFree</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>labelCol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"This is gonna be fun\" it says on the box.  Ok...</td>\n",
       "      <td>[this, is, gonna, be, fun, it, says, on, the, ...</td>\n",
       "      <td>[gonna, fun, says, box, okay, goes, people, wo...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.7372801707214243, -2.7372801707214243]</td>\n",
       "      <td>[0.93919094909386, 0.06080905090614005]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2 out of 3 fell apart when played with by my p...</td>\n",
       "      <td>[2, out, of, 3, fell, apart, when, played, wit...</td>\n",
       "      <td>[2, 3, fell, apart, played, puppy, one, create...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.3529490111555629, -1.3529490111555629]</td>\n",
       "      <td>[0.7946113372529741, 0.20538866274702589]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3 months, all does not work, do not give refun...</td>\n",
       "      <td>[3, months, all, does, not, work, do, not, giv...</td>\n",
       "      <td>[3, months, work, give, refunds, hateful, 34, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.6048582604573204, 0.6048582604573204]</td>\n",
       "      <td>[0.3532329885055081, 0.6467670114944919]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>50 cent is the most garbage rapper ever period...</td>\n",
       "      <td>[50, cent, is, the, most, garbage, rapper, eve...</td>\n",
       "      <td>[50, cent, garbage, rapper, ever, period, poet...</td>\n",
       "      <td>(1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.44672777499593347, 0.44672777499593347]</td>\n",
       "      <td>[0.3901390479363134, 0.6098609520636867]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  \\\n",
       "0     1.0  \"This is gonna be fun\" it says on the box.  Ok...   \n",
       "1     1.0  2 out of 3 fell apart when played with by my p...   \n",
       "2     1.0  3 months, all does not work, do not give refun...   \n",
       "3     1.0  50 cent is the most garbage rapper ever period...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [this, is, gonna, be, fun, it, says, on, the, ...   \n",
       "1  [2, out, of, 3, fell, apart, when, played, wit...   \n",
       "2  [3, months, all, does, not, work, do, not, giv...   \n",
       "3  [50, cent, is, the, most, garbage, rapper, eve...   \n",
       "\n",
       "                                        stopWordFree  \\\n",
       "0  [gonna, fun, says, box, okay, goes, people, wo...   \n",
       "1  [2, 3, fell, apart, played, puppy, one, create...   \n",
       "2  [3, months, work, give, refunds, hateful, 34, ...   \n",
       "3  [50, cent, garbage, rapper, ever, period, poet...   \n",
       "\n",
       "                                            features  label  \\\n",
       "0  (1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "1  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "3  (1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "\n",
       "                                 rawPrediction  \\\n",
       "0    [2.7372801707214243, -2.7372801707214243]   \n",
       "1    [1.3529490111555629, -1.3529490111555629]   \n",
       "2    [-0.6048582604573204, 0.6048582604573204]   \n",
       "3  [-0.44672777499593347, 0.44672777499593347]   \n",
       "\n",
       "                                 probability  labelCol  \n",
       "0    [0.93919094909386, 0.06080905090614005]       0.0  \n",
       "1  [0.7946113372529741, 0.20538866274702589]       0.0  \n",
       "2   [0.3532329885055081, 0.6467670114944919]       1.0  \n",
       "3   [0.3901390479363134, 0.6098609520636867]       1.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_model.transform(trainDF).limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo ahora hacer la misma tranformación o \"predecir\" sobre el otro dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stopWordFree</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>labelCol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>... which should have been the principal desig...</td>\n",
       "      <td>[which, should, have, been, the, principal, de...</td>\n",
       "      <td>[principal, design, goal, close, enough, appea...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5.2669429507596135, -5.2669429507596135]</td>\n",
       "      <td>[0.9948671234490613, 0.005132876550938797]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>...if you are looking for a way to get that St...</td>\n",
       "      <td>[if, you, are, looking, for, a, way, to, get, ...</td>\n",
       "      <td>[looking, way, get, starbucks, pumpkin, spice,...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.25453802784203483, -0.25453802784203483]</td>\n",
       "      <td>[0.5632931472183439, 0.4367068527816561]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1. It won't connect wirelessly;2. It makes alm...</td>\n",
       "      <td>[1, it, won, t, connect, wirelessly, 2, it, ma...</td>\n",
       "      <td>[1, won, connect, wirelessly, 2, makes, almost...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.202556320948331, -2.202556320948331]</td>\n",
       "      <td>[0.9004788345814635, 0.09952116541853658]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A wheel is broken.  The pouch inside has compl...</td>\n",
       "      <td>[a, wheel, is, broken, the, pouch, inside, has...</td>\n",
       "      <td>[wheel, broken, pouch, inside, completely, rip...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.2959415564212704, -0.2959415564212704]</td>\n",
       "      <td>[0.5734500980781883, 0.4265499019218117]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review  \\\n",
       "0     1.0  ... which should have been the principal desig...   \n",
       "1     1.0  ...if you are looking for a way to get that St...   \n",
       "2     1.0  1. It won't connect wirelessly;2. It makes alm...   \n",
       "3     1.0  A wheel is broken.  The pouch inside has compl...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [which, should, have, been, the, principal, de...   \n",
       "1  [if, you, are, looking, for, a, way, to, get, ...   \n",
       "2  [1, it, won, t, connect, wirelessly, 2, it, ma...   \n",
       "3  [a, wheel, is, broken, the, pouch, inside, has...   \n",
       "\n",
       "                                        stopWordFree  \\\n",
       "0  [principal, design, goal, close, enough, appea...   \n",
       "1  [looking, way, get, starbucks, pumpkin, spice,...   \n",
       "2  [1, won, connect, wirelessly, 2, makes, almost...   \n",
       "3  [wheel, broken, pouch, inside, completely, rip...   \n",
       "\n",
       "                                            features  label  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...    0.0   \n",
       "1  (0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...    0.0   \n",
       "2  (0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...    0.0   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "\n",
       "                                 rawPrediction  \\\n",
       "0    [5.2669429507596135, -5.2669429507596135]   \n",
       "1  [0.25453802784203483, -0.25453802784203483]   \n",
       "2      [2.202556320948331, -2.202556320948331]   \n",
       "3    [0.2959415564212704, -0.2959415564212704]   \n",
       "\n",
       "                                  probability  labelCol  \n",
       "0  [0.9948671234490613, 0.005132876550938797]       0.0  \n",
       "1    [0.5632931472183439, 0.4367068527816561]       0.0  \n",
       "2   [0.9004788345814635, 0.09952116541853658]       0.0  \n",
       "3    [0.5734500980781883, 0.4265499019218117]       0.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = p_model.transform(testDF)\n",
    "result.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a las *pipelines* nos es muy fácil reutilizar las transformaciones y modelos para nuevos DF, es hora de evaluar nuestro modelo con la muestra de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de nuestro objeto de tipo `PipelineModel` tenemos toda la información de los subprocesos que hace, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RegexTokenizer_41a2a63d0d56a3b63867,\n",
       " StopWordsRemover_421f94af7b1e8ff2543e,\n",
       " CountVectorizer_43cab63f5c67deb279c1,\n",
       " Binarizer_49c5be7c8fb01447d01a,\n",
       " LogisticRegression_484198cd1fbeb850d14f]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['one', 'great', 'like', 'good', 'use', 'product', 'well', 'get',\n",
       "       'time', 'really', 'love', 'little', 'much', 'also', 'price',\n",
       "       'bought', 'easy', 'works', 'used', 'work', 'even', '2', 'quality',\n",
       "       've', 'm', 'buy', 'first', 'better', 'back', 'using', 'got', '34',\n",
       "       'made', 'recommend', 'still', 'nice', 'two', 'make', 'case', '3',\n",
       "       'put', 'need', 'new', 'way', 'old', 'go', 'best', 'phone', 'small',\n",
       "       'fit', '5', 'day', 'long', '1', 'years', 'perfect', 'didn', 'set',\n",
       "       'see', 'enough', 'doesn', 'think', 'right', 'thing', 'around',\n",
       "       'another', 'since', 'want', 'find', 'light', 'never', '4',\n",
       "       'amazon', 'bit', 'water', 'many', 'sure', 'lot', 'take', 'every',\n",
       "       'without', 'know', 'year', 'say', 'look', 'last', 'hair',\n",
       "       'purchased', 'far', 'looking', 'keep', 'size', 're', 'pretty',\n",
       "       'came', 'found', 'money', 'however', 'makes', 'looks'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(p_model.stages[2].vocabulary)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hacemos al *stage* del modelo, podemos encontrar la curva ROC para evaluar cómo está funcionando el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090491693408799"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = p_model.stages[-1].summary.areaUnderROC\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc = p_model.stages[-1].summary.roc.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.026140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.039128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.052197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FPR       TPR\n",
       "0  0.000000  0.000000\n",
       "1  0.000000  0.013151\n",
       "2  0.000265  0.026140\n",
       "3  0.000530  0.039128\n",
       "4  0.000530  0.052197"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "df_roc.plot('FPR','TPR', color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero como sabemos, es mejor evaluar el modelo sobre el dataset de test que hemos preparado, para ello podemos usar la función [`BinaryClassificationEvaluator`](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.BinaryClassificationEvaluator) para calcular la curva ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8507633299256857\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"AUC: {}\".format(evaluator.evaluate(result))) #result era lo que daba el modelo en el conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo era de esperar baja un poco el valor del área bajo la curva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Logistic-Regression_answers",
  "notebookId": 1355896319138518
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
