{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> Dataframe: A fondo </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/lrg.jpg)\n",
    "\n",
    "&nbsp;   \n",
    "\n",
    "\n",
    "Vamos a ver con más detalle qué podemos hacer con la API `DataFrame` de spark. Dos buenas referencias son la [documentación oficial](https://spark.apache.org/docs/latest/sql-programming-guide.html) y el libro [*Learning Spark*](http://shop.oreilly.com/product/0636920028512.do)\n",
    "\n",
    "\n",
    "Empezamos iniciando la sesión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "\n",
    "    SparkConf()\n",
    "    .setAppName(u\"[ICAI] DataFrame: A fondo\")\n",
    "    .set(\"spark.jars\",\"/var/lib/sqoop/mysql-connector-java-5.1.44-bin.jar\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD vs Dataframe\n",
    "\n",
    "En el anterior sesión vimos que trabajar con `DataFrames` es en general más rápido que trabajar con RDD (y  más sobre todo si trabajamos con *Pyspark*, pero ¿Por qué?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/dataframe.png)\n",
    "<center>\n",
    "    https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Básicamente al trabajar con datos estructurados se puede usar compresores específicos para los tipos normales de una tabla y además se puede saber qué se está haciendo en cada operación y se pude preeveer el resultado final de cada operación, en spark hay dos proyectos que hacen esto posible:\n",
    "\n",
    "* **Project Tungsten**: https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html\n",
    "* **Spark SQL’s Catalyst Optimizer**: https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/catalyst.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con  RDDs y DFs\n",
    "\n",
    "Podemos convertir de `RDD` a `DadaFrame` y viceversa con gran facilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.sparkContext.textFile(\"/datos/people.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Michael, 29', 'Andy, 30', 'Justin, 19']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = lines.map(lambda l: l.split(\",\")) #Lo dividimos por comas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de RDD a DF:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos `Row` para definir los registros del RDD como estructurados (filas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = parts.map(lambda p: Row(name=p[0], age=int(p[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=29, name='Michael'),\n",
       " Row(age=30, name='Andy'),\n",
       " Row(age=19, name='Justin')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.take(4) #AUN ES UN RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaPeople = people.toDF() #ESTO MAS LO DE ROW LO PASA A DARA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 29|Michael|\n",
      "| 30|   Andy|\n",
      "| 19| Justin|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de DF A RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teenagers =  schemaPeople.filter('age between 13 and 19').select('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "|Justin|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teenagers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `.rdd` obtenemos el RDD que hay dentro del DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teenNames = teenagers.rdd.map(lambda p: \"Name: \" + p.name).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Justin\n"
     ]
    }
   ],
   "source": [
    "for name in teenNames:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones\n",
    "\n",
    "![](img/relation-not-function.gif)\n",
    "\n",
    "Dentro de la API de `DataFrame` hay multitud de funciones que podemos usar para nuestros análisis. Podemos ver todas ellas en la [documetanción](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions).\n",
    "\n",
    "Veremos algunos ejemplos basados en siguiente artículo de Databricks:\n",
    "https://databricks.com/blog/2015/06/02/statistical-and-mathematical-functions-with-dataframes-in-spark.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. Random Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F.rand da numeros aleatorios entre 0 y 1, F.randn da normales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"id\", F.rand(seed=10).alias(\"uniform\"), F.randn(seed=27).alias(\"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+--------------------+\n",
      "| id|            uniform|              normal|\n",
      "+---+-------------------+--------------------+\n",
      "|  0|0.41371264720975787|  0.5888539012978773|\n",
      "|  1| 0.7311719281896606|  0.8645537008427937|\n",
      "|  2| 0.9031701155118229|  1.2524569684217643|\n",
      "|  3|0.09430205113458567|  -2.573636861034734|\n",
      "|  4|0.38340505276222947|  0.5469737451926588|\n",
      "|  5| 0.1982919638208397| 0.06157382353970104|\n",
      "|  6|0.12714181165849525|  0.3623040918178586|\n",
      "|  7| 0.7604318153406678|-0.49575204523675975|\n",
      "|  8|   0.83487085888236|   1.022815424084479|\n",
      "|  9| 0.3142596916968412|   2.750429557170309|\n",
      "+---+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Summary and Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+\n",
      "|summary|                id|            uniform|            normal|\n",
      "+-------+------------------+-------------------+------------------+\n",
      "|  count|                10|                 10|                10|\n",
      "|   mean|               4.5| 0.4760757936207261|0.4380572306095948|\n",
      "| stddev|3.0276503540974917| 0.3055791028722139|1.3604956570524473|\n",
      "|    min|                 0|0.09430205113458567|-2.573636861034734|\n",
      "|    max|                 9| 0.9031701155118229| 2.750429557170309|\n",
      "+-------+------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|summary|            uniform|            normal|\n",
      "+-------+-------------------+------------------+\n",
      "|  count|                 10|                10|\n",
      "|   mean| 0.4760757936207261|0.4380572306095948|\n",
      "| stddev| 0.3055791028722139|1.3604956570524473|\n",
      "|    min|0.09430205113458567|-2.573636861034734|\n",
      "|    max| 0.9031701155118229| 2.750429557170309|\n",
      "+-------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('uniform', 'normal').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimo, maximo, media por fila si lo ponemos o de todo el df si no ponemos fila:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------------------+\n",
      "|      avg(uniform)|       min(uniform)|      max(uniform)|\n",
      "+------------------+-------------------+------------------+\n",
      "|0.4760757936207261|0.09430205113458567|0.9031701155118229|\n",
      "+------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " df.select(F.mean('uniform'), F.min('uniform'), F.max('uniform')).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En muchas ocasiones, es adecuado renombrar la nueva columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------------------+\n",
      "|             media|             minimo|            maximo|\n",
      "+------------------+-------------------+------------------+\n",
      "|0.4760757936207261|0.09430205113458567|0.9031701155118229|\n",
      "+------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ALIAS PARA RENOMBRAR \n",
    "df.select(\n",
    "\n",
    "     F.mean('uniform').alias(\"media\"),\n",
    "     F.min('uniform').alias(\"minimo\"),\n",
    "     F.max('uniform').alias(\"maximo\")\n",
    "\n",
    " ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Sample covariance and correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*withColumn crea una columna y si existe la sobre-escribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "\n",
    "    spark.range(0, 10)\n",
    "    .withColumn('rand1', F.rand(seed=10))\n",
    "    .withColumn('rand2', F.rand(seed=27))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05983805032757693"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.cov('rand1', 'rand2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.166666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.cov('id', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6397807763656534"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.corr('rand1', 'rand2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.corr('id', 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Cross Tabulation (Contingency Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with two columns (name, item)\n",
    "names = [\"Alice\", \"Bob\", \"Mike\"]\n",
    "items = [\"milk\", \"bread\", \"butter\", \"apples\", \"oranges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pares = [(names[i % 3], items[i % 5]) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alice', 'milk'),\n",
       " ('Bob', 'bread'),\n",
       " ('Mike', 'butter'),\n",
       " ('Alice', 'apples'),\n",
       " ('Bob', 'oranges')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pares[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pares,[\"name\", \"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "| name|   item|\n",
      "+-----+-------+\n",
      "|Alice|   milk|\n",
      "|  Bob|  bread|\n",
      "| Mike| butter|\n",
      "|Alice| apples|\n",
      "|  Bob|oranges|\n",
      "+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crosstab = TABLA DE CONTEO DE 2 dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+------+----+-------+\n",
      "|name_item|apples|bread|butter|milk|oranges|\n",
      "+---------+------+-----+------+----+-------+\n",
      "|      Bob|     6|    7|     7|   6|      7|\n",
      "|     Mike|     7|    6|     7|   7|      6|\n",
      "|    Alice|     7|    7|     6|   7|      7|\n",
      "+---------+------+-----+------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.crosstab(\"name\", \"item\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Frequent Items (parecido a crosstab pero por parejas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(1, 2, 3) if i % 2 == 0 else (i, 2 * i, i % 4) for i in range(100)],\n",
    "    [\"a\", \"b\", \"c\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  a|  b|  c|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "|  1|  2|  1|\n",
      "|  1|  2|  3|\n",
      "|  3|  6|  3|\n",
      "|  1|  2|  3|\n",
      "+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = df.stat.freqItems([\"a\", \"b\", \"c\"], 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+\n",
      "|a_freqItems|b_freqItems|c_freqItems|\n",
      "+-----------+-----------+-----------+\n",
      "|    [1, 99]|   [2, 198]|     [1, 3]|\n",
      "+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "freq.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Mathematical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(0, 10).withColumn('uniform', F.rand(seed=10) * 3.14) #creamos una dummy df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|            uniform|\n",
      "+---+-------------------+\n",
      "|  0| 1.2990577122386398|\n",
      "|  1| 2.2958798545155346|\n",
      "|  2|  2.835954162707124|\n",
      "|  3|0.29610844056259905|\n",
      "|  4| 1.2038918656734006|\n",
      "|  5| 0.6226367663974367|\n",
      "|  6| 0.3992252886076751|\n",
      "|  7| 2.3877559001696973|\n",
      "|  8| 2.6214944968906106|\n",
      "|  9| 0.9867754319280814|\n",
      "+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+\n",
      "|            uniform|  DEGREES(uniform)|     cos^2 + sin^2|\n",
      "+-------------------+------------------+------------------+\n",
      "| 1.2990577122386398| 74.43052425519424|               1.0|\n",
      "| 2.2958798545155346| 131.5442259328496|               1.0|\n",
      "|  2.835954162707124|162.48820441567537|0.9999999999999999|\n",
      "|0.29610844056259905| 16.96576392243732|0.9999999999999999|\n",
      "| 1.2038918656734006| 68.97792289321647|               1.0|\n",
      "| 0.6226367663974367| 35.67445888424608|0.9999999999999999|\n",
      "| 0.3992252886076751|22.873924112112007|               1.0|\n",
      "| 2.3877559001696973| 136.8083355871844|               1.0|\n",
      "| 2.6214944968906106| 150.2005706886031|               1.0|\n",
      "| 0.9867754319280814|56.538067576677925|               1.0|\n",
      "+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        'uniform',\n",
    "        # Convertir en grados\n",
    "        F.toDegrees('uniform'),\n",
    "        (\n",
    "\n",
    "            # cos^2(x)\n",
    "            F.pow(F.cos(df['uniform']), 2) + \n",
    "\n",
    "            # sin^2(x)\n",
    "            F.pow(F.sin(df.uniform), 2)\n",
    "\n",
    "        ).alias(\"cos^2 + sin^2\")\n",
    "    )\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinar DataFrames\n",
    "\n",
    "![](img/join-types.png)\n",
    "\n",
    "Podemos distinguir dos manearas de combinar dos `DF`:\n",
    "\n",
    "* **`union`**: Muy simple, los dos `DF`tienen que tener el mismo número de columnas y se combinan simplemente poniendo uno encima de otro. Similar al `UNION ALL` de *SQL* o al `rbind` de *R*.\n",
    "\n",
    "\n",
    "* **`join`**: Nos permite cruzar información de dos `DF` por una o más condiciones sobre sus columnas.\n",
    "\n",
    "\n",
    "Veamos algunos ejemplos de la versatilidad de `join`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "empleados = spark.createDataFrame([\n",
    "\n",
    "    (\"Rafferty\", 31),\n",
    "    (\"Jones\", 33),\n",
    "    (\"Heisenberg\", 33),\n",
    "    (\"Robinson\", 34),\n",
    "    (\"Smith\", 34),\n",
    "    (\"Williams\", None)\n",
    "\n",
    "],schema=[\"LastName\", \"DepartmentID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "departamentos = spark.createDataFrame([\n",
    "\n",
    "    (31, \"Sales\"), \n",
    "    (33, \"Engineering\"), \n",
    "    (34, \"Clerical\"),\n",
    "    (35, \"Marketing\")\n",
    "\n",
    "],schema=[\"DepartmentID\", \"DepartmentName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|  LastName|DepartmentID|\n",
      "+----------+------------+\n",
      "|  Rafferty|          31|\n",
      "|     Jones|          33|\n",
      "|Heisenberg|          33|\n",
      "|  Robinson|          34|\n",
      "|     Smith|          34|\n",
      "|  Williams|        null|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empleados.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|DepartmentID|DepartmentName|\n",
      "+------------+--------------+\n",
      "|          31|         Sales|\n",
      "|          33|   Engineering|\n",
      "|          34|      Clerical|\n",
      "|          35|     Marketing|\n",
      "+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departamentos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------+\n",
      "|DepartmentID|  LastName|DepartmentName|\n",
      "+------------+----------+--------------+\n",
      "|          34|  Robinson|      Clerical|\n",
      "|          34|     Smith|      Clerical|\n",
      "|          31|  Rafferty|         Sales|\n",
      "|          33|     Jones|   Engineering|\n",
      "|          33|Heisenberg|   Engineering|\n",
      "+------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    empleados\n",
    "    .join(departamentos,'DepartmentID') #POR DEFECTO HACE INNER JOIN\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------+\n",
      "|DepartmentID|  LastName|DepartmentName|\n",
      "+------------+----------+--------------+\n",
      "|          34|  Robinson|      Clerical|\n",
      "|          34|     Smith|      Clerical|\n",
      "|          31|  Rafferty|         Sales|\n",
      "|        null|  Williams|          null|\n",
      "|          33|     Jones|   Engineering|\n",
      "|          33|Heisenberg|   Engineering|\n",
      "+------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    empleados\n",
    "    .join(departamentos,'DepartmentID','left') #LEFT\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------+\n",
      "|DepartmentID|  LastName|DepartmentName|\n",
      "+------------+----------+--------------+\n",
      "|          34|  Robinson|      Clerical|\n",
      "|          34|     Smith|      Clerical|\n",
      "|          31|  Rafferty|         Sales|\n",
      "|        null|  Williams|          null|\n",
      "|          33|     Jones|   Engineering|\n",
      "|          33|Heisenberg|   Engineering|\n",
      "|          35|      null|     Marketing|\n",
      "+------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    empleados\n",
    "    .join(departamentos,'DepartmentID','full') #FULL\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+--------------+\n",
      "|  LastName|DepartmentID|DepartmentID|DepartmentName|\n",
      "+----------+------------+------------+--------------+\n",
      "|  Rafferty|          31|          31|         Sales|\n",
      "|  Rafferty|          31|          33|   Engineering|\n",
      "|     Jones|          33|          31|         Sales|\n",
      "|     Jones|          33|          33|   Engineering|\n",
      "|Heisenberg|          33|          31|         Sales|\n",
      "|Heisenberg|          33|          33|   Engineering|\n",
      "|  Rafferty|          31|          34|      Clerical|\n",
      "|  Rafferty|          31|          35|     Marketing|\n",
      "|     Jones|          33|          34|      Clerical|\n",
      "|     Jones|          33|          35|     Marketing|\n",
      "|Heisenberg|          33|          34|      Clerical|\n",
      "|Heisenberg|          33|          35|     Marketing|\n",
      "|  Robinson|          34|          31|         Sales|\n",
      "|  Robinson|          34|          33|   Engineering|\n",
      "|     Smith|          34|          31|         Sales|\n",
      "|     Smith|          34|          33|   Engineering|\n",
      "|  Williams|        null|          31|         Sales|\n",
      "|  Williams|        null|          33|   Engineering|\n",
      "|  Robinson|          34|          34|      Clerical|\n",
      "|  Robinson|          34|          35|     Marketing|\n",
      "+----------+------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    empleados\n",
    "    .crossJoin(departamentos)\n",
    "    \n",
    "\n",
    ").show()\n",
    "#intentar evitar que dos columnas se llamen igua!!! \n",
    "    #si no al seleccionar nos da pronlemas\n",
    "    #.crossJoin(departamentos.withColumnRename()) - mirar online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasa si hay duplicados en la clave de cruce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "departamentos2 = spark.createDataFrame([\n",
    "\n",
    "    (31, \"Sales\"), \n",
    "    (33, \"Engineering\"), \n",
    "    (34, \"Clerical\"),\n",
    "    (35, \"Marketing\"),\n",
    "    (31, \"Ventas\"),\n",
    "\n",
    "],schema=[\"DepartmentID\", \"DepartmentName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------+\n",
      "|DepartmentID|  LastName|DepartmentName|\n",
      "+------------+----------+--------------+\n",
      "|          34|  Robinson|      Clerical|\n",
      "|          34|     Smith|      Clerical|\n",
      "|          31|  Rafferty|         Sales|\n",
      "|          31|  Rafferty|        Ventas|\n",
      "|          33|     Jones|   Engineering|\n",
      "|          33|Heisenberg|   Engineering|\n",
      "+------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    empleados\n",
    "    .join(departamentos2,'DepartmentID')\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, veamos como la condición del `join` puede ser mucho más compleja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "productos = spark.createDataFrame([\n",
    "\n",
    "  (\"steak\", \"1990-01-01\", \"2000-01-01\", 150),\n",
    "  (\"steak\", \"2000-01-02\", \"2020-01-01\", 180),\n",
    "  (\"fish\", \"1990-01-01\", \"2020-01-01\", 100)\n",
    "\n",
    "],schema=[\"name\", \"startDate\", \"endDate\", \"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedidos = spark.createDataFrame([\n",
    "\n",
    "  (\"1995-01-01\", \"steak\"),\n",
    "  (\"2000-01-01\", \"fish\"),\n",
    "  (\"2005-01-01\", \"steak\")\n",
    "\n",
    "],schema=[\"date\", \"product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+----------+----------+-----+\n",
      "|      date|product| name| startDate|   endDate|price|\n",
      "+----------+-------+-----+----------+----------+-----+\n",
      "|1995-01-01|  steak|steak|1990-01-01|2000-01-01|  150|\n",
      "|2005-01-01|  steak|steak|2000-01-02|2020-01-01|  180|\n",
      "|2000-01-01|   fish| fish|1990-01-01|2020-01-01|  100|\n",
      "+----------+-------+-----+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#JOIN MUY COMPLEJO QUE SOLO SE HACE CUANDO LA SENTENCIA ES TRUE\n",
    "(\n",
    "\n",
    "    pedidos\n",
    "    .join(\n",
    "        productos,\n",
    "        ( F.col('product') == F.col('name') ) &\n",
    "        ( F.col('date') >= F.col('startDate') ) &\n",
    "        ( F.col('date') <= F.col('endDate') )    \n",
    "    )\n",
    "  \n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregaciones\n",
    "\n",
    "Ya hemos visto el commando `groupBy` que nos sirve para agregar por ciertas columnas. Veremos algunos ejemplos de qué podemos hacer agrupando por columnas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Como definir un esquema a mano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "esquema = T.StructType([\n",
    "\n",
    "    T.StructField(\"carat\",T.DoubleType()),\n",
    "    T.StructField(\"cut\",T.StringType()),\n",
    "    T.StructField(\"color\",T.StringType()),\n",
    "    T.StructField(\"clarity\",T.StringType()),\n",
    "    T.StructField(\"depth\",T.DoubleType()),\n",
    "    T.StructField(\"table\",T.DoubleType()),\n",
    "    T.StructField(\"price\",T.IntegerType()),\n",
    "    T.StructField(\"x\",T.DoubleType()),\n",
    "    T.StructField(\"y\",T.DoubleType()),\n",
    "    T.StructField(\"z\",T.DoubleType()),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a cargar el dataset `diamonds.csv` en este caso ya damos el esquema definido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = (\n",
    "    \n",
    "    spark.read\n",
    "    .options(header=True)\n",
    "    .schema(esquema) ##AQUI LO PONEMOS EL ESQUEMA\n",
    "    .csv('/datos/diamonds.csv')\n",
    "\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- carat: double (nullable = true)\n",
      " |-- cut: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- clarity: string (nullable = true)\n",
      " |-- depth: double (nullable = true)\n",
      " |-- table: double (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      cut|count|\n",
      "+---------+-----+\n",
      "|  Premium|13791|\n",
      "|    Ideal|21551|\n",
      "|     Good| 4906|\n",
      "|     Fair| 1610|\n",
      "|Very Good|12082|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.groupBy(\"cut\").count().show() #group by y luego count/sum/agg(cualquier funcion de tipo agregacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Por defecto el group by no ordena por nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|      cut|conteo|\n",
      "+---------+------+\n",
      "|  Premium| 13791|\n",
      "|    Ideal| 21551|\n",
      "|     Good|  4906|\n",
      "|     Fair|  1610|\n",
      "|Very Good| 12082|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.groupBy(\"cut\").agg(F.count(\"*\").alias(\"conteo\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diamonds.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `agg` Podemos crear varias columnas en la misma agrupación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diamonds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0a90f1d3b546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m agregado = (\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdiamonds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cut\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     .agg(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'diamonds' is not defined"
     ]
    }
   ],
   "source": [
    "agregado = (\n",
    "\n",
    "    diamonds\n",
    "    .groupBy(\"cut\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"conteo\"),\n",
    "        F.sum('x').alias(\"x\"),\n",
    "        F.sum('y').alias(\"y\"),\n",
    "        F.sum('z').alias(\"z\"),\n",
    "        F.mean('price').alias('media'),\n",
    "        F.collect_set('clarity').alias('clarity') #COLLECT SET METE TODOS LOS VALORES DISTINTOS EN UNA LISTA\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agregadp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-53dc7499b33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magregadp\u001b[0m \u001b[0;31m#AUNQUE NO HAY HECHO NADA SABE QUE TIPO VA A RESULTAR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'agregadp' is not defined"
     ]
    }
   ],
   "source": [
    "agregadp #AUNQUE NO HAY HECHO NADA SABE QUE TIPO VA A RESULTAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>conteo</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>media</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Premium</td>\n",
       "      <td>13791</td>\n",
       "      <td>82385.88</td>\n",
       "      <td>82385.88</td>\n",
       "      <td>82385.88</td>\n",
       "      <td>4584.257704</td>\n",
       "      <td>[VS2, SI2, IF, VS1, VVS2, VVS1, I1, SI1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>21551</td>\n",
       "      <td>118691.07</td>\n",
       "      <td>118691.07</td>\n",
       "      <td>118691.07</td>\n",
       "      <td>3457.541970</td>\n",
       "      <td>[VS2, SI2, IF, VS1, VVS2, VVS1, I1, SI1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>4906</td>\n",
       "      <td>28645.08</td>\n",
       "      <td>28645.08</td>\n",
       "      <td>28645.08</td>\n",
       "      <td>3928.864452</td>\n",
       "      <td>[VS2, SI2, IF, VS1, VVS2, VVS1, I1, SI1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1610</td>\n",
       "      <td>10057.50</td>\n",
       "      <td>10057.50</td>\n",
       "      <td>10057.50</td>\n",
       "      <td>4358.757764</td>\n",
       "      <td>[SI1, SI2, IF, VS1, VVS2, VVS1, I1, VS2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>12082</td>\n",
       "      <td>69359.09</td>\n",
       "      <td>69359.09</td>\n",
       "      <td>69359.09</td>\n",
       "      <td>3981.759891</td>\n",
       "      <td>[VS2, SI2, IF, VS1, VVS2, VVS1, I1, SI1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cut  conteo          x          y          z        media  \\\n",
       "0    Premium   13791   82385.88   82385.88   82385.88  4584.257704   \n",
       "1      Ideal   21551  118691.07  118691.07  118691.07  3457.541970   \n",
       "2       Good    4906   28645.08   28645.08   28645.08  3928.864452   \n",
       "3       Fair    1610   10057.50   10057.50   10057.50  4358.757764   \n",
       "4  Very Good   12082   69359.09   69359.09   69359.09  3981.759891   \n",
       "\n",
       "                                    clarity  \n",
       "0  [VS2, SI2, IF, VS1, VVS2, VVS1, I1, SI1]  \n",
       "1  [VS2, SI2, IF, VS1, VVS2, VVS1, I1, SI1]  \n",
       "2  [VS2, SI2, IF, VS1, VVS2, VVS1, I1, SI1]  \n",
       "3  [SI1, SI2, IF, VS1, VVS2, VVS1, I1, VS2]  \n",
       "4  [VS2, SI2, IF, VS1, VVS2, VVS1, I1, SI1]  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agregado.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[carat: double, cut: string, color: string, clarity: string, depth: double, table: double, price: int, x: double, y: double, z: double]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Ventanas-Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/windows.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Las funciones de tipo [*ventana*](https://en.wikipedia.org/wiki/SQL_window_function) nos permite hacer operaciones analíticas más complejas y usar información de otros registros. Veamos algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "productRevenue = spark.read.load('/datos/productRevenue.parquet').cache() #PARQUE YA LLEVA DENTRO EL ESQUEMA\n",
    "        #EL ESQUEMA VIENE DENTRO DEL ARCHIVO\n",
    "        #ADEMAS ES DE TIPO COLUMNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productRevenue.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+\n",
      "|   product|  category|revenue|\n",
      "+----------+----------+-------+\n",
      "|      Thin|Cell phone|   6000|\n",
      "|    Normal|    Tablet|   1500|\n",
      "|      Mini|    Tablet|   5500|\n",
      "|Ultra Thin|Cell phone|   5000|\n",
      "| Very Thin|Cell phone|   6000|\n",
      "|       Big|    Tablet|   2500|\n",
      "|  Bendable|Cell phone|   3000|\n",
      "|  Foldable|Cell phone|   3000|\n",
      "|       Pro|    Tablet|   4500|\n",
      "|      Pro2|    Tablet|   6500|\n",
      "+----------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "productRevenue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos calcular:\n",
    "\n",
    "* La difrencia entre el mayor ingreso de la categoría y el actual.\n",
    "* El puesto (1º,2º,...) a nivel de ingresos para cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Window crea una columna cn el mismo numero de entradas pero haciendo funciones por agrupados. Como un groupby pero mostrando todo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-----------+------------------+\n",
      "|   product|  category|revenue|revenue_max|revenue_difference|\n",
      "+----------+----------+-------+-----------+------------------+\n",
      "|      Thin|Cell phone|   6000|       6000|                 0|\n",
      "|Ultra Thin|Cell phone|   5000|       6000|              1000|\n",
      "| Very Thin|Cell phone|   6000|       6000|                 0|\n",
      "|  Bendable|Cell phone|   3000|       6000|              3000|\n",
      "|  Foldable|Cell phone|   3000|       6000|              3000|\n",
      "|    Normal|    Tablet|   1500|       6500|              5000|\n",
      "|      Mini|    Tablet|   5500|       6500|              1000|\n",
      "|       Big|    Tablet|   2500|       6500|              4000|\n",
      "|       Pro|    Tablet|   4500|       6500|              2000|\n",
      "|      Pro2|    Tablet|   6500|       6500|                 0|\n",
      "+----------+----------+-------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    productRevenue\n",
    "    .withColumn(\n",
    "        \"revenue_max\",\n",
    "        F.max('revenue').over(Window.partitionBy('category')) #DAR EL MAXIMO REV PARTICIONADO POR CATEGORIA \n",
    "    )\n",
    "    .withColumn(\"revenue_difference\", F.col('revenue_max') - F.col('revenue'))\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de las funciones que ya hemos visto, también podemos usar las siguientes funciones sobre una ventana:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td></td>\n",
    "<td><strong>SQL</strong></td>\n",
    "<td><strong>DataFrame API</strong></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"5\"><strong>Ranking functions</strong></td>\n",
    "<td>rank</td>\n",
    "<td>rank</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>dense_rank</td>\n",
    "<td>denseRank</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>percent_rank</td>\n",
    "<td>percentRank</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>ntile</td>\n",
    "<td>ntile</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>row_number</td>\n",
    "<td>rowNumber</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"5\"><strong>Analytic functions</strong></td>\n",
    "<td>cume_dist</td>\n",
    "<td>cumeDist</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>first_value</td>\n",
    "<td>firstValue</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>last_value</td>\n",
    "<td>lastValue</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>lag</td>\n",
    "<td>lag</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>lead</td>\n",
    "<td>lead</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos ahora el ranqueo pedido:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferencia entre rank y frank:\n",
    "- Rank te empata si hay empates (1,1,3...)\n",
    "- DenseRank si hay empate no salta (1,1,2...)\n",
    "- row_number (1,2,3...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-------+-------------+----------+\n",
      "|   product|  category|revenue|ranking|dense_ranking|row_number|\n",
      "+----------+----------+-------+-------+-------------+----------+\n",
      "|      Thin|Cell phone|   6000|      1|            1|         1|\n",
      "| Very Thin|Cell phone|   6000|      1|            1|         2|\n",
      "|Ultra Thin|Cell phone|   5000|      3|            2|         3|\n",
      "|  Bendable|Cell phone|   3000|      4|            3|         4|\n",
      "|  Foldable|Cell phone|   3000|      4|            3|         5|\n",
      "|      Pro2|    Tablet|   6500|      1|            1|         1|\n",
      "|      Mini|    Tablet|   5500|      2|            2|         2|\n",
      "|       Pro|    Tablet|   4500|      3|            3|         3|\n",
      "|       Big|    Tablet|   2500|      4|            4|         4|\n",
      "|    Normal|    Tablet|   1500|      5|            5|         5|\n",
      "+----------+----------+-------+-------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    productRevenue\n",
    "    .withColumn(\n",
    "        \"ranking\",\n",
    "        F.rank() #no tiene argumentos\n",
    "        .over(\n",
    "            Window\n",
    "            .partitionBy('category') #ventana particionada por categoria\n",
    "            .orderBy(F.desc('revenue')) #ordenada por revenue\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"dense_ranking\",\n",
    "        F.dense_rank()\n",
    "        .over(\n",
    "            Window\n",
    "            .partitionBy('category')\n",
    "            .orderBy(F.desc('revenue'))\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"row_number\",\n",
    "        F.row_number()\n",
    "        .over(\n",
    "            Window\n",
    "            .partitionBy('category')\n",
    "            .orderBy(F.desc('revenue'))\n",
    "        )\n",
    "    )\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir la ventana por separado para simplificar el código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana = (\n",
    "\n",
    "    Window\n",
    "    .partitionBy('category')\n",
    "    .orderBy(F.desc('revenue'))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranqueados = (\n",
    "\n",
    "    productRevenue\n",
    "    .withColumn(\"ranking\",F.rank().over(ventana))\n",
    "    .withColumn(\"dense_ranking\",F.dense_rank().over(ventana))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-------+-------------+\n",
      "|   product|  category|revenue|ranking|dense_ranking|\n",
      "+----------+----------+-------+-------+-------------+\n",
      "|      Thin|Cell phone|   6000|      1|            1|\n",
      "| Very Thin|Cell phone|   6000|      1|            1|\n",
      "|Ultra Thin|Cell phone|   5000|      3|            2|\n",
      "|  Bendable|Cell phone|   3000|      4|            3|\n",
      "|  Foldable|Cell phone|   3000|      4|            3|\n",
      "|      Pro2|    Tablet|   6500|      1|            1|\n",
      "|      Mini|    Tablet|   5500|      2|            2|\n",
      "|       Pro|    Tablet|   4500|      3|            3|\n",
      "|       Big|    Tablet|   2500|      4|            4|\n",
      "|    Normal|    Tablet|   1500|      5|            5|\n",
      "+----------+----------+-------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranqueados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "![](img/blog-illustration-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde spark podemos leer todo tipo de formatos, veamos algunos ejemplos más avanzados. Lo primero de todo vamos a cambiar cada uno a la databse de hive de nuestro usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jhelena\n"
     ]
    }
   ],
   "source": [
    "mi_user = os.environ.get('USER') #os nos da nuestro usuario \n",
    "print(mi_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(mi_user) #para cambiar la base de datos por defecto a la nuestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los datos en Hive:\n",
    "**Por defecto guarda en formato PARQUET (LO MAS COMODO EN SPARK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranqueados.write.saveAsTable(\"ranqueos\") #NOS DARIA ERROR SI YA LA TUVIERAMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>database</th>\n",
       "      <th>description</th>\n",
       "      <th>tableType</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airport_part</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>books</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>books_part</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dns</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ranqueos</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ratings_parquet</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ratings_parquet_snappy</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>restaurants2019</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>terrorism</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>terrorism_age_groups</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>terroristplot</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>top10</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tweets</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wh_avro</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wh_parquet</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>world_happiness</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>world_happiness_part</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name database description tableType  isTemporary\n",
       "0             airport_part  jhelena        None  EXTERNAL        False\n",
       "1                    books  jhelena        None  EXTERNAL        False\n",
       "2               books_part  jhelena        None  EXTERNAL        False\n",
       "3                      dns  jhelena        None  EXTERNAL        False\n",
       "4                 ranqueos  jhelena        None   MANAGED        False\n",
       "5          ratings_parquet  jhelena        None   MANAGED        False\n",
       "6   ratings_parquet_snappy  jhelena        None   MANAGED        False\n",
       "7          restaurants2019  jhelena        None   MANAGED        False\n",
       "8                terrorism  jhelena        None  EXTERNAL        False\n",
       "9     terrorism_age_groups  jhelena        None   MANAGED        False\n",
       "10           terroristplot  jhelena        None  EXTERNAL        False\n",
       "11                   top10  jhelena        None   MANAGED        False\n",
       "12                  tweets  jhelena        None  EXTERNAL        False\n",
       "13                 wh_avro  jhelena        None   MANAGED        False\n",
       "14              wh_parquet  jhelena        None   MANAGED        False\n",
       "15         world_happiness  jhelena        None   MANAGED        False\n",
       "16    world_happiness_part  jhelena        None   MANAGED        False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(spark.catalog.listTables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos borrar la tabla creada con sentencia *SQL*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\" DROP TABLE ranqueos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>database</th>\n",
       "      <th>description</th>\n",
       "      <th>tableType</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airport_part</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>books</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>books_part</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dns</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ratings_parquet</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ratings_parquet_snappy</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>restaurants2019</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>terrorism</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>terrorism_age_groups</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>terroristplot</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>top10</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tweets</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>EXTERNAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wh_avro</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wh_parquet</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>world_happiness</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>world_happiness_part</td>\n",
       "      <td>jhelena</td>\n",
       "      <td>None</td>\n",
       "      <td>MANAGED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name database description tableType  isTemporary\n",
       "0             airport_part  jhelena        None  EXTERNAL        False\n",
       "1                    books  jhelena        None  EXTERNAL        False\n",
       "2               books_part  jhelena        None  EXTERNAL        False\n",
       "3                      dns  jhelena        None  EXTERNAL        False\n",
       "4          ratings_parquet  jhelena        None   MANAGED        False\n",
       "5   ratings_parquet_snappy  jhelena        None   MANAGED        False\n",
       "6          restaurants2019  jhelena        None   MANAGED        False\n",
       "7                terrorism  jhelena        None  EXTERNAL        False\n",
       "8     terrorism_age_groups  jhelena        None   MANAGED        False\n",
       "9            terroristplot  jhelena        None  EXTERNAL        False\n",
       "10                   top10  jhelena        None   MANAGED        False\n",
       "11                  tweets  jhelena        None  EXTERNAL        False\n",
       "12                 wh_avro  jhelena        None   MANAGED        False\n",
       "13              wh_parquet  jhelena        None   MANAGED        False\n",
       "14         world_happiness  jhelena        None   MANAGED        False\n",
       "15    world_happiness_part  jhelena        None   MANAGED        False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(spark.catalog.listTables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además podemos guardar la tabla directamen en un direcotrio del hdfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranqueados.write.parquet(\"ranqueos.parquet\") #guarda en el hdfs en parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranqueados.write.save(\"ranqueos.parquet\") #save guarda por lo que hay por defecto (parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tanto `parquet` como `save` hace lo mismo guardar los datos en formato parquet. La última sentencia nos ha dado error porque ya exitía el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Modes\n",
    "Por defecto al guardar un `DF` obtenemos error si existe el directorio, podemos configurar para que esto no ocurra:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table\">\n",
    "<tbody><tr><th>Scala/Java</th><th>Any Language</th><th>Meaning</th></tr>\n",
    "<tr>\n",
    "  <td><code>SaveMode.ErrorIfExists</code> (default)</td>\n",
    "  <td><code>\"error\"</code> (default)</td>\n",
    "  <td>\n",
    "    When saving a DataFrame to a data source, if data already exists,\n",
    "    an exception is expected to be thrown.\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td><code>SaveMode.Append</code></td>\n",
    "  <td><code>\"append\"</code></td>\n",
    "  <td>\n",
    "    When saving a DataFrame to a data source, if data/table already exists,\n",
    "    contents of the DataFrame are expected to be appended to existing data.\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td><code>SaveMode.Overwrite</code></td>\n",
    "  <td><code>\"overwrite\"</code></td>\n",
    "  <td>\n",
    "    Overwrite mode means that when saving a DataFrame to a data source,\n",
    "    if data/table already exists, existing data is expected to be overwritten by the contents of\n",
    "    the DataFrame.\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td><code>SaveMode.Ignore</code></td>\n",
    "  <td><code>\"ignore\"</code></td>\n",
    "  <td>\n",
    "    Ignore mode means that when saving a DataFrame to a data source, if data already exists,\n",
    "    the save operation is expected to not save the contents of the DataFrame and to not\n",
    "    change the existing data. This is similar to a <code>CREATE TABLE IF NOT EXISTS</code> in SQL.\n",
    "  </td>\n",
    "</tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranqueados.write.mode('overwrite').save(\"ranqueos.parquet\") #TIRA LO QUE HAYA Y LO VUELVE A GUARDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.load(\"ranqueos.parquet\").count() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `append` añadimos a la tabla existente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    ranqueados.write.mode('append').save(\"ranqueos.parquet\") \n",
    "    \n",
    "#ANADIMOS A LA TABLA TRES VECES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.load(\"ranqueos.parquet\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/json.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos leer y escribir en formato JSON, aunque realmente se usa el formato [*JSON lines*](http://jsonlines.org/) dónde cada línea es un registro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"URL\":\"http://www.just-eat.co.uk/restaurants-albany-spice/menu\",\"_id\":{\"$oid\":\"55f14312c7447c3da7051d42\"},\"address\":\"Stella Building\",\"address_line\":\"Washington\",\"name\":\"Albany Spice\",\"outcode\":\"NE37\",\"postcode\":\"1BH\",\"rating\":4.5,\"type_of_food\":\"Curry\"}\n",
      "{\"URL\":\"http://www.just-eat.co.uk/restaurants-albarakah-hd4/menu\",\"_id\":{\"$oid\":\"55f14312c7447c3da7051d43\"},\"address\":\"279 Manchester Road\",\"address_line\":\"West Yorkshire\",\"name\":\"Albarakah\",\"outcode\":\"HD4\",\"postcode\":\"5AA\",\"rating\":4.5,\"type_of_food\":\"Curry\"}\n",
      "{\"URL\":\"http://www.just-eat.co.uk/restaurants-albatta-co1/menu\",\"_id\":{\"$oid\":\"55f14312c7447c3da7051d44\"},\"address\":\"18 Sir Isaac Walk\",\"address_line\":\"Colchester\",\"name\":\"Albatta\",\"outcode\":\"CO1\",\"postcode\":\"1JJ\",\"rating\":5.0,\"type_of_food\":\"Lebanese\"}\n",
      "text: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -text /datos/restaurants.json | head -n 3\n",
    "#el json de big data va cada registro es una fila = json lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes = spark.read.json('/datos/restaurants.json') #EN JSON YA VIENEN LOS ESQUEMAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pasar todo a parquet que va MUCHO MAS RAPIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- URL: string (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- $oid: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- address_line: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- outcode: string (nullable = true)\n",
      " |-- postcode: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- type_of_food: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restaurantes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>_id</th>\n",
       "      <th>address</th>\n",
       "      <th>address_line</th>\n",
       "      <th>name</th>\n",
       "      <th>outcode</th>\n",
       "      <th>postcode</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_of_food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albany-s...</td>\n",
       "      <td>(55f14312c7447c3da7051d42,)</td>\n",
       "      <td>Stella Building</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Albany Spice</td>\n",
       "      <td>NE37</td>\n",
       "      <td>1BH</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albaraka...</td>\n",
       "      <td>(55f14312c7447c3da7051d43,)</td>\n",
       "      <td>279 Manchester Road</td>\n",
       "      <td>West Yorkshire</td>\n",
       "      <td>Albarakah</td>\n",
       "      <td>HD4</td>\n",
       "      <td>5AA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albatta-...</td>\n",
       "      <td>(55f14312c7447c3da7051d44,)</td>\n",
       "      <td>18 Sir Isaac Walk</td>\n",
       "      <td>Colchester</td>\n",
       "      <td>Albatta</td>\n",
       "      <td>CO1</td>\n",
       "      <td>1JJ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lebanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albertos...</td>\n",
       "      <td>(55f14312c7447c3da7051d45,)</td>\n",
       "      <td>112 Gannow Lane</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Alberto's Pizza &amp; Kebab House</td>\n",
       "      <td>BB12</td>\n",
       "      <td>6QD</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albertsf...</td>\n",
       "      <td>(55f14312c7447c3da7051d46,)</td>\n",
       "      <td>746 City Road</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>Albert's Fish &amp; Chips</td>\n",
       "      <td>S2</td>\n",
       "      <td>1GN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Fish &amp; Chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albions-...</td>\n",
       "      <td>(55f14312c7447c3da7051d47,)</td>\n",
       "      <td>120 Midland Road Royston</td>\n",
       "      <td>Barnsley</td>\n",
       "      <td>Albions</td>\n",
       "      <td>S71</td>\n",
       "      <td>4QT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albions-...</td>\n",
       "      <td>(55f14312c7447c3da7051d48,)</td>\n",
       "      <td>120 Midland Road Royston</td>\n",
       "      <td>Barnsley</td>\n",
       "      <td>Albions</td>\n",
       "      <td>S71</td>\n",
       "      <td>4QT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-alborz/menu</td>\n",
       "      <td>(55f14312c7447c3da7051d49,)</td>\n",
       "      <td>71 Ormskirk Road</td>\n",
       "      <td>Wigan</td>\n",
       "      <td>Alborz</td>\n",
       "      <td>WN5</td>\n",
       "      <td>9EA</td>\n",
       "      <td>5.5</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-albright...</td>\n",
       "      <td>(55f14312c7447c3da7051d4a,)</td>\n",
       "      <td>5/6 High Street</td>\n",
       "      <td>Albrighton</td>\n",
       "      <td>Albrighton Balti</td>\n",
       "      <td>WV7</td>\n",
       "      <td>3JX</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://www.just-eat.co.uk/restaurants-alcapone...</td>\n",
       "      <td>(55f14312c7447c3da7051d4b,)</td>\n",
       "      <td>105 Highfield Road</td>\n",
       "      <td>Blackpool</td>\n",
       "      <td>Alcapone Pizza Shop</td>\n",
       "      <td>FY4</td>\n",
       "      <td>2JE</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Pizza</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  http://www.just-eat.co.uk/restaurants-albany-s...   \n",
       "1  http://www.just-eat.co.uk/restaurants-albaraka...   \n",
       "2  http://www.just-eat.co.uk/restaurants-albatta-...   \n",
       "3  http://www.just-eat.co.uk/restaurants-albertos...   \n",
       "4  http://www.just-eat.co.uk/restaurants-albertsf...   \n",
       "5  http://www.just-eat.co.uk/restaurants-albions-...   \n",
       "6  http://www.just-eat.co.uk/restaurants-albions-...   \n",
       "7  http://www.just-eat.co.uk/restaurants-alborz/menu   \n",
       "8  http://www.just-eat.co.uk/restaurants-albright...   \n",
       "9  http://www.just-eat.co.uk/restaurants-alcapone...   \n",
       "\n",
       "                           _id                   address    address_line  \\\n",
       "0  (55f14312c7447c3da7051d42,)           Stella Building      Washington   \n",
       "1  (55f14312c7447c3da7051d43,)       279 Manchester Road  West Yorkshire   \n",
       "2  (55f14312c7447c3da7051d44,)         18 Sir Isaac Walk      Colchester   \n",
       "3  (55f14312c7447c3da7051d45,)           112 Gannow Lane         Burnley   \n",
       "4  (55f14312c7447c3da7051d46,)             746 City Road       Sheffield   \n",
       "5  (55f14312c7447c3da7051d47,)  120 Midland Road Royston        Barnsley   \n",
       "6  (55f14312c7447c3da7051d48,)  120 Midland Road Royston        Barnsley   \n",
       "7  (55f14312c7447c3da7051d49,)          71 Ormskirk Road           Wigan   \n",
       "8  (55f14312c7447c3da7051d4a,)           5/6 High Street      Albrighton   \n",
       "9  (55f14312c7447c3da7051d4b,)        105 Highfield Road       Blackpool   \n",
       "\n",
       "                            name outcode postcode  rating  type_of_food  \n",
       "0                   Albany Spice    NE37      1BH     4.5         Curry  \n",
       "1                      Albarakah     HD4      5AA     4.5         Curry  \n",
       "2                        Albatta     CO1      1JJ     5.0      Lebanese  \n",
       "3  Alberto's Pizza & Kebab House    BB12      6QD     5.5         Kebab  \n",
       "4          Albert's Fish & Chips      S2      1GN     4.5  Fish & Chips  \n",
       "5                        Albions     S71      4QT     5.0         Pizza  \n",
       "6                        Albions     S71      4QT     5.0         Pizza  \n",
       "7                         Alborz     WN5      9EA     5.5      American  \n",
       "8               Albrighton Balti     WV7      3JX     5.5         Curry  \n",
       "9            Alcapone Pizza Shop     FY4      2JE     5.5         Pizza  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurantes.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JDBC (Java Database Connectivity)\n",
    "\n",
    "![](img/java_jdbc.png)\n",
    "\n",
    "JDBC es un protocolo altamente utilizado por las bases de datos. De esta manera, muchas base de dato tiene un *driver* para este protocolo. Veamos por ejemplo como conectarnos a *MySQL*\n",
    "\n",
    "**NOTA:** Observar como al iniciar la sesión de spark pusimos:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    ".set(\"spark.jars\",\"/var/lib/sqoop/mysql-connector-java-5.1.44-bin.jar\")\n",
    "```\n",
    "Para añadir el driver a la sesión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = (\n",
    "\n",
    "    spark.read\n",
    "    .format(\"jdbc\") #FORMATO TIPO JDBC\n",
    "    .option(\"url\", \"jdbc:mysql://192.168.80.33:3306/movielens\") #DRIVER QUE VAMOS A USAR, HOST, Y BASE DE DATOS\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\") \n",
    "    .option(\"dbtable\", \"tags\") #LA TABLA QUE QUIERES LEER\n",
    "    .option(\"user\", \"root\")\n",
    "    .option(\"password\", \"root\")\n",
    "    .load()\n",
    " \n",
    ")\n",
    "#no lee los datos pero ve lo que hay y crea el esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174846"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------------+----------+\n",
      "|userId|movieId|              tag|        ts|\n",
      "+------+-------+-----------------+----------+\n",
      "|    18|   4141|      Mark Waters|1240597180|\n",
      "|    65|    208|        dark hero|1368150078|\n",
      "|    65|    353|        dark hero|1368150079|\n",
      "|    65|    521|    noir thriller|1368149983|\n",
      "|    65|    592|        dark hero|1368150078|\n",
      "|    65|    668|        bollywood|1368149876|\n",
      "|    65|    898| screwball comedy|1368150160|\n",
      "|    65|   1248|    noir thriller|1368149983|\n",
      "|    65|   1391|             mars|1368150055|\n",
      "|    65|   1617|         neo-noir|1368150217|\n",
      "|    65|   1694|            jesus|1368149925|\n",
      "|    65|   1783|    noir thriller|1368149983|\n",
      "|    65|   2022|            jesus|1368149925|\n",
      "|    65|   2193|           dragon|1368151314|\n",
      "|    65|   2353|conspiracy theory|1368151266|\n",
      "|    65|   2662|             mars|1368150055|\n",
      "|    65|   2726|    noir thriller|1368149983|\n",
      "|    65|   2840|            jesus|1368149925|\n",
      "|    65|   3052|            jesus|1368149926|\n",
      "|    65|   5135|        bollywood|1368149876|\n",
      "+------+-------+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+\n",
      "|movieID|               tag|count|\n",
      "+-------+------------------+-----+\n",
      "|  79132| alternate reality|   98|\n",
      "|   2959|         Brad Pitt|   74|\n",
      "|    593|   Anthony Hopkins|   64|\n",
      "|   1653|          dystopia|   54|\n",
      "|   2420|            mentor|   53|\n",
      "|  70286|            aliens|   52|\n",
      "|   4973|beautifully filmed|   52|\n",
      "|  79132|            action|   50|\n",
      "|   4226|         nonlinear|   49|\n",
      "|   8874|      black comedy|   49|\n",
      "|   2291|          original|   48|\n",
      "|  44191|          dystopia|   48|\n",
      "|     32|         Brad Pitt|   48|\n",
      "|   2329|     Edward Norton|   47|\n",
      "|   6711|       atmospheric|   47|\n",
      "|  64614|    Clint Eastwood|   46|\n",
      "|  69122|            comedy|   46|\n",
      "|   5618|             anime|   46|\n",
      "|     47|         Brad Pitt|   45|\n",
      "|  58559|            Batman|   45|\n",
      "+-------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    tags\n",
    "    .groupBy('movieID','tag')\n",
    "    .count()\n",
    "    .filter('count>2')\n",
    "    .orderBy(F.desc('count'))\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen_pelis = (\n",
    "\n",
    "    tags\n",
    "    .groupBy('movieID')\n",
    "    .agg(F.collect_set('tag').alias('tags'))\n",
    "    .withColumn('conteo',F.size('tags')) #F.size te dice el numero de elementos en una lista\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+\n",
      "|movieID|                tags|conteo|\n",
      "+-------+--------------------+------+\n",
      "|    148|[nudity (topless)...|     2|\n",
      "|    471|[VHS, Business is...|    27|\n",
      "|    496|[Sundance award w...|     2|\n",
      "|    833|[ZAZ, comedy, spo...|     4|\n",
      "|   1088|[coming of age, g...|    20|\n",
      "|   1238|[affectionate, Be...|     8|\n",
      "|   1342|[gruesome, CLV, n...|    13|\n",
      "|   1580|[comic book, Acti...|    35|\n",
      "|   1591|[super hero, comi...|     7|\n",
      "|   1645|[courtroom, DVD, ...|    26|\n",
      "|   1829|[deep, China, Hon...|     3|\n",
      "|   1959|[Oscar (Best Cine...|    17|\n",
      "|   2122|[Eric's Dvds, ada...|    14|\n",
      "|   2142|[adventure, class...|     3|\n",
      "|   2366|[stop motion, dvd...|    26|\n",
      "|   2866|[Steve Rash, musi...|     4|\n",
      "|   3175|[star trek, DVD-V...|    25|\n",
      "|   3749|[John Malkovich, ...|     2|\n",
      "|   3794|             [indie]|     1|\n",
      "|   3918|[Betamax, Tumey's...|     8|\n",
      "+-------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resumen_pelis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos escribir la información procesada del *MySQL* directamente a un fichero *JSON* por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen_pelis.write.mode('overwrite').json('pelis.json') #guardar a json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"movieID\":148,\"tags\":[\"nudity (topless)\",\"Nudity (Topless - Notable)\"],\"conteo\":2}\n",
      "{\"movieID\":471,\"tags\":[\"VHS\",\"Business is the antagonist\",\"satirical\",\"Comedy\",\"funny\",\"no idea\",\"BD-R\",\"f\",\"Didn't finish\",\"coen bros\",\"cheesy\",\"quirky\",\"New Year's Eve\",\"hula hoop\",\"btaege\",\"Capra-esque\",\"NO_FA_GANES\",\"Fantasy\",\"Tumey's DVDs\",\"coen brothers\",\"Underrated\",\"BOARDROOM JUNGLE\",\"1950s\",\"business\",\"To See\",\"netflixq\",\"Coen Brothers\"],\"conteo\":27}\n",
      "{\"movieID\":496,\"tags\":[\"Sundance award winner\",\"loneliness\"],\"conteo\":2}\n",
      "{\"movieID\":833,\"tags\":[\"ZAZ\",\"comedy\",\"spoof\",\"Hart Bochner\"],\"conteo\":4}\n"
     ]
    }
   ],
   "source": [
    "for i in spark.sparkContext.textFile('pelis.json').take(4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+\n",
      "|conteo|movieID|                tags|\n",
      "+------+-------+--------------------+\n",
      "|     8|     35|[bisexual, compar...|\n",
      "|     2|    503|[social satire, l...|\n",
      "|     1|    583|     [Nanni Moretti]|\n",
      "|    29|    594|[adapted from:boo...|\n",
      "|     9|    610|[Adult Animation,...|\n",
      "|     6|    761|[pretty terrible,...|\n",
      "|     8|    880|[Futuristmovies.c...|\n",
      "|     1|   1519|[less than 300 ra...|\n",
      "|    18|   1589|[pretty good, dra...|\n",
      "|     1|   1815|[less than 300 ra...|\n",
      "|     9|   1881|[Nostalgia Critic...|\n",
      "|    25|   2080|[Disney, reviewed...|\n",
      "|    46|   2324|[father, top 250 ...|\n",
      "|     1|   2444|   [black and white]|\n",
      "|     3|   2445|[blindness, Irwin...|\n",
      "|     5|   2649|[atmosphere, Rowl...|\n",
      "|    13|   2915|[male teenager(s)...|\n",
      "|     1|   3065|[less than 300 ra...|\n",
      "|     7|   3316|[nudity (topless)...|\n",
      "|    21|   3468|[Oscar (Best Cine...|\n",
      "+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.json('pelis.json').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Introduction to Apache Spark on Databricks (2)",
  "notebookId": 687660855473850
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
