{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> MLlib: Machine Learning con Spark </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "\n",
    "    SparkConf()\n",
    "    .setAppName(u\"[ICAI] ML a fondo\")\n",
    "    .set(\"spark.executor.memory\", \"7g\")\n",
    "    .set(\"spark.executor.cores\", \"5\")\n",
    "    .set(\"spark.default.parallelism\", 800)\n",
    "    .set(\"spark.sql.shuffle.partitions\", 800)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning de modelos\n",
    "\n",
    "![](img/rf.jpg)\n",
    "\n",
    "Como hemos visto en el ejercicio anterior estabamos consiguiendo peores resultados en el [Random Forest](https://es.wikipedia.org/wiki/Random_forest) que un solo árbol, veamos como solucionar esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF, testDF = ( #cargamos los datos dividiendola directamente en 70-30\n",
    "\n",
    "    spark.read\n",
    "    .options(header=True,inferSchema=True)\n",
    "    .csv('/datos/hour.csv')\n",
    "    .drop('casual','registerd','instant','dteday')\n",
    "    .randomSplit([0.7, 0.3], seed=1234)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Número de registros en `trainDF`: 12150\n",
      "## Número de registros en `testDF`: 5229\n"
     ]
    }
   ],
   "source": [
    "trainDF.cache()\n",
    "testDF.cache()\n",
    "print(\"## Número de registros en `trainDF`: {}\".format(trainDF.count()))\n",
    "print(\"## Número de registros en `testDF`: {}\".format(testDF.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.printSchema() #todas las variables que decidamos que son categoricas lo tenemos que codificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['season',\n",
       " 'yr',\n",
       " 'mnth',\n",
       " 'hr',\n",
       " 'holiday',\n",
       " 'weekday',\n",
       " 'workingday',\n",
       " 'weathersit',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'hum',\n",
       " 'windspeed',\n",
       " 'registered']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresCols = trainDF.columns[:-1] #quitamos la ultima que es la variable a predecir (el conteo)\n",
    "featuresCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primero montamos de nuevo el árbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\") \n",
    "#coge todas las variables y las mete a un vector concatenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler.transform(trainDF)\n",
    "#genera una columna llamada raw features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VectorIndexer? #decide que variables son categoricas y las codifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(labelCol='cnt') #arbol donde la variable a predecir es cnt (podriamos decir que inputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[vectorAssembler, vectorIndexer, dt]) \n",
    "#creamos el pipleine que coge todos los numeros las pone en un vector, indexa y entrena el modelo\n",
    "    #el pipeline coge el output del anterior para hacer el siguiete paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainDF) #entreno el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"cnt\") #para el metodo de evaliacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = evaluator.evaluate(model.transform(trainDF))\n",
    "rmse_valid = evaluator.evaluate(model.transform(testDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## RMSE (Train): 32.659\n",
      "## RMSE (Valid): 33.179\n"
     ]
    }
   ],
   "source": [
    "print(\"## RMSE (Train): {:.3f}\".format(rmse_train))\n",
    "print(\"## RMSE (Valid): {:.3f}\".format(rmse_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stages #nos da los tres transformadores (podemos modificarlos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora el bosque:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(labelCol='cnt') #defino el random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(stages= model.stages[:-1] + [rf]) #usamos de la anterior todas hasta la penultima y cambiamos el dt por rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = pipeline2.fit(trainDF) #entreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = evaluator.evaluate(model2.transform(trainDF))\n",
    "rmse_valid = evaluator.evaluate(model2.transform(testDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## RMSE (Train): 41.687\n",
      "## RMSE (Valid): 42.729\n"
     ]
    }
   ],
   "source": [
    "print(\"## RMSE (Train): {:.3f}\".format(rmse_train))\n",
    "print(\"## RMSE (Valid): {:.3f}\".format(rmse_valid))\n",
    "#vemos que el error es peor que en el dt\n",
    "    #tiene unos hiper-parametros por defecto que deberiamos modificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos más complejos tienen varios hiper-parámetros que hay que configurar para conseguir la mayor *performance*, a esta búsqueda de la configuración óptima se le suele conocer como [*tuning*](https://en.wikipedia.org/wiki/Hyperparameter_optimization). Veamos los parámetros del modelo en cuestión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval. (default: False)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "featureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]. (default: auto)\n",
      "featuresCol: features column name. (default: features)\n",
      "impurity: Criterion used for information gain calculation (case-insensitive). Supported options: variance (default: variance)\n",
      "labelCol: label column name. (default: label)\n",
      "maxBins: Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. (default: 32)\n",
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5)\n",
      "maxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size. (default: 256)\n",
      "minInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\n",
      "minInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1)\n",
      "numTrees: Number of trees to train (>= 1). (default: 20)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "seed: random seed. (default: 4544595120712362955)\n",
      "subsamplingRate: Fraction of the training data used for learning each decision tree, in range (0, 1]. (default: 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(RandomForestRegressor().explainParams())\n",
    "#hay parametros de optimizacion del proceso spark e hyperparametros de modelo (nos enfocamos en estos)\n",
    "#IMP: numTrees, maxDepth (no baja mas de 5 niveles por defecto), maxBins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestRegressor(labelCol='cnt', numTrees=200, maxDepth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Pipeline(stages= model.stages[:-1] + [rf3]).fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = evaluator.evaluate(model3.transform(trainDF))\n",
    "rmse_valid = evaluator.evaluate(model3.transform(testDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## RMSE (Train): 17.871\n",
      "## RMSE (Valid): 22.209\n"
     ]
    }
   ],
   "source": [
    "print(\"## RMSE (Train): {:.3f}\".format(rmse_train))\n",
    "print(\"## RMSE (Valid): {:.3f}\".format(rmse_valid))\n",
    "#queremos la minima diferencia posible para evitar sobre-entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ya hemos conseguido mejores resultados!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation y búsqueda por malla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/cv.png)\n",
    "\n",
    "En Spark MLlib existen funciones para hacer fácil la búsqueda de hiperparámetros y la [validación cruzada](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (\n",
    "\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [100, 200, 300])\n",
    "    .addGrid(rf.maxDepth, [4, 10])\n",
    "    .build()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(\n",
    "\n",
    "    estimator = pipeline2, #aqui ya hemos metido que queremos el rf sin parametros\n",
    "    estimatorParamMaps = paramGrid, #aqui metemos los parametros\n",
    "    evaluator = evaluator,\n",
    "    numFolds = 3\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUIDADO** Este `fit` puede durar varios minutos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = crossval.fit(trainDF) #coge el data-set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54.16436455546874,\n",
       " 23.147411883242945,\n",
       " 51.926540068261154,\n",
       " 22.823147824447453,\n",
       " 52.40418431361557,\n",
       " 22.793689821884286]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.avgMetrics #media en cada uno de esos puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor = np.argsort(cvModel.avgMetrics)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.793689821884286"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.avgMetrics[mejor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestRegressor_41c4b53d06a9b79a06da', name='numTrees', doc='Number of trees to train (>= 1).'): 300,\n",
       " Param(parent='RandomForestRegressor_41c4b53d06a9b79a06da', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.getEstimatorParamMaps()[mejor] #nos quedamos con la configuracion de la maya para la mejor configuracion\n",
    "#es un extremo: deberiams ajustar la malla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = evaluator.evaluate(cvModel.transform(trainDF))\n",
    "rmse_valid = evaluator.evaluate(cvModel.transform(testDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## RMSE (Train): 17.901\n",
      "## RMSE (Valid): 22.400\n"
     ]
    }
   ],
   "source": [
    "print(\"## RMSE (Train): {:.3f}\".format(rmse_train))\n",
    "print(\"## RMSE (Valid): {:.3f}\".format(rmse_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering: K-Means\n",
    "\n",
    "![](img/wikimedia.png)\n",
    "\n",
    "Veamos un ejemplo de modelo no supervisado. Usaremos para ello un dataset de artículos de wikipedia que se puede encontrar en: https://dumps.wikimedia.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = spark.read.parquet('/datos/wiki.parquet').repartition(800).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111495"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- lastrev_pdt_time: timestamp (nullable = true)\n",
      " |-- revid: long (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- contributorid: long (nullable = true)\n",
      " |-- contributorusername: string (nullable = true)\n",
      " |-- contributorip: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wiki_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lastrev_pdt_time</th>\n",
       "      <th>revid</th>\n",
       "      <th>comment</th>\n",
       "      <th>contributorid</th>\n",
       "      <th>contributorusername</th>\n",
       "      <th>contributorip</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33235801</td>\n",
       "      <td>KIG60</td>\n",
       "      <td>2016-03-03 17:56:42</td>\n",
       "      <td>708165041</td>\n",
       "      <td>/* External links */merge cat per https://en.w...</td>\n",
       "      <td>3637572.0</td>\n",
       "      <td>SQL</td>\n",
       "      <td>None</td>\n",
       "      <td>{{Infobox Radio station\\n | name = KIG60 - Bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3484057</td>\n",
       "      <td>Chris Brown (album)</td>\n",
       "      <td>2016-03-03 08:06:20</td>\n",
       "      <td>708085410</td>\n",
       "      <td>/* Track listing */</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>82.51.120.241</td>\n",
       "      <td>{{Infobox album &lt;!-- See Wikipedia:WikiProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2872543</td>\n",
       "      <td>Humane Slaughter Act</td>\n",
       "      <td>2016-03-03 14:13:09</td>\n",
       "      <td>708135254</td>\n",
       "      <td>/* Content of the Humane Slaughter Act */</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2601:282:8200:4DC6:5D1B:7B5B:CB61:981A</td>\n",
       "      <td>&lt;!-- Deleted image removed: [[Image:CattleRest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8100880</td>\n",
       "      <td>The Bicester School</td>\n",
       "      <td>2016-03-04 12:30:29</td>\n",
       "      <td>708293801</td>\n",
       "      <td>Reverted edits by [[Special:Contribs/94.119.64...</td>\n",
       "      <td>506179.0</td>\n",
       "      <td>Gilliam</td>\n",
       "      <td>None</td>\n",
       "      <td>{{Use dmy dates|date=October 2014}}\\n{{Infobox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32693240</td>\n",
       "      <td>Siege of Nagykanizsa</td>\n",
       "      <td>2016-03-05 01:30:19</td>\n",
       "      <td>708387224</td>\n",
       "      <td>/* References */[[WP:CHECKWIKI]] error fixes u...</td>\n",
       "      <td>1862829.0</td>\n",
       "      <td>Magioladitis</td>\n",
       "      <td>None</td>\n",
       "      <td>{{refimprove|date=September 2011}}\\n{{Infobox ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17074415</td>\n",
       "      <td>Andr??s Roemer</td>\n",
       "      <td>2016-03-04 11:48:53</td>\n",
       "      <td>708287447</td>\n",
       "      <td>Cleaning</td>\n",
       "      <td>7971374.0</td>\n",
       "      <td>Werther mx</td>\n",
       "      <td>None</td>\n",
       "      <td>{{Use mdy dates|date=January 2015}}\\n{{Infobox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47835010</td>\n",
       "      <td>Karie</td>\n",
       "      <td>2016-03-04 06:27:44</td>\n",
       "      <td>708241814</td>\n",
       "      <td>Removing \"Karie.jpg\", it has been deleted from...</td>\n",
       "      <td>2304267.0</td>\n",
       "      <td>CommonsDelinker</td>\n",
       "      <td>None</td>\n",
       "      <td>{{Infobox film\\n| name = Karie\\n| image =\\n| c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6100355</td>\n",
       "      <td>Ois??n McConville</td>\n",
       "      <td>2016-03-04 19:12:20</td>\n",
       "      <td>708348063</td>\n",
       "      <td>migrating [[Wikipedia:Persondata|Persondata]] ...</td>\n",
       "      <td>24420788.0</td>\n",
       "      <td>KasparBot</td>\n",
       "      <td>None</td>\n",
       "      <td>{{Infobox GAA player \\n| image           = Ois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18799478</td>\n",
       "      <td>Remetea Mare</td>\n",
       "      <td>2016-03-04 08:50:15</td>\n",
       "      <td>708260679</td>\n",
       "      <td>Robot - Speedily moving category Communes in T...</td>\n",
       "      <td>1215485.0</td>\n",
       "      <td>Cydebot</td>\n",
       "      <td>None</td>\n",
       "      <td>{{refimprove|date=July 2009}}\\n{{Infobox settl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>722668</td>\n",
       "      <td>Greece national football team</td>\n",
       "      <td>2016-03-03 08:45:24</td>\n",
       "      <td>708090889</td>\n",
       "      <td>/* Recent call-ups */</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>91.140.24.95</td>\n",
       "      <td>{{About|the men's team|the women's team|Greece...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                          title    lastrev_pdt_time      revid  \\\n",
       "0  33235801                          KIG60 2016-03-03 17:56:42  708165041   \n",
       "1   3484057            Chris Brown (album) 2016-03-03 08:06:20  708085410   \n",
       "2   2872543           Humane Slaughter Act 2016-03-03 14:13:09  708135254   \n",
       "3   8100880            The Bicester School 2016-03-04 12:30:29  708293801   \n",
       "4  32693240           Siege of Nagykanizsa 2016-03-05 01:30:19  708387224   \n",
       "5  17074415                 Andr??s Roemer 2016-03-04 11:48:53  708287447   \n",
       "6  47835010                          Karie 2016-03-04 06:27:44  708241814   \n",
       "7   6100355              Ois??n McConville 2016-03-04 19:12:20  708348063   \n",
       "8  18799478                   Remetea Mare 2016-03-04 08:50:15  708260679   \n",
       "9    722668  Greece national football team 2016-03-03 08:45:24  708090889   \n",
       "\n",
       "                                             comment  contributorid  \\\n",
       "0  /* External links */merge cat per https://en.w...      3637572.0   \n",
       "1                                /* Track listing */            NaN   \n",
       "2          /* Content of the Humane Slaughter Act */            NaN   \n",
       "3  Reverted edits by [[Special:Contribs/94.119.64...       506179.0   \n",
       "4  /* References */[[WP:CHECKWIKI]] error fixes u...      1862829.0   \n",
       "5                                           Cleaning      7971374.0   \n",
       "6  Removing \"Karie.jpg\", it has been deleted from...      2304267.0   \n",
       "7  migrating [[Wikipedia:Persondata|Persondata]] ...     24420788.0   \n",
       "8  Robot - Speedily moving category Communes in T...      1215485.0   \n",
       "9                              /* Recent call-ups */            NaN   \n",
       "\n",
       "  contributorusername                           contributorip  \\\n",
       "0                 SQL                                    None   \n",
       "1                None                           82.51.120.241   \n",
       "2                None  2601:282:8200:4DC6:5D1B:7B5B:CB61:981A   \n",
       "3             Gilliam                                    None   \n",
       "4        Magioladitis                                    None   \n",
       "5          Werther mx                                    None   \n",
       "6     CommonsDelinker                                    None   \n",
       "7           KasparBot                                    None   \n",
       "8             Cydebot                                    None   \n",
       "9                None                            91.140.24.95   \n",
       "\n",
       "                                                text  \n",
       "0  {{Infobox Radio station\\n | name = KIG60 - Bur...  \n",
       "1  {{Infobox album <!-- See Wikipedia:WikiProject...  \n",
       "2  <!-- Deleted image removed: [[Image:CattleRest...  \n",
       "3  {{Use dmy dates|date=October 2014}}\\n{{Infobox...  \n",
       "4  {{refimprove|date=September 2011}}\\n{{Infobox ...  \n",
       "5  {{Use mdy dates|date=January 2015}}\\n{{Infobox...  \n",
       "6  {{Infobox film\\n| name = Karie\\n| image =\\n| c...  \n",
       "7  {{Infobox GAA player \\n| image           = Ois...  \n",
       "8  {{refimprove|date=July 2009}}\\n{{Infobox settl...  \n",
       "9  {{About|the men's team|the women's team|Greece...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos por un tratemiento del texto como ya hemos visto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{Infobox Radio station\n",
      " | name = KIG60 - Burlington All Hazards\n",
      " | image = [[Image:Noaa all hazards.svg|150px]]\n",
      " | city = [[Burlington, Vermont]]\n",
      " | area = [[Burlington, Vermont metropolitan area|Burlington Metro]]\n",
      " | branding = [[NOAA Weather Radio All Hazards|NOAA All Hazards Radio]]\n",
      " | slogan = The Voice Of The National Weather Service\n",
      " | airdate = \n",
      " | language = [[American English|English]]\n",
      " | frequency = 162.400 [[Megahertz|MHz]]\n",
      " | format = [[Weather radio|Weather/Civil Emergency]]\n",
      " | power = 500 [[Watt]]s\n",
      " | erp = \n",
      " | haat = \n",
      " | class = C\n",
      " | callsign_meaning = \n",
      " | former_callsigns = \n",
      " | owner = [[National Oceanic and Atmospheric Administration|NOAA]]/[[National Weather Service]]\n",
      " | webcast = \n",
      " | website = [http://www.erh.noaa.gov/btv www.erh.noaa.gov/btv]\n",
      " | affiliations =\n",
      "}}\n",
      "'''KIG60''' (sometimes referred to as '''Burlington All Hazards''') is a [[NOAA Weather Radio All Hazards|NOAA Weather Radio]] station that serves the [[Burlington, Vermont metropolitan area|Burlington metropolitan area]] and surrounding cities. The broadcasts can also be heard throughout southern parts of [[Quebec]] and [[Ontario]]. It is programmed from the [[National Weather Service]] forecast office in [[Burlington, Vermont]] with its transmitter located in [[Mount Mansfield|Mt. Mansfield]]. It broadcasts weather and hazard information for [[Addison County, Vermont|Addison]], [[Chittenden County, Vermont|Chittenden]], [[Franklin County, Vermont|Franklin]], [[Grand Isle County, Vermont|Grand Isle]], [[Lamoille County, Vermont|Lamoille]], and [[Washington County, Vermont|Washington]] counties in [[Vermont]], plus [[Clinton County, New York|Clinton]], [[Essex County, New York|Essex]], [[Franklin County, New York|Franklin]], and [[St. Lawrence County, New York|St. Lawrence]] counties in [[New York]].\n",
      "\n",
      "==External links==\n",
      "*[http://www.erh.noaa.gov/btv/nwr/ NWS Burlington - NOAA Weather Radio Info]\n",
      "*[http://www.nws.noaa.gov/nwr/Maps/PHP/site.php?State=VT&Site=KIG60 KIG-60 Maps & Details]\n",
      "\n",
      "{{Burlington-Plattsburgh Radio}}\n",
      "\n",
      "{{coord missing|Vermont}}\n",
      "\n",
      "[[Category:Radio stations in Vermont|*KIG60]]\n",
      "[[Category:NOAA Weather Radio]]\n",
      "\n",
      "\n",
      "{{Vermont-radio-station-stub}}\n",
      "------------\n",
      "\n",
      "\n",
      "{{Infobox album <!-- See Wikipedia:WikiProject Albums -->\n",
      "| Name        = Chris Brown\n",
      "| Type        = studio\n",
      "| Artist      = [[Chris Brown]]\n",
      "| Cover       = Chris brown.jpg\n",
      "| Released    = November 29, 2005\n",
      "| Recorded    = January 2005 &ndash; May 2005\n",
      "| Genre       = [[Contemporary R&B|R&B]]\n",
      "| Length      = 55:44\n",
      "| Label       = {{flatlist|\n",
      "* [[Jive Records|Jive]]\n",
      "* CBE\n",
      "* [[Zomba Label Group|Zomba]]\n",
      "* [[Sony BMG Music Entertainment|Sony BMG]] {{small|(International distribution)}}\n",
      "}}\n",
      "| Producer    = {{flatlist|\n",
      "* Chris Brown {{small|([[Executive producer#Music|exec.]])}}\n",
      "* Mark Pitts {{small|(co-exec.)}}\n",
      "* [[Scott Storch]]\n",
      "* [[Jermaine Dupri]]\n",
      "* [[Bryan-Michael Cox]]\n",
      "* [[WyldCard]]\n",
      "* [[The Underdogs (duo)|The Underdogs]]\n",
      "* [[Dre & Vidal]]\n",
      "* Shea Taylor\n",
      "* [[Cool & Dre]]\n",
      "* [[Sean Garrett]]\n",
      "* Shannon \"Slam\" Lawrence\n",
      "* Oak\n",
      "* Eddie Hustle\n",
      "* [[LRoc]]\n",
      "}}\n",
      "| This album  = '''''Chris Brown'''''<br/>(2005)  \n",
      "| Next album  = ''[[Exclusive (album)|Exclusive]]''<br/>(2007)\n",
      "| Misc = {{Extra album cover\n",
      "| Upper caption = Alternative cover\n",
      "| Type = studio\n",
      "| Cover = Chris Brown cover.jpg\n",
      "| Lower caption = International cover\n",
      "}}\n",
      "{{Singles\n",
      "| Name = Chris Brown\n",
      "| Type = studio\n",
      "| single 1 = [[Run It!]]\n",
      "| single 1 date = June 30, 2005\n",
      "| single 2 = [[Yo (Excuse Me Miss)]]\n",
      "| single 2 date = December 13, 2005\n",
      "| single 3 = [[Gimme That]]\n",
      "| single 3 date = May 7, 2006\n",
      "| single 4 = [[Say Goodbye (Chris Brown song)|Say Goodbye]]\n",
      "| single 4 date = August 8, 2006\n",
      "| single 5 = [[Poppin' (song)|Poppin']]\n",
      "| single 5 date = November 21, 2006\n",
      "}}\n",
      "}} \n",
      "{{Album ratings\n",
      "| rev1 = [[AllMusic]]\n",
      "| rev1score = {{rating|3|5}}<ref name=\"Kellman\">Kellman, Andy. [{{Allmusic|class=album|id=r801585|pure_url=yes}} 2005]. [[Allmusic]]. Retrieved on 2012-02-12</ref>\n",
      "| rev2 = ''[[Rolling Stone]]''\n",
      "| rev2score = {{rating|2.5|5}}<ref name=\"Hoard\">Hoard, Christian. [http://www.rollingstone.com/music/albumreviews/chris-brown-20051128]. ''[[Rolling Stone]]''. Retrieved on 2012-02-12</ref>\n",
      "}}\n",
      "'''''Chris Brown''''' is the eponymous debut [[studio album]] by American [[Contemporary R&B|R&B]] recording artist [[Chris Brown]], released on November 29, 2005 in the [[United States]] on [[Jive Records]]. It was a commercial success, certified [[RIAA certification#Albums|2x Platinum]] by the [[Recording Industry Association of America]] (RIAA) for scanning two million in the United States.<ref name=\"Sales\"/> The album also earned Brown his first two [[Grammy Award|Grammy]] nominations for [[Grammy Award for Best New Artist|Best New Artist]] and [[Best Contemporary R&B Album]] at the [[49th Grammy Awards]].\n",
      "\n",
      "==Background==\n",
      "Chris Brown was born on May 5, 1989, in [[Tappahannock, Virginia]], started as a [[rapper]], until Brown took pride in his singing. In 2002, at the age of 13, he was discovered at his father's gas station by a production team, who was looking for local talent. In August 2004, Brown, who had adapted the stage name \"C-Syzle\" and T.J. attracted the attention of Tina Davis, [[Def Jam Recordings]]' senior [[Artist and repertoire|A&R]] executive, and auditioned them in front of [[Island Def Jam Music Group]] CEO [[L.A. Reid|Antonio \"L. A.\" Reid]].<ref name = \"KING\">{{cite web|title = Is Chris Brown Violent?| work =| publisher = ''[[Giant (magazine)|Giant]]''| date =2006-03-02| url = http://giantmag.com/articles/chris-brown-most-likely-to-succeed/| format = Online| accessdate = 2009-08-07 }}</ref><ref name=\"SFGate\">{{cite news|title=Brown runs with it|work=[[Hearst Corporation]]|publisher=[[San Francisco Chronicle]]|url=http://www.sfgate.com/cgi-bin/article.cgi?f=/c/a/2006/10/01/PKG5ULA4C41.DTL&type=music|date=2006-10-01|accessdate=2009-05-28 | first=Lee | last=Hildebrand}}</ref>\n",
      "\n",
      "Afterwards, Reid offered to sign both of them on the spot, but Brown claimed Allen had become \"greedy\" during the prolonged negotiations that spanned in two months.<ref name = \"KING\"/><ref name=\"SFGate\"/> Davis advised Brown not to sign the deal.<ref name = \"KING\"/> Davis later lost her job, due to [[restructuring]], after Island Def Jam and [[Roc-A-Fella Records]] merged.<ref>{{cite web|first = Patrick|last= MacDonald |title=Chris Brown, triple threat: singer, dancer, songwriter|work=[[The Seattle Times]]|publisher=[[The Seattle Times Company]]|url=http://community.seattletimes.nwsource.com/archive/?date=20060324&slug=cbrown24|date=2006-03-24|accessdate=2009-08-07}}</ref> On the same day, Brown hired her as his manager and moved in into her [[New Jersey]]'s home.<ref name = \"KING\"/> After weeks of label searching, Brown had a deal with Jive Records, known for their pop and R&B artists, such as [[Britney Spears]], [[Justin Timberlake]] and [[R. Kelly]] by Christmas Eve 2005.<ref name=\"Times Online\">{{cite news|first = Edgar|last=Eggar |title=The new Michael Jackson|work=[[The Times]]|publisher=[[The Times|Times Online]]|url=http://entertainment.timesonline.co.uk/tol/arts_and_entertainment/music/article728620.ece|date=2006-02-12|accessdate=2009-05-28 | location=London}}{{subscription required}}</ref><ref name=\"SFGate\"/> He also dropped out of tenth grade at his [[Essex High School (Virginia)|Essex High School]] in Virginia, in favor of tutoring. Brown then began recording the album in [[Miami, Florida]] with Mark Pitts, the Jive's A&R, who has signed Brown to the label. At that point, they have recorded about 50 songs, going into his first album. The album was initially titled ''Young Love'', but the idea was discarded as \"too kiddie\".<ref name=\"Coolnight\">{{cite news|title=COOL@NIGHT, CHRIS BROWN: Letting his feet do the talking, Only 16, he has moves like Michael and a No. 1 record|last=Guzmn|first=Rafer|date=April 13, 2006|work=Newsday|publisher=Fred Groser}}</ref>\n",
      "\n",
      "==Music==\n",
      "\"[[Run It!]]\" takes place in a party setting, with Brown explaining, \"It's really a guy checking for a girl, or a girl checking for a guy...asking to see if they can run it. If they can be eligible to be your girlfriend, boyfriend, whatever. 'Let me see if you can run it; show me what you got.'\"<ref name=\"Dancing\">{{cite web|url=http://www.mtv.com/news/articles/1511011/chris-brown-dancing-run-it-up-charts.jhtml|title=Chris Brown Dancing His 'Run It!' Straight Up The Charts|last=Reid|first=Shaheem|date=October 5, 2005|accessdate=June 23, 2012|work=''MTV News''|publisher=Viacom}}</ref>  \"[[Yo (Excuse Me Miss)]]\" discusses the first conversation someone has with a girl: \"Fellas, first thing they say when they see a girl is 'Yo! Yo!'. I'm saying it like that, but technically not like that. She takes my breath away, all I can say is 'Yo, let me just talk to you for a minute. Chill with me for a minute.'\"<ref name=\"Dancing\"/>\n",
      "\n",
      "==Singles==\n",
      "The album's lead single \"Run It!\" featured rapper [[Juelz Santana]] and was produced by [[Scott Storch]]. It received continuous [[airplay (song)|airplay]] (topping the [[Billboard Hot 100 Airplay|''Billboard'' Hot 100 Airplay]]), and reached number one on the [[Billboard Hot 100|''Billboard'' Hot 100]], where it stayed for five weeks. It was preceded by [[Kanye West]] featuring [[Jamie Foxx]]'s \"[[Gold Digger (Kanye West song)|Gold Digger]]\", and was succeeded by [[Mariah Carey]]'s \"[[Don't Forget About Us]]\". It also topped ''Billboard'' [[Pop 100]]. Other singles released from the album include \"[[Yo (Excuse Me Miss)]]\" (another U.S. top ten hit for Brown), the [[remix|remixed]] version of \"[[Gimme That]]\"  featuring rapper [[Lil Wayne]], and the fourth single \"[[Say Goodbye (Chris Brown song)|Say Goodbye]]\" peaked at number ten in the U.S. The fifth and final single from the album, \"[[Poppin' (song)|Poppin']]\", charted outside the U.S. top forty.\n",
      "\n",
      "==Commercial performance==\n",
      "The album debuted at number two on the [[Billboard 200|''Billboard'' 200]] with first-week sales of 154,000 copies.<ref>{{cite web|last=Grein |first=Paul |url=http://new.music.yahoo.com/blogs/chart_watch/74346/week-ending-march-27-2011-albums-chris-browns-recovery/;_ylt=Ak3Hy5O1j1eETJ7pnwB2fWkPwiUv |title=Week Ending March 27, 2011: Albums: Chris Brown's Recovery - Chart Watch |publisher=[[Yahoo! Music]] |date=March 30, 2011 |accessdate=April 19, 2011}}</ref> It was certified [[music recording sales certification|double platinum]] by the [[Recording Industry Association of America]] (RIAA).<ref name=\"RIAA\">{{cite web|url=http://riaa.com/goldandplatinumdata.php?resultpage=1&table=SEARCH_RESULTS&artist=chris%20brown&format=ALBUM&startYear=1958&endYear=2009&sort=Artist&perPage=25|title=RIAA - Gold & Platinum|work=[[Recording Industry Association of America|RIAA]]|accessdate=2009-01-20}}</ref> As of April 2011, the album has sold 2.1 million copies in the United States alone.<ref name=\"Sales\">{{cite web|last=Grein |first=Paul |url=http://new.music.yahoo.com/blogs/chart_watch/74345/week-ending-march-20-2011-songs-the-chris-brown-matter/ |title=Week Ending March 20, 2011: Songs: The Chris Brown Matter |publisher=[[Yahoo! Music]] |date=March 23, 2011 |accessdate=April 19, 2011}}</ref>\n",
      "\n",
      "==Track listing==\n",
      "{{track list\n",
      "| headline        = Standard edition\n",
      "| writing_credits = yes\n",
      "| extra_column = Producer(s)\n",
      "\n",
      "| title1  = Intro\n",
      "| writer1 = {{flatlist|\n",
      "* [[Chris Brown|Christopher Brown]]\n",
      "* Edmund \"Eddie Hustle\" Clement\n",
      "}}\n",
      "| extra1  = Eddie Hustle\n",
      "| length1 = 0:56\n",
      "\n",
      "| title2 = [[Run It!]]\n",
      "| note2   = featuring [[Juelz Santana]]\n",
      "| writer2 = {{flatlist|\n",
      "* [[Scott Storch]]\n",
      "* [[Sean Garrett]]\n",
      "* [[Juelz Santana|LaRon James]]\n",
      "* [[Chris Butler (musician)|Christopher Butler]]\n",
      "}}\n",
      "| extra2 = {{flatlist|\n",
      "* Storch\n",
      "* Garrett*\n",
      "}}\n",
      "| length2 = 3:49\n",
      "\n",
      "| title3 = [[Yo (Excuse Me Miss)]]\n",
      "| writer3 = {{flatlist|\n",
      "* [[Johnt?? Austin]]\n",
      "* [[Dre & Vidal|Andre Harris]]\n",
      "* [[Dre & Vidal|Vidal Davis]]\n",
      "}}\n",
      "| extra3 = [[Dre & Vidal]]\n",
      "| length3 = 3:49\n",
      "\n",
      "| title4 = Young Love\n",
      "| writer4 = {{flatlist|\n",
      "* [[Vinnie Barrett|Vinny Barrett]]\n",
      "* Antonio Dixon\n",
      "* [[Bobby Eli]]\n",
      "* [[Keri Hilson]]\n",
      "* [[Harvey Mason, Jr.]]\n",
      "* [[Patrick M. Smith|Patrick \"J. Que\" Smith]]\n",
      "* Damon Thomas\n",
      "}}\n",
      "| extra4 = {{flatlist|\n",
      "* [[The Underdogs (duo)|The Underdogs]]\n",
      "* Dixon\n",
      "}}\n",
      "| length4 = 3:38\n",
      "\n",
      "| title5  = [[Gimme That]]\n",
      "| writer5 = {{flatlist|\n",
      "* Storch\n",
      "* Garrett\n",
      "}}\n",
      "| extra5  = {{flatlist|\n",
      "* Storch\n",
      "* Garrett*\n",
      "}}\n",
      "| length5 = 3:06\n",
      "\n",
      "| title6  = Ya Man Ain't Me\n",
      "| writer6 = {{flatlist|\n",
      "* Erik Dawkins\n",
      "* Dixon\n",
      "* Thomas\n",
      "* Mason, Jr.\n",
      "* [[Troop (band)|Steve Russell]]\n",
      "* [[Tank (American singer)|Durrell \"Tank\" Babbs]]\n",
      "}}\n",
      "| extra6 = {{flatlist|\n",
      "* The Underdogs\n",
      "* Dixon*\n",
      "}}\n",
      "| length6 = 3:34\n",
      "\n",
      "| title7 = Winner\n",
      "| writer7 = {{flatlist|\n",
      "* Brown\n",
      "* [[Bryan-Michael Cox]]\n",
      "* [[Kendrick Dean|Kendrick \"WyldCard\" Dean]]\n",
      "* [[Adonis Shropshire]]\n",
      "}}\n",
      "| extra7 = {{flatlist|\n",
      "* Cox\n",
      "* [[Kendrick Dean|WyldCard]]*\n",
      "}}\n",
      "| length7 = 4:04\n",
      "\n",
      "| title8 = Ain't No Way (You Won't Love Me)\n",
      "| writer8 = {{flatlist|\n",
      "* Warren \"Oak\" Felder\n",
      "* Zhang Fuquan\n",
      "* Garrett\n",
      "}}\n",
      "| extra8 = {{flatlist|\n",
      "* Garrett\n",
      "* Oak*\n",
      "}}\n",
      "| length8 = 3:23\n",
      "\n",
      "| title9 = What's My Name?\n",
      "| note9 = featuring [[Noah]]\n",
      "| writer9 = {{flatlist|\n",
      "* Brown\n",
      "* [[Cool & Dre|Andre Lyon]]\n",
      "* [[Noah|Stephens Noah]]\n",
      "* [[Cool & Dre|Marcello Valenzano]]\n",
      "}}\n",
      "| extra9 = [[Cool & Dre]]\n",
      "| length9 = 3:52\n",
      "\n",
      "| title10  = Is This Love?\n",
      "| writer10 = {{flatlist|\n",
      "* Dawkins\n",
      "* Dixon\n",
      "* Mason, Jr.\n",
      "* Russell\n",
      "* Thomas\n",
      "}}\n",
      "| extra10  = The Underdogs\n",
      "| length10 = 3:17\n",
      "\n",
      "| title11  = [[Poppin' (song)|Poppin']]\n",
      "| writer11 = {{flatlist|\n",
      "* Austin\n",
      "* Harris\n",
      "* Davis\n",
      "}}\n",
      "| extra11 = Dre & Vidal\n",
      "| length11 = 4:25\n",
      "\n",
      "| title12  = Just Fine\n",
      "| writer12 = {{flatlist|\n",
      "* Brown\n",
      "* Daniel Glass\n",
      "* Lance Bennett\n",
      "* [[Winans family|Mike Winans]]\n",
      "* Peter Zora\n",
      "* Shannon \"Slam\" Lawrence\n",
      "}}\n",
      "| extra12 = {{flatlist|\n",
      "* Bennett\n",
      "* Winans\n",
      "* Lawrence\n",
      "}}\n",
      "| length12 = 3:52\n",
      "\n",
      "| title13  = [[Say Goodbye (Chris Brown song)|Say Goodbye]]\n",
      "| writer13 = {{flatlist|\n",
      "* Cox\n",
      "* Dean\n",
      "* Shropshire\n",
      "}}\n",
      "| extra13  = Cox\n",
      "| length13 = 4:49\n",
      "\n",
      "| title14 = Run It! (Remix)\n",
      "| note14 = featuring [[Bow Wow (rapper)|Bow Wow]] and [[Jermaine Dupri]]\n",
      "| writer14 = {{flatlist|\n",
      "* [[Jermaine Dupri]]\n",
      "* Garrett\n",
      "* [[Bow Wow (rapper)|Shad Moss]]\n",
      "* Storch\n",
      "* [[Darryl McDaniels]]\n",
      "* [[Jam-Master Jay|Jason Mizell]]\n",
      "* [[Joseph Simmons]]\n",
      "* Larry Smith\n",
      "* [[Russell Simmons]]\n",
      "}}\n",
      "| extra14 = {{flatlist|\n",
      "* Dupri^\n",
      "* Storch\n",
      "* [[LRoc]]*^\n",
      "* Garrett*\n",
      "}}\n",
      "| length14 = 4:04\n",
      "\n",
      "| title15 = Thank You\n",
      "| writer15 = {{flatlist|\n",
      "* Brown\n",
      "* Tina Davis\n",
      "* Lamont \"LA\" Fleming\n",
      "* Shea Taylor\n",
      "}}\n",
      "| extra15 = Taylor\n",
      "| length15 = 4:27\n",
      "\n",
      "| title16 = Gimme That (Remix)\n",
      "| writer16 = {{flatlist|\n",
      "* Storch\n",
      "* Garrett\n",
      "* [[Lil Wayne|Dwayne Carter, Jr.]]\n",
      "}}\n",
      "| extra16 = Storch\n",
      "| length16 = 3:56\n",
      "| note16 = featuring [[Lil Wayne]]\n",
      "| total_length = 55:44\n",
      "}}\n",
      "\n",
      "*(*) Denotes co-producer.\n",
      "*(^) Denotes additional producer.\n",
      "\n",
      ";Samples credits\n",
      "*\"Run It!\" contains a portion of the composition from \"[[I Know What Boys Like (song)|I Know What Boys Like]]\" written by [[Chris Butler (musician)|Christopher Butler]], performed by [[The Waitresses]].\n",
      "*\"Young Love\" samples \"[[Sideshow (song)|Sideshow]]\" written by [[Bobby Eli]] and [[Vinnie Barrett|Vinny Barrett]], performed by [[Blue Magic (band)|Blue Magic]].\n",
      "*\"Ain't No Way (You Won't Love Me)\" contains a portion of the composition from \"Song of the Dragon & Phoenix\" written by Zhang Fuquan.\n",
      "*\"Run It! (Remix)\" samples \"Jam-Master Jay\" written by [[Darryl McDaniels]], [[Jam-Master Jay|Jason Mizell]], [[Joseph Simmons]], Larry Smith, [[Russell Simmons]], performed by [[Run-DMC]].\n",
      "\n",
      "==Promotion==\n",
      "Through the winter, Brown joined the Scream V Encore Tour, featuring [[Ciara]], [[Bow Wow (rapper)|Bow Wow]], [[Omarion]] and [[Marques Houston]], as a supporting act. Later, he headlined the [[Xbox 360]] Presents: Chris Brown Tour, supported by [[T-Pain]].\n",
      "\n",
      "==Charts==\n",
      "{|class=\"wikitable\"\n",
      "!Chart (2005)\n",
      "!Peak<br />position\n",
      "|-\n",
      "|[[ARIA Charts|Australian ARIA Album Charts]]<ref>http://pandora.nla.gov.au/pan/23790/20060410-0000/issue833.pdf</ref>\n",
      "|align=\"center\"|57\n",
      "|-\n",
      "|Austrian Albums Chart<ref name=\"acharts\">{{cite web|url=http://acharts.us/album/14236|title=Chris Brown - Chris Brown - Music Charts|work=aCharts|accessdate=2007-12-21}}</ref>\n",
      "|align=\"center\"|66\n",
      "|-\n",
      "|Belgium Albums Chart ([[Flanders]])<ref name=\"acharts\"/>\n",
      "|align=\"center\"|47\n",
      "|-\n",
      "|[[Dutch Albums Chart]]<ref name=\"acharts\"/>\n",
      "|align=\"center\"|47\n",
      "|-\n",
      "|[[European Top 100 Albums]]<ref>{{cite web|url={{BillboardURLbyName|artist=chris brown|chart=European Albums}}|title=European Top 100 Albums - Chris Brown - Chris Brown|work=Billboard|publisher=Nielsen Business Media|accessdate=2009-01-20}} {{Dead link|date=October 2010|bot=H3llBot}}</ref>\n",
      "|align=\"center\"|42\n",
      "|-\n",
      "|French [[Syndicat National de l'??dition Phonographique|SNEP]] Albums Chart<ref name=\"acharts\"/>\n",
      "|align=\"center\"|51\n",
      "|-\n",
      "|German Albums Chart<ref name=\"acharts\"/>\n",
      "|align=\"center\"|31\n",
      "|-\n",
      "|[[Irish Albums Chart]]<ref name=\"acharts\"/>\n",
      "|align=\"center\"|71\n",
      "|-\n",
      "|New Zealand [[Recording Industry Association of New Zealand|RIANZ]] Albums Chart<ref name=\"acharts\"/>\n",
      "|align=\"center\"|8\n",
      "|-\n",
      "|[[Swiss Music Charts|Swiss Albums Chart]]<ref name=\"acharts\"/>\n",
      "|align=\"center\"|18\n",
      "|-\n",
      "|[[UK Albums Chart]]<ref name=\"acharts\"/>\n",
      "|align=\"center\"|29\n",
      "|-\n",
      "{{albumchart|UKR&B|4|date=2006-02-18|accessdate=December 26, 2015|refname=\"UKR&B\"}}\n",
      "|-\n",
      "|US [[Billboard 200|''Billboard'' 200]]<ref name=\"Billboard charts\">{{cite web|url={{BillboardURLbyName|artist=harry lauder|chart=all}}|title=Artist Chart History - Chris Brown - Albums|work=Billboard|publisher=Nielsen Business Media|accessdate=2009-04-12}}</ref>\n",
      "|align=\"center\"|2\n",
      "|-\n",
      "|US [[Top R&B/Hip-Hop Albums]] (''[[Billboard (magazine)|Billboard]]'')<ref name=\"Billboard charts\"/>\n",
      "|align=\"center\"|1\n",
      "|-\n",
      "|US [[Billboard charts|R&B/Hip-Hop Catalog Albums]] ([[Billboard (magazine)|''Billboard'']])<ref>{{cite web | url={{BillboardURLbyName|artist=Chris Brown|chart=R&B/Hip-Hop Catalog Albums}} | title=Chris Brown ??? Chart History: R&B/Hip-Hop Catalog Albums | publisher=[[Prometheus Global Media]] | work=[[Billboard (magazine)|Billboard]] | accessdate=January 20, 2016}}</ref>\n",
      "| style=\"text-align:center;\"|4\n",
      "|}\n",
      "\n",
      "==Certifications==\n",
      "{{certification Table Top}}\n",
      "{{certification Table Entry|type=album|region=Australia|artist=Chris Brown |title=Chris Brown|award=Gold|certyear=2006|relyear=2005|autocat=yes}}\n",
      "{{certification Table Entry|type=album|region=Canada|artist=Chris Brown|title=Chris Brown|award=Gold|relyear=2005|relmonth=11|certyear=2007|certmonth=01|autocat=yes}}\n",
      "{{certification Table Entry|type=album|region=United Kingdom|artist=Chris Brown|title=Chris Brown|award=Gold|certyear=2006|relyear=2005|autocat=yes}}\n",
      "{{certification Table Entry|type=album|region=United States|artist=Chris Brown|title=Chris Brown |award=Platinum|number=2|certyear=2006|relyear=2005|autocat=yes}}\n",
      "{{Certification Table Bottom|format=3col}}\n",
      "\n",
      "==Personnel==\n",
      "{{col-begin}}\n",
      "{{col-2}}\n",
      "*[[Executive producers#Music|Executive producers]]: [[Chris Brown]], Tina Davis, Mark Pitts\n",
      "*Art direction: Courtney Walter\n",
      "*[[Artist and repertoire|A&R]]: Leticia Hilliard, [[Matt Schwartz]]\n",
      "*[[Audio engineering|Assistant recording engineers]]: Val Brathwrite (track 7), Vadim Chislov (2, 5, 16), Anthony G. Crisano (1, 5, 9, 12, 15&ndash;16), Patrick Magee (2, 5, 16), Lucas McLendon (1), Tadd Mingo (14), Aaron Renner (4, 6, 10)\n",
      "*Bass: David Cabrerra (track 9)\n",
      "*Design: Courtney Walter\n",
      "*[[Audio engineering|Recording engineers]]: Wayne Allison (tracks 2, 5, 16), Vincent Dilorenzo (3, 11), Conrad Golding (2, 5, 16), Dabling \"Hobby Boy\" Harward (4, 6, 10), John Horesco IV (14), Eddie Hustle (music 1), Charles McCrorey (2, 5, 9, 16), Oak (8), Carlos Paucar (5, 16), Keith Sengbusch (9, 12), Kelly Sheehan (4, 6, 10), Shea Taylor (15), Sam Thomas (7, 13)\n",
      "*Guitar: Val Brathwrite, Aaron Fishbein (tracks 2, 5, 16), David Cabrerra (9)\n",
      "\n",
      "{{col-2}}\n",
      "\n",
      "*[[Keyboard instrument|Keyboards]]: Kendrick Dean (tracks 7, 13), Shea Taylor (15)\n",
      "*[[Audio mastering|Mastering]]: Herb Powers\n",
      "*Mixing: Kevin \"KD\" Davis (track 8), Vincent Dilorenzo (3, 11), [[Jermaine Dupri]] (14), Jean-Marie Horvat (7, 13), Eddie Hustle (1), Rich Keller (12), Phil Tan (14), The Underdogs (4, 6, 10), Stephen \"Stevo\" George (15), Brian Stanley (2, 5, 9, 16)\n",
      "*Mixing assistant: Val Brathwaite (tracks 2, 5, 16), Steve Tolle (9), Mike Tschupp (2)\n",
      "*Multi instruments: [[Bryan-Michael Cox]] (tracks 7, 13), Vidal Davis (3, 11), Andre Harris (3, 11), Shea Taylor (drum machine 15)\n",
      "*Photography: Clay Patrick McBride\n",
      "*Remix producer: Jermaine Dupri (track 14), L-Rock (14)\n",
      "*Background vocals: Steve Russell (track 10)\n",
      "*Vocal producer: Lamont \"LA\" Flemming (track 15), Shannon \"Slam\" Lawrence (12)\n",
      "*Vocal recording: Charles McCrorey (tracks 1, 15), Stephen \"Stevo\" George (additional 15)\n",
      "*Vocal tracking: Ian Crosse (track 8)\n",
      "\n",
      "{{col-end}}\n",
      "\n",
      "==References==\n",
      "{{reflist}}\n",
      "\n",
      "{{Chris Brown}}\n",
      "\n",
      "{{DEFAULTSORT:Chris Brown (Album)}}\n",
      "[[Category:2005 debut albums]]\n",
      "[[Category:Albums produced by Bryan-Michael Cox]]\n",
      "[[Category:Albums produced by Cool & Dre]]\n",
      "[[Category:Albums produced by Dre & Vidal]]\n",
      "[[Category:Albums produced by Jermaine Dupri]]\n",
      "[[Category:Albums produced by Scott Storch]]\n",
      "[[Category:Albums produced by Sean Garrett]]\n",
      "[[Category:Albums produced by The Underdogs (production team)]]\n",
      "[[Category:Chris Brown albums]]\n",
      "[[Category:Jive Records albums]]\n",
      "[[Category:Zomba Group of Companies albums]]\n",
      "------------\n",
      "\n",
      "\n",
      "<!-- Deleted image removed: [[Image:CattleRestrainedForSlaughter.jpg|thumb|right|300px|Cow restrained for stunning just prior to slaughter.]] -->\n",
      "{{Infobox U.S. legislation\n",
      "| shorttitle        = Humane Slaughter Act\n",
      "| othershorttitles  =\n",
      "| longtitle         = An Act to establish the use of humane methods of slaughter of livestock as a policy of the United States, and for other purposes.\n",
      "| colloquialacronym = \n",
      "| nickname          = Humane Methods of Slaughter Act\n",
      "| enacted by        = 85th\n",
      "| effective date    = August 27, 1958\n",
      "| public law url    = http://www.gpo.gov/fdsys/pkg/STATUTE-72/pdf/STATUTE-72-Pg862.pdf\n",
      "| cite public law   = 85-765\n",
      "| cite statutes at large = {{usstat|72|862}}\n",
      "| acts amended    = \n",
      "| acts repealed   = \n",
      "| title amended   = [[Title 7 of the United States Code|7 U.S.C.: Agriculture]]\n",
      "| sections created = {{Usc-title-chap|7|48}} ?? 1901 et seq.\n",
      "| sections amended = \n",
      "| leghisturl      = \n",
      "| introducedin    = House\n",
      "| introducedbill  = {{USBill|85|H.R.|8308}}\n",
      "| introducedby    = [[William R. Poage]] ([[Democratic Party (United States)|D]]-[[Texas|TX]])\n",
      "| introduceddate  = July 9, 1957\n",
      "| committees      = [[United States House Committee on Agriculture|House Agriculture]], [[United States Senate Committee on Agriculture, Nutrition and Forestry|Senate Agriculture and Forestry]]\n",
      "| passedbody1     = House\n",
      "| passeddate1     = February 4, 1958\n",
      "| passedvote1     = Passed voice vote\n",
      "| passedbody2     = Senate\n",
      "| passedas2       = <!-- used if the second body changes the name of the legislation -->\n",
      "| passeddate2     = July 29, 1958\n",
      "| passedvote2     = [https://www.govtrack.us/congress/votes/85-1958/s258 72-9]\n",
      "| conferencedate  = \n",
      "| passedbody3     = \n",
      "| passeddate3     = \n",
      "| passedvote3     = \n",
      "| agreedbody3     = House\n",
      "| agreeddate3     = August 13, 1958\n",
      "| agreedvote3     = Agreed voice vote\n",
      "| agreedbody4     = <!-- used if agreedbody3 further amends legislation -->\n",
      "| agreeddate4     = <!-- used if agreedbody3 further amends legislation -->\n",
      "| agreedvote4     = <!-- used if agreedbody3 further amends legislation -->\n",
      "| passedbody4     = \n",
      "| passeddate4     = \n",
      "| passedvote4     = \n",
      "| signedpresident = [[Dwight D. Eisenhower]]\n",
      "| signeddate      = August 27, 1958\n",
      "| unsignedpresident = <!-- used when passed without presidential signing -->\n",
      "| unsigneddate    = <!-- used when passed without presidential signing -->\n",
      "| vetoedpresident = <!-- used when passed by overriding presidential veto -->\n",
      "| vetoeddate      = <!-- used when passed by overriding presidential veto -->\n",
      "| overriddenbody1 = <!-- used when passed by overriding presidential veto -->\n",
      "| overriddendate1 = <!-- used when passed by overriding presidential veto -->\n",
      "| overriddenvote1 = <!-- used when passed by overriding presidential veto -->\n",
      "| overriddenbody2 = <!-- used when passed by overriding presidential veto -->\n",
      "| overriddendate2 = <!-- used when passed by overriding presidential veto -->\n",
      "| overriddenvote2 = <!-- used when passed by overriding presidential veto -->\n",
      "| amendments      = \n",
      "| SCOTUS cases    = \n",
      "}}\n",
      "The '''Humane Slaughter Act''',  or the Humane Methods of Livestock Slaughter Act, (P.L. 85-765; 7 U.S.C. 1901 et seq.) is a [[United States federal law]] designed to decrease suffering of livestock during slaughter.  It was approved on August 27, 1958.<ref>{{cite web|url=http://constitution.org/uslaw/sal/072_statutes_at_large.pdf#page=893| title = To establish the use of humane methods of slaughter of livestock as a policy of the United States, and for other purposes.|accessdate= 2013-06-12}}</ref> The most notable of these requirements is the need to have an animal completely sedated and insensible to pain. This is to minimize the suffering to the point where the animal feels nothing at all, instead losing a consciousness from which it will never awaken. This differs from animal to animal as size increases and decreases. Larger animals such as bovine require a stronger method than chickens, for example. Bovine require electronarcosis or something equally potent, though electronarcosis remains a standard. The bovine would have a device placed on its head that, once activated, sends an electric charge that efficiently and safely stuns the animal.<ref>{{cite web|last=Anil|first=Haluk|title=Religious slaughter: A current controversial animal welfare issue|url=http://www.animalfrontiers.org/content/2/3/64.full|publisher=Animal Frontiers}}</ref> Chickens, on the other hand, require much less current to be efficiently sedated and are given a run under electrically charged water. To ensure that these guidelines are met, The [[Food Safety and Inspection Service]] inspectors at slaughtering plants are responsible for overseeing compliance, and have the authority to stop slaughter lines and order plant employees to take corrective actions. Although more than 168 million chickens (excluding broilers) and around 9 billion broiler chickens are killed for food in the United States yearly,<ref>{{cite web|url = http://usda.mannlib.cornell.edu/usda/current/PoulProdVa/PoulProdVa-05-29-2009.pdf | title = Chickens: Lost, Sold for Slaughter, Price, and Value,by State, United States, and Puerto Rico, 2007 |date = May 2009| accessdate=2009-12-09}} {{Dead link|date=October 2010|bot=H3llBot}}</ref> the Humane Slaughter Act specifically mentions only cattle, calves, horses, mules, sheep and swine.<ref>{{cite web|url=http://www.animallaw.info/statutes/stusfd7usca1901.htm| title = Humane Slaughter Act |accessdate= 2008-12-09}}</ref>\n",
      "\n",
      "Due to several reports of alleged non-compliance with these regulations and safety protocols, originating in the early 2000s, specifically late 2002 {{citation needed|date=November 2014}}. This caused the FSIS to assign additional veterinarians to various district offices to allow monitoring and  alleging significant non-compliance, FSIS assigned additional veterinarians to its district offices specifically to monitor slaughter and handling procedures and to report to their headquarters about any issues of compliance. This has been the case ever since, as Congress passed a bill in 2002, The [[2002 farm bill]], that requires a compliance report to be submitted annually. In 2003, the initiative increased further as, in the FY in 2003, Congress voted in another $5 million operation to the FSIS effort and increased the amount of compliance inspectors by 50. Language in the FY 2004 consolidated appropriations act directs FSIS to continue fulfilling that mandate, and the FY2005 budget request calls for another $5 million to be allocated for enforcement activities. Despite these requirements in place, reports from January 2004 [[GAO]] have noted that there is still alleged non-compliance. These were narrowed down to select states that issues of non-compliance still allegedly persist (GAO-04-247).  Earlier concerns about humane treatment of non-ambulatory ([[downed cattle|downer]]) cattle at slaughter houses became irrelevant  when FSIS issued regulations in January 2004 (69 FR 1892) prohibiting them from being slaughtered and inspected for use as human food.<ref>[http://ncseonline.org/nle/crsreports/05jun/97-905.pdf CRS Report for Congress: Agriculture: A Glossary of Terms, Programs, and Laws, 2005 Edition - Order Code 97-905]</ref>\n",
      "\n",
      "==Content of the Humane Slaughter Act==\n",
      "\n",
      "''7 U.S.C.A. ?? 1902. Humane methods''\n",
      "\n",
      "''No method of slaughtering or handling in connection with slaughtering shall be deemed to comply with the public policy of the United States unless it is humane. Either of the following two methods of slaughtering and handling are hereby found to be humane:''\n",
      "\n",
      "''(a) in the case of cattle, calves, horses, mules, sheep, swine, and other livestock, all animals are rendered insensible to pain by a single blow or gunshot or an electrical, chemical or other means that is rapid and effective, before being shackled, hoisted, thrown, cast, or cut.\n",
      "\n",
      "''(b) by slaughtering in accordance with the ritual requirements of the Islamic and Jewish faith or any other religious faith that prescribes a method of slaughter whereby the animal suffers loss of consciousness by anemia of the brain caused by the simultaneous and instantaneous severance of the carotid arteries with a sharp instrument and handling in connection with such slaughtering.''\n",
      "\n",
      "According to the law, animals should be stunned into unconsciousness prior to their slaughter to ensure a death with less suffering than in killing methods used earlier.  The most common methods are electrocution and CO2 stunning for swine and [[Captive bolt pistol|captive bolt stunning]] for cattle, sheep, and goats. Of these methods of electrocution, [[electronarcosis]] has been widely acclaimed as the safest, most humane and most reliable as well as the surest way to stun the animal and render it insensitive to pain. Organizations such as the Egyptian Fatwa Committee have mutually agreed to this method when of keeping the standards of Halal a concern. Electronarcosis does not infringe on these standards for Halal.<ref>Egyptian fatwa Committee, December 18th 1978, [http://www.organic-halal-meat.com/article/fatwa-stunning.php \"The Opinions of the Ulema on the Permissibility of Stunning Animals\"], ''Organic Halal Meat.', 1978</ref> Frequent on-site monitoring is necessary, as is the employment of skilled and well-trained personnel.  An animal is considered properly stunned when there is no \"righting reflex\"; that is, the animal must not try to stand up and right itself.  Only then can it be considered fully unconscious.  It can then proceed down the line, where works in slaughterhouses can begin the slaughtering of the specified livestock animal.\n",
      "\n",
      "For religious sects to proceed in the slaughtering of animals under specifically related rituals, they must fall within compliance of the previously mentioned criterion. No religion is exempt and all animals due to be slaughtered must be rendered insensible before hand. Many religions find these regulations to fall within their own guidelines as appropriate. The two most common religious slaughter methods in the United States are the method of [[kosher]], of the Jewish faith and the method of Halal, of the Muslim faith. While all require that the animal be killed through ritual slaughter, proponents of certain religious-based slaughter methods claim that the severing of the animal's [[carotid arteries]], jugular veins and vagus nerve renders the animal unconscious as effectively than most other methods, but has yet to be proven.\n",
      "\n",
      "==History of the Humane Slaughter Act==\n",
      "\n",
      "===1958===\n",
      "The first version of the HMSLA was passed in 1958.  Public demand for the act was so great that when asked at a press conference whether he would sign it, President [[Dwight D. Eisenhower]] stated, \"If I went by mail, I???d think no one was interested in anything but humane slaughter.\"\n",
      "Senator Hubert H. Humphrey was the author of the first humane slaughter bill introduced in the US Congress and chief Senate sponsor of the Federal Humane Slaughter Act, which passed in 1958.  National organizations like the [[Animal Welfare Institute]] and [[The Humane Society of the United States]] supported its passage.\n",
      "\n",
      "===1978===\n",
      "In 1979, the HMSLA was updated and [[United States Department of Agriculture]] (USDA) inspectors were given the authority to stop the slaughtering line when cruelty was observed. Officially, slaughtering was not to continue until said cruelty, whether as a result of equipment or of abuses by personnel, was corrected. However, the USDA eventually stopped authorizing USDA inspectors to stop the line, since doing so incurs considerable cost of time for the industry.{{citation needed|date=June 2012}}\n",
      "\n",
      "===2002===\n",
      "On May 13, 2002 President [[George W. Bush]] signed the Farm Bill (Public Law 107-171) into law which contains an amendment (section 10305) stating that it was \"the sense of Congress that the Secretary of Agriculture should fully enforce\" the Humane Slaughter Act.\n",
      "\n",
      "When introducing the Resolution on the Senate floor, Senator [[Peter Fitzgerald (politician)|Peter Fitzgerald]] said:\n",
      "\n",
      "{{quote|On April 10, 2001, the [[Washington Post]] printed a front page story entitled \"They Die Piece by Piece.\" This graphic article asserted that the United States Department of Agriculture was not appropriately enforcing the Humane Slaughter Act. In response, I am introducing this resolution that encourages the Secretary of Agriculture to fully enforce current law including the Humane Slaughter Act of 1958, as amended by the [[Federal Meat Inspection Act]] in 1978.\n",
      "\n",
      "The Humane Slaughter Act requires that animals be rendered insensible to pain before they are slaughtered. However, there are continual reports of alleged non-compliance. For example, the Washington Post has reported that \"enforcement records, interviews, videos and worker affidavits describe repeated violations of the Humane Slaughter Act\" and \"the government took no action against a [[Texas]] beef company that was cited 22 times in 1998 for violations that include chopping hooves off live cattle\".}}\n",
      "\n",
      "===Amendments to 1958 Act===\n",
      "U.S. Congressional amendments and legislative authority pertaining to the Humane Slaughter Act of 1958.\n",
      "{|style=\"border:1px solid gray; align:left; width:70%\" cellspacing=3 cellpadding=0\n",
      "|-style=\"font-weight:bold; text-align:center; background:#6FF; color:black;\"\n",
      "! style=\" border-bottom:1.5px solid black\"|Date of Enactment\n",
      "! style=\" border-bottom:1.5px solid black\"|Public Law Number\n",
      "! style=\" border-bottom:1.5px solid black\"|U.S. Statute Citation\n",
      "! style=\" border-bottom:1.5px solid black\"|U.S. Legislative Bill\n",
      "! style=\" border-bottom:1.5px solid black\"|U.S. Presidential Administration\n",
      "|-\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5;\"|June 29, 1960\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5; text-align:center;\"|P.L. 86-547\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5; text-align:center;\"|{{usstat|74|255}}\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5; text-align:center;\"|{{USBill|86|H.R.|12705}}\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5; text-align:center;\"|Dwight D. Eisenhower\n",
      "|-\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5;\"|October 10, 1978\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5; text-align:center;\"|P.L. 95-445\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5; text-align:center;\"|{{usstat|92|1069}}\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5; text-align:center;\"|{{USBill|95|S.|3092}}\n",
      "| style=\"border-bottom:1px solid gray; background:#F5F5F5; text-align:center;\"|Jimmy E. Carter\n",
      "|-\n",
      "| style=\"border-bottom:1.5px solid black; background:#F5F5F5;\"|May 13, 2002\n",
      "| style=\"border-bottom:1.5px solid black; background:#F5F5F5; text-align:center;\"|P.L. 107-171\n",
      "| style=\"border-bottom:1.5px solid black; background:#F5F5F5; text-align:center;\"|{{usstat|116|134}}\n",
      "| style=\"border-bottom:1.5px solid black; background:#F5F5F5; text-align:center;\"|{{USBill|107|H.R.|2646}}\n",
      "| style=\"border-bottom:1.5px solid black; background:#F5F5F5; text-align:center;\"|George W. Bush\n",
      "|}\n",
      "\n",
      "==Criticism of the HMSLA==\n",
      "\n",
      "===Exclusionary policies===\n",
      "The HMSLA is criticized by [[animal rights]] advocates and the [[Humane Society of the United States]] for only including cattle, pigs, and sheep but not [[poultry]], [[fish]], [[rabbit]]s or other animals routinely slaughtered for food. After a 2004 [[People for the Ethical Treatment of Animals|PETA]] undercover investigation which publicized abuse of chickens by employees of a [[West Virginia]] [[Pilgrim's Pride]] slaughterhouse that supplied chickens to [[KFC]], PETA was joined by the Humane Society in calling for the Humane Slaughter Act to be expanded to include birds.<ref name=\"pilgrim's pride\">{{cite news\n",
      "|url= http://www.nytimes.com/2004/07/25/weekinreview/the-nation-gaining-ground-at-last-a-company-takes-peta-seriously.html\n",
      "|title= The Nation: Gaining Ground; At Last, a Company Takes PETA Seriously\n",
      "|accessdate= 2009-07-30\n",
      "|date= 2004-07-25\n",
      "|publisher= The New York Times\n",
      "| first=Donald G.\n",
      "| last=McNeil Jr}}</ref>\n",
      "\n",
      "==See also==\n",
      "* [[Animal law]]\n",
      "*[[Animal rights]]\n",
      "*[[Factory farming]]\n",
      "*[[Dhabihah|Islamic ritual slaughter]]\n",
      "* [[Animal slaughter]]\n",
      "\n",
      "==Footnotes==\n",
      "{{Reflist|3}}\n",
      "\n",
      "==External links==\n",
      "{{More footnotes|date=February 2008}}\n",
      "* [http://www.fsis.usda.gov/oa/Congress/hhand2003.htm 2003 Report from the USDA]\n",
      "* {{cite web |url=http://www.animallaw.info/statutes/stusfd7usca1901.htm |title=Statute in Full at Animallaw.info |website=Animal Legal and Historical Center |publisher=Michigan State University College of Law}}\n",
      "* [http://www.goveg.com/government_hsa.asp Criticism of the HMSLA from an animal rights perspective]\n",
      "* [http://www.hsus.org/farm_animals/factory_farms/slaughter_and_animal_welfare/ Criticism of the HMSLA from the HSUS]\n",
      "* [http://cyberactivist.blogspot.com/ Blog of Former Slaughterhouse Worker, Virgil Butler]\n",
      "* {{cite web |url=http://www.hfa.org/slaughterhouse.html |title=Humane Farm Association USDA Petition, with Quotes from USDA Inspectors and Slaughterhouse Workers |website=HFA Campaign Against Factory Farming |publisher=Humane Farming Association}}\n",
      "* {{cite web |url=http://www.fsis.usda.gov/wps/portal/fsis/topics/regulatory-compliance/humane-handling |title=Humane Methods of Livestock Slaughter |website=Food Safety and Inspection Service |publisher=United States Department of Agriculture}}\n",
      "\n",
      "[[Category:1958 in law]]\n",
      "[[Category:United States federal agriculture legislation]]\n",
      "[[Category:Meat processing in the United States]]\n",
      "[[Category:Law articles needing an infobox]]\n",
      "[[Category:Animal rights and welfare legislation in the United States]]\n",
      "------------\n",
      "\n",
      "\n",
      "{{Use dmy dates|date=October 2014}}\n",
      "{{Infobox UK school\n",
      "| name         = The Bicester School\n",
      "| image        = BicesterCommunityCollege.png\n",
      "| size         = 100px\n",
      "| latitude     = 51.900813\n",
      "| longitude    = -1.160806\n",
      "| dms          =\n",
      "| motto        = Aspire and Achieve\n",
      "| motto_pl     =\n",
      "| established  = 1966\n",
      "| approx       =\n",
      "| closed       =\n",
      "| c_approx     =\n",
      "| type         = [[Academy (English school)|Academy]]\n",
      "| religion     =\n",
      "| president    =\n",
      "| head_label   = Headteacher\n",
      "| head         = Mr Tony Rushworth\n",
      "| r_head_label =\n",
      "| r_head       =\n",
      "| chair_label  =\n",
      "| chair        =\n",
      "| founder      =\n",
      "| founder_pl   =\n",
      "| street       = Queen's Avenue\n",
      "| city         = [[Bicester]]\n",
      "| county       = [[Oxfordshire]]\n",
      "| country      = [[England]]\n",
      "| postcode     = OX26 2NS\n",
      "| LEA          = [[Oxfordshire County Council|Oxfordshire]]\n",
      "| ofsted       = yes\n",
      "| dfeno        = 931/4011\n",
      "| urn          = 142024\n",
      "| old_urn      = 123233\n",
      "| enrollment   = 989 (May 2014)\n",
      "| gender       = [[Coeducation|Co-educational]]\n",
      "| lower_age    = 11\n",
      "| upper_age    = 18\n",
      "| houses       =\n",
      "| colours      = [[Burgundy (color)|Burgundy]] {{color box|#800020}}\n",
      "| publication  =\n",
      "| free_label_1 =\n",
      "| free_1       =\n",
      "| free_label_2 =\n",
      "| free_2       =\n",
      "| free_label_3 =\n",
      "| free_3       =\n",
      "| website      = http://www.thebicesterschool.org.uk/\n",
      "| website_name = The Bicester School\n",
      "}}\n",
      "\n",
      "'''The Bicester School''' (previously Bicester Community College) is a mixed, multi-heritage, [[secondary school]], with around 963 students (including a [[sixth form]]). It is situated in [[Bicester]], [[Oxfordshire]], [[England]], and occupies a {{convert|32|acre|m2|sing=on}} site leading off Queens Avenue.\n",
      "\n",
      "The school's sports facilities are used by [[Bicester Athletic Club]], which has been awarded [[National Lottery (United Kingdom)|National Lottery]] funding to add all{{nbhyph}}weather surfaces to the sports field's jumping and throwing event areas.<ref>{{cite press release \n",
      "| title= Bicester Athletic Club scoop Thames Valley public TV vote and Lottery cash \n",
      "| publisher=Big Lottery Fund \n",
      "| date= 30 November 2007 \n",
      "| url = http://www.biglotteryfund.org.uk/global-content/press-releases/england/south-east/bicester-athletic-club-scoop-thames-valley-public-tv-vote-and-lottery-cash\n",
      "| accessdate=7 March 2013}}</ref>\n",
      "\n",
      "==History==\n",
      "The Bicester School was formed as a new comprehensive school in 1966. It was created by the merger of Highfield Secondary Modern School and Bicester Grammar School, who had shared the current site since 1963. Bicester Grammar School had previously been situated at the junction of London Road and Launton Road.<ref>{{cite news \n",
      "|url=http://www.bicesteradvertiser.net/archive/2000/12/08/Oxfordshire+Archive/6625367.Revamp_starts_after_20_years/ \n",
      "|title=Revamp starts after 20 years \n",
      "|publisher=Bicester Advertiser \n",
      "|date={{date|2000-12-08}} \n",
      "| accessdate={{date|2007-12-19}}}}</ref><ref>{{cite news |url=http://www.oxfordtimes.co.uk/archive/2002/04/23/Oxfordshire+Archive/6594820.Former_pupils_reunite/ |title=Former pupils reunite |publisher=[[The Oxford Times]] |date={{date|2002-04-23}} | accessdate={{date|2007-12-19}}}}</ref>\n",
      "\n",
      "The school has been a Government-designated [[Specialist school|specialist]] [[Technology College]] since 1998. In May 2011 Bicester Community College received the Most Improved Award from the Specialist Schools and Academies Trust (SSAT) for improving its GCSE results by 20 percentage points from 2007&ndash;2010. The college received congratulations for significantly improving its 5+ A*&ndash;C results including GCSE English and Mathematics.\n",
      "\n",
      "At the previous inspection in October 2010 the 963-pupil school was deemed satisfactory. The latest [[Ofsted]] inspection that took place on 6 and 7 December in 2012 has revealed that Bicester Community College, overall, falls under the inadequate category. Inadequate is the lowest of all four tiers ranked by Ofsted, with the other tiers being \"Requires improvement\" ( previously \"Satisfactory\"), \"Good\" and \"Outstanding.\"\n",
      "\n",
      "Achievement of pupils, quality of teaching, behaviour and safety of pupils and leadership and management were deemed level four on the scale of one to four, with four being the worst category (inadequate). Principal Jason Clarke has responded to the report, stating that \"[the school is] very disappointed by the outcome of the inspection and the impact it may have on hard work undertaken since the last inspection two years ago. The report acknowledges the recent positive impact of many initiatives currently in place and under way. My greatest disappointment is the grade for behaviour, which does not truly reflect the positive attitude and pride the vast majority of our students have for their school.\"\n",
      "\n",
      "The school was put in [[special measures]] in February 2013.<ref>{{cite news\n",
      "| url        = http://www.bicesteradvertiser.net/news/10202583.School_placed_in_special_measures/?ref=nt\n",
      "| title      = School placed in special measures\n",
      "| date       = 2 February 2013\n",
      "| accessdate = 7 March 2013\n",
      "| newspaper  = Bicester Advertiser\n",
      "| publisher  = Newsquest (Oxfordshire & Wiltshire) Ltd\n",
      "}}</ref>\n",
      "\n",
      "Oxfordshire county council subsequently asked the Department for Education for permission to remove the board of governors, with the request being granted on Thursday 21 February 2013. A new five person interim executive board (IEB) was put in place to oversee the school.<ref>http://www.bicesteradvertiser.net/news/10241101.Head_apologises_as_council_sacks_Bicester_college_governors/</ref>\n",
      "\n",
      "On Monday 18 March 2013 the Principal Jason Clarke left the school by mutual agreement with the IEB. The IEB announced the appointment of neighbouring Cooper School head Ben Baxter as interim head from Monday 15 April.<ref>http://www.bicesteradvertiser.net/news/10295312.Bicester_college_head_leaves_after_Ofsted_slating/?action=success</ref>\n",
      "\n",
      "A school inspection on 21 and 22 May 2014 rated the school \"Good\" in all categories. The requirement for special measures was removed. <ref> {{cite web|title=Inspection report: Bicester Community College, 21???22 May 2014|url=http://www.ofsted.gov.uk/provider/files/2394805/urn/123233.pdf|publisher=Ofsted|accessdate=11 September 2014}}</ref>\n",
      "\n",
      "In August 2015 Bicester Community College converted to [[Academy (English school)|academy status]] and was renamed The Bicester School. The school is now sponsored by [[Activate Learning]].\n",
      "\n",
      "==Performance==\n",
      "Bicester Community College students achieved their best-ever results in 2010.\n",
      "\n",
      "===GCSE===\n",
      "'''Examination Performance 2010'''\n",
      "* Students achieving at least five A* to Cs GCSEs 69% \n",
      "* Students achieving at least five A* to Cs GCSEs including English and Maths 55%  \n",
      "* Students achieving at least five A* to Gs GCSEs  99%\n",
      "\n",
      "===Sixth Form 2010 Success===\n",
      "* A Level Grades awarded at D or E  0.98%  \n",
      "* A Levels awarded at f grade  78%  \n",
      "\n",
      "The [[college]] gained School Achievement awards in 2001 and 2002 in recognition of the significant improvements in its examination results.<ref>{{cite web |url=http://www.teachernet.gov.uk/docbank/index.cfm?id=1284 |title=2001 winners of the School Achievement Award (Round One) |publisher=[[Department for Children, Schools and Families]] |accessdate={{date|2007-12-14}}}}</ref><ref>{{cite web |url=http://www.teachernet.gov.uk/management/payandperformance/schoolachievementawards/round2search/index.cfm |title=Bicester College 2002 School Achievement Award (Round Two) |accessdate={{date|2007-12-14}}}}</ref> In 2006 Bicester achieved membership of the Most Improved Specialist Schools Club after the number of pupils getting five or more A**ndash;C grades at [[General Certificate of Secondary Education|GCSE]] rose from 40 per cent in 2002 to 50 per cent in 2005.<ref>{{cite news |url=http://www.oxfordtimes.co.uk/archive/2006/01/26/Oxfordshire+Archive/6644960.School_among_most_improved/ |title=School among most improved |publisher=[[The Oxford Times]] |date=26 January 2006 | accessdate=7 March 2013}}</ref> The results dropped in 2006 with only 36 per cent achieving the benchmark five or more GCSE passes at A*&ndash;C,<ref>{{cite news |url=http://www.oxfordmail.co.uk/news/yourtown/bicester/990326.Business_alarm_at_bad_GCSE_results_for_town/ |title=Business alarm at bad GCSE results for town |publisher=[[The Oxford Times|Oxford Mail]] |date={{date|2006-10-27}} |accessdate={{date|2007-12-18}}}}</ref> but the 2007 results were a significant improvement with 52 per cent gaining five or more GCSE passes at the appropriate grades.<ref>{{cite news \n",
      "| url       = http://education.guardian.co.uk/secondaries/tables/0,,2237859,00.html\n",
      "| title     = 2007 GCSE and A-level tables\n",
      "| publisher = Guardian News and Media Limited 2011\n",
      "| newspaper = The Guardian\n",
      "| accessdate=7 March 2013}}</ref>\n",
      "\n",
      "There have been successful Oxbridge applications from the school in the last ten years, and the school has sent students to other top UK universities, including [[King's College London]], the [[London School of Economics and Political Science]], [[University College London]], the [[University of Warwick]], the [[University of Bristol]] and the [[University of Nottingham]]. The [[University of Reading]], [[Coventry University]], the [[University of Southampton]], [[Oxford Brookes University]] and [[Nottingham Trent University]] are also popular destinations for former students of the school.{{Citation needed|date=January 2008}}\n",
      "\n",
      "==Performing arts==\n",
      "In 2008 the college was awarded the [[Artsmark]] Gold Award in recognition of its achievements in the arts.\n",
      "\n",
      "Bicester Community College has a performing arts department, with a jazz band, choirs, wind band, string orchestra, chamber ensembles, a boys' dance company and dance clubs.<ref>{{cite news |url=http://www.bbc.co.uk/oxford/content/articles/2007/07/12/bicester_jazz.shtml |title=Bicester Community College Jazz |first=Tim |last=Bearder |publisher=BBC |date={{date|2007-12-07}} |accessdate={{date|2007-12-18}}}}</ref>\n",
      "\n",
      "The orchestra and jazz band went on a trip to Germany in July 2007, performing three concerts.<ref>{{cite news |url=http://bicester.casualrain.com/BCC-HC/parts/tour.html |title=Bicester Community College Music Tour |first=Helen |last=Comley |publisher=BCC |date={{date|2008-01-09}} |accessdate={{date|2008-01-09}}}}</ref>\n",
      "\n",
      "The orchestra and jazz band also visited Belgium in July 2009, performing at various venues and events, including The Last Post Ceremony at Menin Gate, Ypres. \n",
      "\n",
      "Music and dance groups from the school performed at the [[MAD about Waddesdon]] festival in June 2010.<ref>{{cite web|url=http://madaboutwaddesdon.waddesdon.org.uk/sunday_programme.html|title=MAD about Waddesdon &ndash; Sunday Programme|accessdate={{date|2009-06-17}}| archiveurl= http://web.archive.org/web/20090627135145/http://madaboutwaddesdon.waddesdon.org.uk/sunday_programme.html| archivedate= 27 June 2009 <!--DASHBot-->| deadurl= no}}</ref>\n",
      "\n",
      "The department has put on shows, including ''Grease'' in 2006,''The Sound of Music'' in 2007 and ''High School Musical'' in February 2008, ''Les Miserables'' in 2009 and ''Bugsy Malone'' in 2010.<ref>{{cite news |url=http://bicester.casualrain.com/BCC-HC/parts/revs.html |title=Bicester Community College Performing Arts Reviews |first=Helen |last=Comley |publisher=BCC |date={{date|2008-01-09}} |accessdate={{date|2008-01-09}}}}</ref>\n",
      "\n",
      "==References==\n",
      "{{reflist|2}}\n",
      "\n",
      "==External links==\n",
      "*[http://thebicesterschool.org.uk/ The Bicester School official website]\n",
      "\n",
      "{{Schools in Oxfordshire}}\n",
      "\n",
      "{{DEFAULTSORT:Bicester School}}\n",
      "[[Category:Secondary schools in Oxfordshire]]\n",
      "[[Category:Educational institutions established in 1966]]\n",
      "[[Category:Bicester]]\n",
      "[[Category:1966 establishments in England]]\n",
      "[[Category:Academies in Oxfordshire]]\n",
      "------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in wiki_df.select('text').take(4):\n",
    "\n",
    "    print(i.text)\n",
    "    print('------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, IDF, Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Natural Language Processing: RegexTokenizer: Convert the lowerText col to a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = (\n",
    "\n",
    "    RegexTokenizer()\n",
    "    .setInputCol(\"text\")\n",
    "    .setOutputCol(\"words\")\n",
    "    .setPattern(r'\\W+') #dvidimos el texto en una lista por cuaquier caracter no alfanumerico\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_words_df = tokenizer.transform(wiki_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- lastrev_pdt_time: timestamp (nullable = true)\n",
      " |-- revid: long (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- contributorid: long (nullable = true)\n",
      " |-- contributorusername: string (nullable = true)\n",
      " |-- contributorip: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wiki_words_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['infobox', 'radio', 'station', 'name', 'kig60', 'burlington',\n",
       "       'all', 'hazards', 'image', 'image', 'noaa', 'all', 'hazards',\n",
       "       'svg', '150px', 'city', 'burlington', 'vermont', 'area',\n",
       "       'burlington', 'vermont', 'metropolitan', 'area', 'burlington',\n",
       "       'metro', 'branding', 'noaa', 'weather', 'radio', 'all', 'hazards',\n",
       "       'noaa', 'all', 'hazards', 'radio', 'slogan', 'the', 'voice', 'of',\n",
       "       'the', 'national', 'weather', 'service', 'airdate', 'language',\n",
       "       'american', 'english', 'english', 'frequency', '162', '400',\n",
       "       'megahertz', 'mhz', 'format', 'weather', 'radio', 'weather',\n",
       "       'civil', 'emergency', 'power', '500', 'watt', 's', 'erp', 'haat',\n",
       "       'class', 'c', 'callsign_meaning', 'former_callsigns', 'owner',\n",
       "       'national', 'oceanic', 'and', 'atmospheric', 'administration',\n",
       "       'noaa', 'national', 'weather', 'service', 'webcast', 'website',\n",
       "       'http', 'www', 'erh', 'noaa', 'gov', 'btv', 'www', 'erh', 'noaa',\n",
       "       'gov', 'btv', 'affiliations', 'kig60', 'sometimes', 'referred',\n",
       "       'to', 'as', 'burlington', 'all', 'hazards', 'is', 'a', 'noaa',\n",
       "       'weather', 'radio', 'all', 'hazards', 'noaa', 'weather', 'radio',\n",
       "       'station', 'that', 'serves', 'the', 'burlington', 'vermont',\n",
       "       'metropolitan', 'area', 'burlington', 'metropolitan', 'area',\n",
       "       'and', 'surrounding', 'cities', 'the', 'broadcasts', 'can', 'also',\n",
       "       'be', 'heard', 'throughout', 'southern', 'parts', 'of', 'quebec',\n",
       "       'and', 'ontario', 'it', 'is', 'programmed', 'from', 'the',\n",
       "       'national', 'weather', 'service', 'forecast', 'office', 'in',\n",
       "       'burlington', 'vermont', 'with', 'its', 'transmitter', 'located',\n",
       "       'in', 'mount', 'mansfield', 'mt', 'mansfield', 'it', 'broadcasts',\n",
       "       'weather', 'and', 'hazard', 'information', 'for', 'addison',\n",
       "       'county', 'vermont', 'addison', 'chittenden', 'county', 'vermont',\n",
       "       'chittenden', 'franklin', 'county', 'vermont', 'franklin', 'grand',\n",
       "       'isle', 'county', 'vermont', 'grand', 'isle', 'lamoille', 'county',\n",
       "       'vermont', 'lamoille', 'and', 'washington', 'county', 'vermont',\n",
       "       'washington', 'counties', 'in', 'vermont', 'plus', 'clinton',\n",
       "       'county', 'new', 'york', 'clinton', 'essex', 'county', 'new',\n",
       "       'york', 'essex', 'franklin', 'county', 'new', 'york', 'franklin',\n",
       "       'and', 'st', 'lawrence', 'county', 'new', 'york', 'st', 'lawrence',\n",
       "       'counties', 'in', 'new', 'york', 'external', 'links', 'http',\n",
       "       'www', 'erh', 'noaa', 'gov', 'btv', 'nwr', 'nws', 'burlington',\n",
       "       'noaa', 'weather', 'radio', 'info', 'http', 'www', 'nws', 'noaa',\n",
       "       'gov', 'nwr', 'maps', 'php', 'site', 'php', 'state', 'vt', 'site',\n",
       "       'kig60', 'kig', '60', 'maps', 'details', 'burlington',\n",
       "       'plattsburgh', 'radio', 'coord', 'missing', 'vermont', 'category',\n",
       "       'radio', 'stations', 'in', 'vermont', 'kig60', 'category', 'noaa',\n",
       "       'weather', 'radio', 'vermont', 'radio', 'station', 'stub'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(wiki_words_df.select(\"words\").first()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Natural Language Processing: StopWordsRemover: Remove Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover().setInputCol(\"words\").setOutputCol(\"noStopWords\") #quitamos los stopWords en ingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_words_list_df = remover.transform(wiki_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- lastrev_pdt_time: timestamp (nullable = true)\n",
      " |-- revid: long (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- contributorid: long (nullable = true)\n",
      " |-- contributorusername: string (nullable = true)\n",
      " |-- contributorip: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- noStopWords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_stop_words_list_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|      id|               title|               words|         noStopWords|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|33235801|               KIG60|[infobox, radio, ...|[infobox, radio, ...|\n",
      "| 3484057| Chris Brown (album)|[infobox, album, ...|[infobox, album, ...|\n",
      "| 2872543|Humane Slaughter Act|[deleted, image, ...|[deleted, image, ...|\n",
      "| 8100880| The Bicester School|[use, dmy, dates,...|[use, dmy, dates,...|\n",
      "|32693240|Siege of Nagykanizsa|[refimprove, date...|[refimprove, date...|\n",
      "|17074415|      Andr??s Roemer|[use, mdy, dates,...|[use, mdy, dates,...|\n",
      "|47835010|               Karie|[infobox, film, n...|[infobox, film, n...|\n",
      "| 6100355|   Ois??n McConville|[infobox, gaa, pl...|[infobox, gaa, pl...|\n",
      "|18799478|        Remetea Mare|[refimprove, date...|[refimprove, date...|\n",
      "|  722668|Greece national f...|[about, the, men,...|[men, team, women...|\n",
      "| 1300969|United States pre...|[main, united, st...|[main, united, st...|\n",
      "| 1825388|       Orifice plate|[image, blende, e...|[image, blende, e...|\n",
      "| 5952590|    Avigdor Kahalani|[blp, sources, da...|[blp, sources, da...|\n",
      "| 5990609|        Alfred Pfaff|[infobox, footbal...|[infobox, footbal...|\n",
      "|  228180|          Hideo Nomo|[infobox, basebal...|[infobox, basebal...|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_stop_words_list_df.select(\"id\", \"title\", \"words\", \"noStopWords\").show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT words)|\n",
      "+---------------------+\n",
      "|              3720161|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_stop_words_list_df.select(F.explode('noStopWords').alias('words')).select(F.countDistinct('words')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: HashingTF\n",
    "\n",
    "![](img/tf-idf.png)\n",
    "\n",
    "[*HashingTF*](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) es una técnica empleada para no tener que calcular la matriz *term frequency* completa, por métodos de hashing conseguimos resultados muy cercanos con una *performance* de cálculo mucho más rápida y paralelizable.\n",
    "PESAN MAS LAS PALABRAS QUE MENOS APARECEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_tf = HashingTF().setInputCol(\"noStopWords\").setOutputCol(\"hashingTF\").setNumFeatures(20000) #20mil hasehs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized_data_df = hashing_tf.transform(no_stop_words_list_df) #A ESTO (unlike WordCount) no hay que hacer un fit antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- lastrev_pdt_time: timestamp (nullable = true)\n",
      " |-- revid: long (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- contributorid: long (nullable = true)\n",
      " |-- contributorusername: string (nullable = true)\n",
      " |-- contributorip: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- noStopWords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- hashingTF: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurized_data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>noStopWords</th>\n",
       "      <th>hashingTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33235801</td>\n",
       "      <td>KIG60</td>\n",
       "      <td>[infobox, radio, station, name, kig60, burling...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3484057</td>\n",
       "      <td>Chris Brown (album)</td>\n",
       "      <td>[infobox, album, see, wikipedia, wikiproject, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2872543</td>\n",
       "      <td>Humane Slaughter Act</td>\n",
       "      <td>[deleted, image, removed, image, cattlerestrai...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8100880</td>\n",
       "      <td>The Bicester School</td>\n",
       "      <td>[use, dmy, dates, date, october, 2014, infobox...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32693240</td>\n",
       "      <td>Siege of Nagykanizsa</td>\n",
       "      <td>[refimprove, date, september, 2011, infobox, m...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17074415</td>\n",
       "      <td>Andr??s Roemer</td>\n",
       "      <td>[use, mdy, dates, date, january, 2015, infobox...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47835010</td>\n",
       "      <td>Karie</td>\n",
       "      <td>[infobox, film, name, karie, image, caption, w...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6100355</td>\n",
       "      <td>Ois??n McConville</td>\n",
       "      <td>[infobox, gaa, player, image, oisin, mcconvill...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18799478</td>\n",
       "      <td>Remetea Mare</td>\n",
       "      <td>[refimprove, date, july, 2009, infobox, settle...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>722668</td>\n",
       "      <td>Greece national football team</td>\n",
       "      <td>[men, team, women, team, greece, women, nation...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                          title  \\\n",
       "0  33235801                          KIG60   \n",
       "1   3484057            Chris Brown (album)   \n",
       "2   2872543           Humane Slaughter Act   \n",
       "3   8100880            The Bicester School   \n",
       "4  32693240           Siege of Nagykanizsa   \n",
       "5  17074415                 Andr??s Roemer   \n",
       "6  47835010                          Karie   \n",
       "7   6100355              Ois??n McConville   \n",
       "8  18799478                   Remetea Mare   \n",
       "9    722668  Greece national football team   \n",
       "\n",
       "                                         noStopWords  \\\n",
       "0  [infobox, radio, station, name, kig60, burling...   \n",
       "1  [infobox, album, see, wikipedia, wikiproject, ...   \n",
       "2  [deleted, image, removed, image, cattlerestrai...   \n",
       "3  [use, dmy, dates, date, october, 2014, infobox...   \n",
       "4  [refimprove, date, september, 2011, infobox, m...   \n",
       "5  [use, mdy, dates, date, january, 2015, infobox...   \n",
       "6  [infobox, film, name, karie, image, caption, w...   \n",
       "7  [infobox, gaa, player, image, oisin, mcconvill...   \n",
       "8  [refimprove, date, july, 2009, infobox, settle...   \n",
       "9  [men, team, women, team, greece, women, nation...   \n",
       "\n",
       "                                           hashingTF  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurized_data_df.select(\"id\", \"title\", \"noStopWords\", \"hashingTF\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = featurized_data_df.select('hashingTF').first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.linalg.SparseVector"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  2.,  1.,  1.,  5.,  2.,  1.,  2.,  1.,  1.,  1.,  2.,\n",
       "        1.,  2.,  1.,  1., 10.,  2.,  1.,  3.,  1.,  2.,  1.,  1.,  1.,\n",
       "        2.,  2.,  1., 14.,  6.,  1.,  3.,  1.,  1.,  1.,  2.,  2.,  2.,\n",
       "        4.,  1.,  1.,  3., 11.,  1.,  1.,  1.,  1., 11.,  1.,  1.,  1.,\n",
       "        1.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,\n",
       "        1.,  1.,  2.,  1., 12.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  2.,  4.,  2.,  1.,  4.,  4.,  1.,  1.,  5.,  1.,\n",
       "        1.,  1.,  1.,  3.,  2.,  1.,  1.,  1.,  2.,  4.,  3.,  2.,  2.,\n",
       "        2.,  1., 10.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = featurized_data_df.select(\"id\", \"title\", \"noStopWords\", \"hashingTF\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=33235801, title='KIG60', noStopWords=['infobox', 'radio', 'station', 'name', 'kig60', 'burlington', 'hazards', 'image', 'image', 'noaa', 'hazards', 'svg', '150px', 'city', 'burlington', 'vermont', 'area', 'burlington', 'vermont', 'metropolitan', 'area', 'burlington', 'metro', 'branding', 'noaa', 'weather', 'radio', 'hazards', 'noaa', 'hazards', 'radio', 'slogan', 'voice', 'national', 'weather', 'service', 'airdate', 'language', 'american', 'english', 'english', 'frequency', '162', '400', 'megahertz', 'mhz', 'format', 'weather', 'radio', 'weather', 'civil', 'emergency', 'power', '500', 'watt', 'erp', 'haat', 'class', 'c', 'callsign_meaning', 'former_callsigns', 'owner', 'national', 'oceanic', 'atmospheric', 'administration', 'noaa', 'national', 'weather', 'service', 'webcast', 'website', 'http', 'www', 'erh', 'noaa', 'gov', 'btv', 'www', 'erh', 'noaa', 'gov', 'btv', 'affiliations', 'kig60', 'sometimes', 'referred', 'burlington', 'hazards', 'noaa', 'weather', 'radio', 'hazards', 'noaa', 'weather', 'radio', 'station', 'serves', 'burlington', 'vermont', 'metropolitan', 'area', 'burlington', 'metropolitan', 'area', 'surrounding', 'cities', 'broadcasts', 'also', 'heard', 'throughout', 'southern', 'parts', 'quebec', 'ontario', 'programmed', 'national', 'weather', 'service', 'forecast', 'office', 'burlington', 'vermont', 'transmitter', 'located', 'mount', 'mansfield', 'mt', 'mansfield', 'broadcasts', 'weather', 'hazard', 'information', 'addison', 'county', 'vermont', 'addison', 'chittenden', 'county', 'vermont', 'chittenden', 'franklin', 'county', 'vermont', 'franklin', 'grand', 'isle', 'county', 'vermont', 'grand', 'isle', 'lamoille', 'county', 'vermont', 'lamoille', 'washington', 'county', 'vermont', 'washington', 'counties', 'vermont', 'plus', 'clinton', 'county', 'new', 'york', 'clinton', 'essex', 'county', 'new', 'york', 'essex', 'franklin', 'county', 'new', 'york', 'franklin', 'st', 'lawrence', 'county', 'new', 'york', 'st', 'lawrence', 'counties', 'new', 'york', 'external', 'links', 'http', 'www', 'erh', 'noaa', 'gov', 'btv', 'nwr', 'nws', 'burlington', 'noaa', 'weather', 'radio', 'info', 'http', 'www', 'nws', 'noaa', 'gov', 'nwr', 'maps', 'php', 'site', 'php', 'state', 'vt', 'site', 'kig60', 'kig', '60', 'maps', 'details', 'burlington', 'plattsburgh', 'radio', 'coord', 'missing', 'vermont', 'category', 'radio', 'stations', 'vermont', 'kig60', 'category', 'noaa', 'weather', 'radio', 'vermont', 'radio', 'station', 'stub'], hashingTF=SparseVector(20000, {8: 1.0, 15: 1.0, 73: 2.0, 130: 1.0, 307: 1.0, 360: 5.0, 374: 2.0, 612: 1.0, 713: 2.0, 937: 1.0, 945: 1.0, 1468: 1.0, 2087: 2.0, 2384: 1.0, 2631: 2.0, 2930: 1.0, 3520: 1.0, 3545: 10.0, 3846: 2.0, 4239: 1.0, 4270: 3.0, 4330: 1.0, 4383: 2.0, 5349: 1.0, 5573: 1.0, 5743: 1.0, 5891: 2.0, 6001: 2.0, 6303: 1.0, 6533: 14.0, 6648: 6.0, 6860: 1.0, 6923: 3.0, 6980: 1.0, 7245: 1.0, 7414: 1.0, 7722: 2.0, 7950: 2.0, 8298: 2.0, 8455: 4.0, 8534: 1.0, 8572: 1.0, 8630: 3.0, 9172: 11.0, 9357: 1.0, 9707: 1.0, 9779: 1.0, 9825: 1.0, 9856: 11.0, 10201: 1.0, 10223: 1.0, 10586: 1.0, 10617: 1.0, 10665: 3.0, 11341: 1.0, 11394: 1.0, 11407: 1.0, 11525: 1.0, 11607: 1.0, 11716: 1.0, 11768: 1.0, 11827: 2.0, 11846: 1.0, 11960: 1.0, 12001: 1.0, 12028: 1.0, 12658: 1.0, 12712: 2.0, 13222: 1.0, 13428: 12.0, 13722: 1.0, 13743: 1.0, 13792: 1.0, 13793: 4.0, 13886: 1.0, 13998: 1.0, 14634: 1.0, 14917: 1.0, 14978: 1.0, 15099: 1.0, 15133: 1.0, 15220: 2.0, 15271: 4.0, 15347: 2.0, 15495: 1.0, 15645: 4.0, 15649: 4.0, 15662: 1.0, 15849: 1.0, 16025: 5.0, 16082: 1.0, 16128: 1.0, 16173: 1.0, 16355: 1.0, 16753: 3.0, 17482: 2.0, 17496: 1.0, 17644: 1.0, 17652: 1.0, 17775: 2.0, 17910: 4.0, 17995: 3.0, 18079: 2.0, 18399: 2.0, 18958: 2.0, 19063: 1.0, 19227: 10.0, 19369: 1.0, 19496: 1.0, 19737: 1.0, 19787: 1.0, 19823: 1.0, 19830: 1.0}))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: IDF\n",
    "\n",
    "Calculamos ahora los puntuaciones inversas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF().setInputCol(\"hashingTF\").setOutputCol(\"idf\") #DAMOS PESO A LAS PALABRAS QUE SALEN POCO\n",
    "idf_model = idf.fit(featurized_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDF_47fd8c036f5f17fcf6d9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashingTF</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{{Infobox Radio station\\n | name = KIG60 - Bur...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{{Infobox album &lt;!-- See Wikipedia:WikiProject...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;!-- Deleted image removed: [[Image:CattleRest...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{{Use dmy dates|date=October 2014}}\\n{{Infobox...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{{refimprove|date=September 2011}}\\n{{Infobox ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{{Use mdy dates|date=January 2015}}\\n{{Infobox...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{{Infobox film\\n| name = Karie\\n| image =\\n| c...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{{Infobox GAA player \\n| image           = Ois...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{{refimprove|date=July 2009}}\\n{{Infobox settl...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{{About|the men's team|the women's team|Greece...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  {{Infobox Radio station\\n | name = KIG60 - Bur...   \n",
       "1  {{Infobox album <!-- See Wikipedia:WikiProject...   \n",
       "2  <!-- Deleted image removed: [[Image:CattleRest...   \n",
       "3  {{Use dmy dates|date=October 2014}}\\n{{Infobox...   \n",
       "4  {{refimprove|date=September 2011}}\\n{{Infobox ...   \n",
       "5  {{Use mdy dates|date=January 2015}}\\n{{Infobox...   \n",
       "6  {{Infobox film\\n| name = Karie\\n| image =\\n| c...   \n",
       "7  {{Infobox GAA player \\n| image           = Ois...   \n",
       "8  {{refimprove|date=July 2009}}\\n{{Infobox settl...   \n",
       "9  {{About|the men's team|the women's team|Greece...   \n",
       "\n",
       "                                           hashingTF  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 idf  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.488...  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_model.transform(featurized_data_df).select(\"text\",\"hashingTF\",\"idf\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5: Normalizer\n",
    "\n",
    "Cómo queremos usar un método que usa distancias (K-Means) suele ser aconsejable normalizar las variables de entrada para que su dimensión no altere en el resultado del algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer().setInputCol(\"idf\").setOutputCol(\"features\") \n",
    "#NORMALIZAMOS LA VARIABLE IDF PARA QUE TODAS LAS COL SUMEN 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6: k-means & tie it all together...\n",
    "\n",
    "![](img/clustering.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = (\n",
    "    \n",
    "    KMeans()\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setPredictionCol(\"prediction\")\n",
    "    .setK(100)\n",
    "    .setSeed(1234)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer, remover, hashing_tf, idf, normalizer, kmeans])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUIDADO** Este `fit` puede durar varios minutos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(wiki_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions_df = model.transform(wiki_df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111495"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la variable `prediction` nos ha marcado en qué cluster a asignado cada artículo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "0          83\n",
       "1          24\n",
       "2          92\n",
       "3          25\n",
       "4          80\n",
       "5          64\n",
       "6          64\n",
       "7          70\n",
       "8          61\n",
       "9          45"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions_df.select(\"prediction\").limit(10).toPandas() #cuantos articulos de wikipedia han caido en ese grupo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántos grupos hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions_df.select(\"prediction\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|        64|44460|\n",
      "|        78| 7822|\n",
      "|        24| 3933|\n",
      "|        92| 3689|\n",
      "|        26| 3106|\n",
      "|        75| 3029|\n",
      "|        30| 2662|\n",
      "|        80| 2646|\n",
      "|        93| 2468|\n",
      "|        25| 2206|\n",
      "|         1| 2083|\n",
      "|        65| 1906|\n",
      "|         2| 1812|\n",
      "|        82| 1701|\n",
      "|        49| 1528|\n",
      "|        15| 1389|\n",
      "|        17| 1332|\n",
      "|        74| 1228|\n",
      "|        18| 1081|\n",
      "|         6| 1036|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_predictions_df.groupBy(\"prediction\").count().orderBy(F.desc(\"count\")).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lastrev_pdt_time</th>\n",
       "      <th>revid</th>\n",
       "      <th>comment</th>\n",
       "      <th>contributorid</th>\n",
       "      <th>contributorusername</th>\n",
       "      <th>contributorip</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>noStopWords</th>\n",
       "      <th>hashingTF</th>\n",
       "      <th>idf</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5919308</td>\n",
       "      <td>Apache Hadoop</td>\n",
       "      <td>2016-03-04 22:58:48</td>\n",
       "      <td>708371306</td>\n",
       "      <td>/* History */</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>71.84.15.41</td>\n",
       "      <td>{{multiple issues|\\n{{advert|date=October 2013...</td>\n",
       "      <td>[multiple, issues, advert, date, october, 2013...</td>\n",
       "      <td>[multiple, issues, advert, date, october, 2013...</td>\n",
       "      <td>(0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 14.299669926436321, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.010390351683305786, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          title    lastrev_pdt_time      revid        comment  \\\n",
       "0  5919308  Apache Hadoop 2016-03-04 22:58:48  708371306  /* History */   \n",
       "\n",
       "  contributorid contributorusername contributorip  \\\n",
       "0          None                None   71.84.15.41   \n",
       "\n",
       "                                                text  \\\n",
       "0  {{multiple issues|\\n{{advert|date=October 2013...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [multiple, issues, advert, date, october, 2013...   \n",
       "\n",
       "                                         noStopWords  \\\n",
       "0  [multiple, issues, advert, date, october, 2013...   \n",
       "\n",
       "                                           hashingTF  \\\n",
       "0  (0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 idf  \\\n",
       "0  (0.0, 14.299669926436321, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            features  prediction  \n",
       "0  (0.0, 0.010390351683305786, 0.0, 0.0, 0.0, 0.0...          64  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions_df.filter(F.lower(F.col('title')).like('%hadoop%')).toPandas() #vemos que este articulo esta en el cluster 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lastrev_pdt_time</th>\n",
       "      <th>revid</th>\n",
       "      <th>comment</th>\n",
       "      <th>contributorid</th>\n",
       "      <th>contributorusername</th>\n",
       "      <th>contributorip</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>noStopWords</th>\n",
       "      <th>hashingTF</th>\n",
       "      <th>idf</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42164234</td>\n",
       "      <td>Apache Spark</td>\n",
       "      <td>2016-03-03 14:13:40</td>\n",
       "      <td>708135330</td>\n",
       "      <td>relegate details to footnotes</td>\n",
       "      <td>196471</td>\n",
       "      <td>Qwertyus</td>\n",
       "      <td>None</td>\n",
       "      <td>{{Infobox Software\\n| name                   =...</td>\n",
       "      <td>[infobox, software, name, apache, spark, logo,...</td>\n",
       "      <td>[infobox, software, name, apache, spark, logo,...</td>\n",
       "      <td>(0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 6.128429968472709, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>(0.0, 0.014094462407126097, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id         title    lastrev_pdt_time      revid  \\\n",
       "0  42164234  Apache Spark 2016-03-03 14:13:40  708135330   \n",
       "\n",
       "                         comment  contributorid contributorusername  \\\n",
       "0  relegate details to footnotes         196471            Qwertyus   \n",
       "\n",
       "  contributorip                                               text  \\\n",
       "0          None  {{Infobox Software\\n| name                   =...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [infobox, software, name, apache, spark, logo,...   \n",
       "\n",
       "                                         noStopWords  \\\n",
       "0  [infobox, software, name, apache, spark, logo,...   \n",
       "\n",
       "                                           hashingTF  \\\n",
       "0  (0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 idf  \\\n",
       "0  (0.0, 6.128429968472709, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                            features  prediction  \n",
       "0  (0.0, 0.014094462407126097, 0.0, 0.0, 0.0, 0.0...          64  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions_df.filter(F.lower(F.col('title')).like('%apache spark%')).toPandas() #este tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chris Brown (album)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elis Paprika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grammy Award for Best Rap Album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maryland Deathfest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crime Pays (Cam'ron album)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If You Leave (Daughter album)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Little One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Steve Scott (poet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elvis Costello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Min barndoms jul (Mia Marianne och Per Filip a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rachel Alejandro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Leaving (EP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Themes (Vangelis album)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Roy Young (musician)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Universal Religion Chapter 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A Kind of Magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pepper's Ghost (Buckethead album)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pharrell Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Franz Ferdinand (band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Love Goes On (Paulette Carlson album)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title\n",
       "0                                 Chris Brown (album)\n",
       "1                                        Elis Paprika\n",
       "2                     Grammy Award for Best Rap Album\n",
       "3                                  Maryland Deathfest\n",
       "4                          Crime Pays (Cam'ron album)\n",
       "5                       If You Leave (Daughter album)\n",
       "6                                          Little One\n",
       "7                                  Steve Scott (poet)\n",
       "8                                      Elvis Costello\n",
       "9   Min barndoms jul (Mia Marianne och Per Filip a...\n",
       "10                                   Rachel Alejandro\n",
       "11                                       Leaving (EP)\n",
       "12                            Themes (Vangelis album)\n",
       "13                               Roy Young (musician)\n",
       "14                       Universal Religion Chapter 6\n",
       "15                                    A Kind of Magic\n",
       "16                  Pepper's Ghost (Buckethead album)\n",
       "17                                  Pharrell Williams\n",
       "18                             Franz Ferdinand (band)\n",
       "19              Love Goes On (Paulette Carlson album)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions_df.filter('prediction = 24').select('title').limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que la temática de estos artículos es informática / tecnología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Logistic-Regression_answers",
  "notebookId": 1355896319138518
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
